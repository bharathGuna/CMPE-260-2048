{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DQN_2048.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bRrnos3RGPq3"
      },
      "source": [
        "# 2048 Game Using Deep Q Learning\n",
        "\n",
        "In this colab, I have tried to implement 2048 game using Deep Convolutional Network.\n",
        "Deep Convolutional Network  accepts Game Matrix(nXn) as input. DCN has two convolutional layers, Expansion layer, Hidden layers, one Fully connected layer and last layer is a Dense layer with 4 outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPtPfzmpn_f7"
      },
      "source": [
        "\n",
        "![Screen Shot 2021-11-29 at 11.03.07 PM.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I5zbIIHGPq6"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1vZAFf9jWEz",
        "outputId": "f89a7b1d-fc78-4300-d546-b145fbb3fbe6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9KY9ue51GPq8"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import random \n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhaJP0x2GZw8",
        "outputId": "a610e1ea-260f-41f9-f4db-407e0f305564"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCqRxSSTGPrB"
      },
      "source": [
        "### Defining the Logic of Game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWM_sjU3a7BX"
      },
      "source": [
        "def reverse(mat):\n",
        "    new=[]\n",
        "    for i in range(len(mat)):\n",
        "        new.append([])\n",
        "        for j in range(len(mat[0])):\n",
        "            new[i].append(mat[i][len(mat[0])-j-1])\n",
        "    return new\n",
        "\n",
        "def transpose(mat):\n",
        "    new=[]\n",
        "    for i in range(len(mat[0])):\n",
        "        new.append([])\n",
        "        for j in range(len(mat)):\n",
        "            new[i].append(mat[j][i])\n",
        "            \n",
        "    return np.transpose(mat)\n",
        "\n",
        "def cover_up(mat):\n",
        "    new = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    done = False\n",
        "    for i in range(4):\n",
        "        count = 0\n",
        "        for j in range(4):\n",
        "            if mat[i][j]!=0:\n",
        "                new[i][count] = mat[i][j]\n",
        "                if j!=count:\n",
        "                    done=True\n",
        "                count+=1\n",
        "    return (new,done)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7yMqdrRSGPrD"
      },
      "source": [
        "#initialize a new game matrix  of zixe n*n\n",
        "def new_game(n):\n",
        "    matrix = np.zeros([n,n])\n",
        "    return matrix\n",
        "\n",
        "#add 2 or 4 in the matrix\n",
        "def add_two(m):\n",
        "    empty_cells = []\n",
        "    for i in range(len(m)):\n",
        "        for j in range(len(m[0])):\n",
        "            if(m[i][j]==0):\n",
        "                empty_cells.append((i,j))\n",
        "    if(len(empty_cells)==0):\n",
        "        return m\n",
        "    \n",
        "    index_pair = empty_cells[random.randint(0,len(empty_cells)-1)]\n",
        "  \n",
        "    prob = random.random()\n",
        "    if(prob>=0.9):\n",
        "        m[index_pair[0]][index_pair[1]]=4\n",
        "    else:\n",
        "        m[index_pair[0]][index_pair[1]]=2\n",
        "    return m\n",
        "\n",
        "#to check state of the game\n",
        "def game_state(mat):\n",
        "  \n",
        "    for i in range(len(mat)-1):\n",
        "        for j in range(len(mat[0])-1): \n",
        "            if mat[i][j]==mat[i+1][j] or mat[i][j+1]==mat[i][j]:\n",
        "                return 'Game not over'\n",
        "            \n",
        "    for i in range(len(mat)): #check for any zero entries\n",
        "        for j in range(len(mat[0])):\n",
        "            if mat[i][j]==0:\n",
        "                return 'Game not over'\n",
        "            \n",
        "    for k in range(len(mat)-1): #to check the left/right entries on the last row\n",
        "        if mat[len(mat)-1][k]==mat[len(mat)-1][k+1]:\n",
        "            return 'Game not over'\n",
        "        \n",
        "    for j in range(len(mat)-1): #check up/down entries on last column\n",
        "        if mat[j][len(mat)-1]==mat[j+1][len(mat)-1]:\n",
        "            return 'Game not over'\n",
        "        \n",
        "    return 'lose'\n",
        "\n",
        "\n",
        "\n",
        "#up move\n",
        "def up(game):\n",
        "        game = transpose(game)\n",
        "        game,done = cover_up(game)\n",
        "        temp = merge(game)\n",
        "        game = temp[0]\n",
        "        done = done or temp[1]\n",
        "        game = cover_up(game)[0]\n",
        "        game = transpose(game)\n",
        "        return (game,done,temp[2])\n",
        "#left move\n",
        "def left(game):\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "#down move\n",
        "def down(game):\n",
        "        game=reverse(transpose(game))\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=transpose(reverse(game))\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "#right move\n",
        "def right(game):\n",
        "        game=reverse(game)\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=reverse(game)\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "# Merge when two neighboring cells have the same value       \n",
        "def merge(mat):\n",
        "    done=False\n",
        "    score = 0\n",
        "    for i in range(4):\n",
        "        for j in range(3):\n",
        "            if mat[i][j]==mat[i][j+1] and mat[i][j]!=0:\n",
        "                mat[i][j]*=2\n",
        "                score += mat[i][j]   \n",
        "                mat[i][j+1]=0\n",
        "                done=True\n",
        "    return (mat,done,score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0bcWTxcGPrH"
      },
      "source": [
        "### Controls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "niiEbAq8GPrI"
      },
      "source": [
        "# Defining the dictionary for UP,DOWN, LEFT,RIGHT arrow movement\n",
        "controls = {0:up,1:left,2:right,3:down}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMeZQ0crGPrN"
      },
      "source": [
        "### Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RhjqTjqDGPrP"
      },
      "source": [
        "#hyper parameters for model training\n",
        "\n",
        "#gamma for Q-learning\n",
        "gamma = 0.9\n",
        "\n",
        "#epsilon greedy approach\n",
        "epsilon = 0.9\n",
        "\n",
        "#Learning Rate\n",
        "start_learning_rate = 0.0005\n",
        "\n",
        "\n",
        "#to store states and lables of the game for training\n",
        "#states of the game\n",
        "replay_memory = list()\n",
        "\n",
        "#labels of the states\n",
        "replay_labels = list()\n",
        "\n",
        "#capacity of memory\n",
        "mem_capacity = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpaJQPtFGPrJ"
      },
      "source": [
        "### Important Functions\n",
        "* Creating Empty Cell Function (Used in Reward)\n",
        "* Convert Input Values of Matrix to power of 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XyCfKsh6GPrK"
      },
      "source": [
        "#convert the input game matrix into corresponding power of 2 matrix.\n",
        "def change_values(X):\n",
        "    power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            if(X[i][j]==0):\n",
        "                power_mat[0][i][j][0] = 1.0\n",
        "            else:\n",
        "                power = int(math.log(X[i][j],2))\n",
        "                power_mat[0][i][j][power] = 1.0\n",
        "    return power_mat        \n",
        "\n",
        "#find the number of empty cells in the game matrix.\n",
        "def findemptyCell(mat):\n",
        "    count = 0\n",
        "    for i in range(len(mat)):\n",
        "        for j in range(len(mat)):\n",
        "            if(mat[i][j]==0):\n",
        "                count+=1\n",
        "    return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jZ9R3ZU4GPrR"
      },
      "source": [
        "#first convolution layer depth\n",
        "depth1 = 128\n",
        "\n",
        "#second convolution layer depth\n",
        "depth2 = 128\n",
        "\n",
        "#batch size for batch gradient descent\n",
        "batch_size = 512\n",
        "\n",
        "#input units\n",
        "input_units = 16\n",
        "\n",
        "#fully connected layer neurons\n",
        "hidden_units = 256 \n",
        "#output neurons = number of moves\n",
        "output_units = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x45dZMdzr_Q"
      },
      "source": [
        "## Building Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEaEsCbDGPrR"
      },
      "source": [
        "\n",
        "* Loss = mean (square( Q(st,at) - (r + gamma x max(Q(st+1,a))) ) )\n",
        "* Activation = RELU\n",
        "* Optimizer = RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJRHZhLC1WBu",
        "outputId": "9734c9d9-1034-4b55-f749-8ea5b5d6ec9b"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "#input data\n",
        "\n",
        "tf_batch_dataset =tf.compat.v1.placeholder(tf.float32,shape=(batch_size,4,4,16))\n",
        "tf_batch_labels  = tf.compat.v1.placeholder(tf.float32,shape=(batch_size,output_units))\n",
        "single_dataset   = tf.compat.v1.placeholder(tf.float32,shape=(1,4,4,16))\n",
        "\n",
        "\n",
        "#CONV LAYERS\n",
        "#conv layer1 weights\n",
        "def conv1_layer1_weights(shape=([1,2,input_units,depth1]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "def conv2_layer1_weights(shape=([2,1,input_units,depth1]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "\n",
        "#conv layer1 biases\n",
        "def conv1_layer1_biases(shape=([1,2,input_units,depth1]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "def conv2_layer1_biases(shape=([2,1,input_units,depth1]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "\n",
        "\n",
        "#conv layer2 weights\n",
        "def conv1_layer2_weights(shape=([1,2,depth1,depth2]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "def conv2_layer2_weights(shape=([2,1,depth1,depth2]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "\n",
        "#conv layer2 biases\n",
        "\n",
        "def conv1_layer2_biases(shape=([1,2,depth1,depth2]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "def conv2_layer2_biases(shape=([2,1,depth1,depth2]), dtype=None):\n",
        "    return tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.01)(shape, dtype=\"float32\")\n",
        "\n",
        "\n",
        "#Fully connected Layers\n",
        "expand_size = 2*4*depth2*2 + 3*3*depth2*2 + 4*3*depth1*2\n",
        "\n",
        "initializer_layerfcw1 = keras.initializers.TruncatedNormal(mean=0, stddev=0.01)\n",
        "fc_layer1_weights = tf.Variable(initializer_layerfcw1(shape=([expand_size,hidden_units])))\n",
        "\n",
        "initializer_layerfcb1 = keras.initializers.TruncatedNormal(mean=0, stddev=0.01)\n",
        "fc_layer1_biases = tf.Variable(initializer_layerfcb1(shape=([1,hidden_units])))\n",
        "\n",
        "initializer_layerfcw2 = keras.initializers.TruncatedNormal(mean=0, stddev=0.01)\n",
        "fc_layer2_weights = tf.Variable(initializer_layerfcw2(shape=([hidden_units,output_units])))\n",
        "\n",
        "initializer_layerfcb2 = keras.initializers.TruncatedNormal(mean=0, stddev=0.01)\n",
        "fc_layer2_biases = tf.Variable(initializer_layerfcb2(shape=([1,output_units])))\n",
        "\n",
        "\n",
        "def make_model(input_shape):\n",
        "    #Input\n",
        "    input=keras.Input(shape=input_shape[1:] ,name='input',batch_size=input_shape[0])\n",
        " \n",
        "    #layer1    \n",
        "\n",
        "    x=layers.Conv2D(kernel_size=(1,2),filters=128,strides=1,padding=\"valid\",name=\"conv1\",kernel_initializer=conv1_layer1_weights)(input)\n",
        "    y1=layers.Activation(\"relu\")(x)\n",
        "    y2=layers.Conv2D(kernel_size=(2,1),filters=128,strides=1,padding=\"valid\",name=\"conv2\",kernel_initializer=conv2_layer1_weights)(input)\n",
        "    y3=layers.Activation(\"relu\")(y2)\n",
        "\n",
        "   #layer2\n",
        "    y4=tf.keras.layers.Conv2D(kernel_size=(1,2),filters=128,strides=1,padding=\"valid\",name=\"conv11\",kernel_initializer=conv1_layer2_weights)(y1)\n",
        "    y5=layers.Activation(\"relu\")(y4)\n",
        "    y6=tf.keras.layers.Conv2D(kernel_size=(2,1),filters=128,strides=1,padding=\"valid\",name=\"conv12\",kernel_initializer=conv2_layer2_weights)(y1)\n",
        "    y7=layers.Activation(\"relu\")(y6)\n",
        "    y8=tf.keras.layers.Conv2D(kernel_size=(1,2),filters=128,strides=1,padding=\"valid\",name=\"conv21\",kernel_initializer=conv1_layer2_weights)(y3)\n",
        "    y9=layers.Activation(\"relu\")(y8)\n",
        "    y10=tf.keras.layers.Conv2D(kernel_size=(2,1),filters=128,strides=1,padding=\"valid\",name=\"conv22\",kernel_initializer=conv2_layer2_weights)(y3)\n",
        "    y11=layers.Activation(\"relu\")(y10)\n",
        "\n",
        "    #get shapes of all activations\n",
        "    shape1 = y1.shape.as_list()\n",
        "    shape2 = y3.shape.as_list()\n",
        "    shape11 = y5.shape.as_list()\n",
        "    shape12 = y7.shape.as_list()\n",
        "    shape21 = y9.shape.as_list()\n",
        "    shape22 = y11.shape.as_list()\n",
        "  \n",
        "    #expansion\n",
        "    hidden1 = tf.reshape(y1,[shape1[0],shape1[1]*shape1[2]*shape1[3]])\n",
        "    hidden2 = tf.reshape(y3,[shape2[0],shape2[1]*shape2[2]*shape2[3]])\n",
        "    hidden11 = tf.reshape(y5,[shape11[0],shape11[1]*shape11[2]*shape11[3]])\n",
        "    hidden12 = tf.reshape(y7,[shape12[0],shape12[1]*shape12[2]*shape12[3]])\n",
        "    hidden21 = tf.reshape(y9,[shape21[0],shape21[1]*shape21[2]*shape21[3]])\n",
        "    hidden22 = tf.reshape(y11,[shape22[0],shape22[1]*shape22[2]*shape22[3]])\n",
        " \n",
        "    #concatenation\n",
        "    hidden = tf.concat([hidden1,hidden2,hidden11,hidden12,hidden21,hidden22],axis=1)\n",
        "\n",
        "    #full connected layers\n",
        "    # hidden=layers.Dense(units=256,kernel_initializer=fc_layer1_weights,bias_initializer=fc_layer1_biases,activation=\"relu\")(hidden)\n",
        "    hidden=layers.Dense(units=256,activation=\"relu\")(hidden)\n",
        "    \n",
        "    #output layer\n",
        "\n",
        "    output=layers.Dense(4,activation=None)(hidden)\n",
        "  \n",
        "    return keras.Model(input,output)\n",
        "\n",
        "\n",
        "model1=make_model(input_shape=(1, 4, 4, 16))\n",
        "model2=make_model(input_shape=(512, 4, 4, 16))\n",
        "\n",
        "# Model prediction for single example\n",
        "single_output = model1(single_dataset)\n",
        "\n",
        "# Model prediction for batch data\n",
        "logits = model2(tf_batch_dataset)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v1.py:409: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prdnfJORfDJp"
      },
      "source": [
        "## Defining Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ocva3TOfL4E",
        "outputId": "5f9b7651-de98-4060-fb7d-9086127e40c4"
      },
      "source": [
        "loss = tf.square(tf.subtract(tf_batch_labels,logits))\n",
        "loss = tf.reduce_sum(loss,axis=1,keep_dims=True)\n",
        "loss = tf.reduce_mean(loss)/2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEdFUpPufC43"
      },
      "source": [
        "## Defining RMS Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "618MhZjqfUoW",
        "outputId": "020a7e0b-0bd1-4937-8fee-d4289294de69"
      },
      "source": [
        "#optimizer\n",
        "global_step = tf.Variable(0)  # count the number of steps taken.\n",
        "learning_rate = tf.train.exponential_decay(float(start_learning_rate), global_step, 1000, 0.90, staircase=True)\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/rmsprop.py:192: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQw18ZGURWtO",
        "outputId": "b941ad07-d7ba-462b-ecd2-c6a3ca2d66e7"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(1, 4, 4, 16)]      0           []                               \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)                 (1, 4, 3, 128)       4224        ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2 (Conv2D)                 (1, 3, 4, 128)       4224        ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " activation (Activation)        (1, 4, 3, 128)       0           ['conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (1, 3, 4, 128)       0           ['conv2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv11 (Conv2D)                (1, 4, 2, 128)       32896       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv12 (Conv2D)                (1, 3, 3, 128)       32896       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv21 (Conv2D)                (1, 3, 3, 128)       32896       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv22 (Conv2D)                (1, 2, 4, 128)       32896       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (1, 4, 2, 128)       0           ['conv11[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (1, 3, 3, 128)       0           ['conv12[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (1, 3, 3, 128)       0           ['conv21[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (1, 2, 4, 128)       0           ['conv22[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_op_layer_Reshape (TensorFlo  [(1, 1536)]         0           ['activation[0][0]']             \n",
            " wOpLayer)                                                                                        \n",
            "                                                                                                  \n",
            " tf_op_layer_Reshape_1 (TensorF  [(1, 1536)]         0           ['activation_1[0][0]']           \n",
            " lowOpLayer)                                                                                      \n",
            "                                                                                                  \n",
            " tf_op_layer_Reshape_2 (TensorF  [(1, 1024)]         0           ['activation_2[0][0]']           \n",
            " lowOpLayer)                                                                                      \n",
            "                                                                                                  \n",
            " tf_op_layer_Reshape_3 (TensorF  [(1, 1152)]         0           ['activation_3[0][0]']           \n",
            " lowOpLayer)                                                                                      \n",
            "                                                                                                  \n",
            " tf_op_layer_Reshape_4 (TensorF  [(1, 1152)]         0           ['activation_4[0][0]']           \n",
            " lowOpLayer)                                                                                      \n",
            "                                                                                                  \n",
            " tf_op_layer_Reshape_5 (TensorF  [(1, 1024)]         0           ['activation_5[0][0]']           \n",
            " lowOpLayer)                                                                                      \n",
            "                                                                                                  \n",
            " tf_op_layer_concat (TensorFlow  [(1, 7424)]         0           ['tf_op_layer_Reshape[0][0]',    \n",
            " OpLayer)                                                         'tf_op_layer_Reshape_1[0][0]',  \n",
            "                                                                  'tf_op_layer_Reshape_2[0][0]',  \n",
            "                                                                  'tf_op_layer_Reshape_3[0][0]',  \n",
            "                                                                  'tf_op_layer_Reshape_4[0][0]',  \n",
            "                                                                  'tf_op_layer_Reshape_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (1, 256)             1900800     ['tf_op_layer_concat[0][0]']     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (1, 4)               1028        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,041,860\n",
            "Trainable params: 2,041,860\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFMG1UgFYrgm"
      },
      "source": [
        "##Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CkYI1mnWGPrS"
      },
      "source": [
        "#loss\n",
        "J = []\n",
        "\n",
        "#scores\n",
        "scores = []\n",
        "\n",
        "#to store final weights\n",
        "final_weights = {}\n",
        "\n",
        "#number of episodes\n",
        "M = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZSegh2CGPrV",
        "outputId": "464812f0-5c86-40c9-e4dc-f2e1dd4c34ee"
      },
      "source": [
        "with tf.Session() as session:\n",
        "  \n",
        "    tf.global_variables_initializer().run()\n",
        "    print(\"Initialized\")\n",
        "    \n",
        "    global epsilon\n",
        "    global replay_labels\n",
        "    global replay_memory\n",
        "\n",
        "    #for episode with max score\n",
        "    maximum = -1\n",
        "    episode = -1\n",
        "    \n",
        "    #total_iters \n",
        "    total_iters = 1\n",
        "    \n",
        "    #number of back props\n",
        "    back=0\n",
        "    \n",
        "    for ep in range(M):\n",
        "        global board\n",
        "        board = new_game(4) ## initilizing the game board\n",
        "        add_two(board)\n",
        "        add_two(board)\n",
        "        \n",
        "        #whether episode finished or not\n",
        "        finish = 'Game not over'\n",
        "        \n",
        "        #total_score of this episode\n",
        "        total_score = 0\n",
        "        \n",
        "        #iters per episode\n",
        "        local_iters = 1\n",
        "        \n",
        "        while(finish=='Game not over'):\n",
        "            prev_board = deepcopy(board)\n",
        "\n",
        "            #store prev max\n",
        "            prev_max = np.max(prev_board)\n",
        "\n",
        "            #get the required move for this state\n",
        "            state = deepcopy(board)\n",
        "           \n",
        "            state = change_values(state)\n",
        "          \n",
        "            state = np.array(state,dtype = np.float32).reshape(1,4,4,16)\n",
        "           \n",
        "            feed_dict = {single_dataset:state}\n",
        "        \n",
        "            control_scores = session.run(single_output,feed_dict=feed_dict)\n",
        " \n",
        "            #find the move with max Q value (sorting in decreasing order)\n",
        "            control_buttons = np.flip(np.argsort(control_scores),axis=1)\n",
        "         \n",
        "            #copy the Q-values as labels\n",
        "            labels = deepcopy(control_scores[0])\n",
        "       \n",
        "            #generate random number for epsilon greedy approach\n",
        "            num = random.uniform(0,1)\n",
        "   \n",
        "            #num is less epsilon generate random move\n",
        "            if(num<epsilon):\n",
        "                #find legal moves\n",
        "                legal_moves = list()\n",
        "                for i in range(4):\n",
        "                    temp_board = deepcopy(prev_board)\n",
        "                   \n",
        "                    temp_board,_,_ = controls[i](temp_board)\n",
        "                    if(np.array_equal(temp_board,prev_board)):\n",
        "                        continue\n",
        "                    else:\n",
        "                        legal_moves.append(i)\n",
        "                if(len(legal_moves)==0):\n",
        "                    finish = 'lose'\n",
        "                    continue\n",
        "                \n",
        "                #generate random move.\n",
        "                con = random.sample(legal_moves,1)[0]\n",
        "             \n",
        "                #apply the move\n",
        "                temp_state = deepcopy(prev_board)\n",
        "                temp_state,_,score = controls[con](temp_state)\n",
        "                total_score += score\n",
        "                finish = game_state(temp_state)\n",
        "                \n",
        "                #get number of merges\n",
        "                empty1 = findemptyCell(prev_board)\n",
        "                empty2 = findemptyCell(temp_state)\n",
        "                \n",
        "                if(finish=='Game not over'):\n",
        "                    temp_state = add_two(temp_state)\n",
        "\n",
        "                board = deepcopy(temp_state)\n",
        "\n",
        "                #get next max after applying the move\n",
        "                next_max = np.max(temp_state)\n",
        "\n",
        "               #Current Reward = number of merges + log(new max,2)\n",
        "                #reward math.log(next_max,2)*0.1 if next_max is higher than prev max\n",
        "                labels[con] = (math.log(next_max,2))*0.1\n",
        "                \n",
        "                if(next_max==prev_max):\n",
        "                    labels[con] = 0\n",
        "                \n",
        "                #reward is also the number of merges\n",
        "                labels[con] += (empty2-empty1)\n",
        "                \n",
        "                #get the next state max Q-value\n",
        "                temp_state = change_values(temp_state)\n",
        "                temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
        "                feed_dict = {single_dataset:temp_state}\n",
        "                temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
        "                    \n",
        "                max_qvalue = np.max(temp_scores)\n",
        "                \n",
        "                #final labels add gamma*max_qvalue\n",
        "                labels[con] = (labels[con] + gamma*max_qvalue)\n",
        "            \n",
        "            #generate the the max predicted move\n",
        "            else:\n",
        "                for con in control_buttons[0]:\n",
        "                    prev_state = deepcopy(prev_board)\n",
        "                    \n",
        "                    #apply the LEGAl Move with max q_value\n",
        "                    temp_state,_,score = controls[con](prev_state)\n",
        "                    \n",
        "                    #if illegal move label = 0\n",
        "                    if(np.array_equal(prev_board,temp_state)):\n",
        "                        labels[con] = 0\n",
        "                        continue\n",
        "                        \n",
        "                    #get number of merges\n",
        "                    empty1 = findemptyCell(prev_board)\n",
        "                    empty2 = findemptyCell(temp_state)\n",
        "\n",
        "                    temp_state = add_two(temp_state)\n",
        "                    board = deepcopy(temp_state)\n",
        "                    total_score += score\n",
        "\n",
        "                    next_max = np.max(temp_state)\n",
        "                    \n",
        "                    #reward\n",
        "                    labels[con] = (math.log(next_max,2))*0.1\n",
        "                    if(next_max==prev_max):\n",
        "                        labels[con] = 0\n",
        "                    \n",
        "                    labels[con] += (empty2-empty1)\n",
        "\n",
        "                    #get next max qvalue\n",
        "                    temp_state = change_values(temp_state)\n",
        "                    temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
        "                    feed_dict = {single_dataset:temp_state}\n",
        "                    temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
        "\n",
        "                    max_qvalue = np.max(temp_scores)\n",
        "\n",
        "                    #final labels\n",
        "                    labels[con] = (labels[con] + gamma*max_qvalue)\n",
        "                    break\n",
        "                    \n",
        "                if(np.array_equal(prev_board,board)):\n",
        "                    finish = 'lose'\n",
        "            \n",
        "            #decrease the epsilon value\n",
        "            if((ep>5000) or (epsilon>0.1 and total_iters%2500==0)):\n",
        "                epsilon = epsilon/1.005\n",
        "                \n",
        "           \n",
        "            #change the matrix values and store them in memory\n",
        "            prev_state = deepcopy(prev_board)\n",
        "            prev_state = change_values(prev_state)\n",
        "            prev_state = np.array(prev_state,dtype=np.float32).reshape(1,4,4,16)\n",
        "            # print(replay_labels)\n",
        "            replay_labels.append(labels)\n",
        "            replay_memory.append(prev_state)\n",
        "            \n",
        "            \n",
        "            #back-propagation\n",
        "            if(len(replay_memory)>=mem_capacity):\n",
        "                back_loss = 0\n",
        "                batch_num = 0\n",
        "                z = list(zip(replay_memory,replay_labels))\n",
        "                np.random.shuffle(z)\n",
        "                np.random.shuffle(z)\n",
        "                replay_memory,replay_labels = zip(*z)\n",
        "                \n",
        "                for i in range(0,len(replay_memory),batch_size):\n",
        "                    if(i + batch_size>len(replay_memory)):\n",
        "                        break\n",
        "                        \n",
        "                    batch_data = deepcopy(replay_memory[i:i+batch_size])\n",
        "                    batch_labels = deepcopy(replay_labels[i:i+batch_size])\n",
        "                    \n",
        "                    batch_data = np.array(batch_data,dtype=np.float32).reshape(batch_size,4,4,16)\n",
        "                    batch_labels = np.array(batch_labels,dtype=np.float32).reshape(batch_size,output_units)\n",
        "                \n",
        "                    feed_dict = {tf_batch_dataset: batch_data, tf_batch_labels: batch_labels}\n",
        "                    _,l = session.run([optimizer,loss],feed_dict=feed_dict)\n",
        "                  \n",
        "                    back_loss += l \n",
        "                    \n",
        "                    print(\"Mini-Batch - {} Back-Prop : {}, Loss : {}\".format(batch_num,back,l))\n",
        "                    batch_num +=1\n",
        "                back_loss /= batch_num\n",
        "                J.append(back_loss)\n",
        "                \n",
        "                #store the weights in a dictionary\n",
        "                final_weights['conv1_layer1_weights'] = session.run(conv1_layer1_weights())\n",
        "                final_weights['conv1_layer2_weights'] = session.run(conv1_layer2_weights())\n",
        "                final_weights['conv2_layer1_weights'] = session.run(conv2_layer1_weights())\n",
        "                final_weights['conv2_layer2_weights'] = session.run(conv2_layer2_weights())\n",
        "                final_weights['conv1_layer1_biases'] = session.run(conv1_layer1_biases())\n",
        "                final_weights['conv1_layer2_biases'] = session.run(conv1_layer2_biases())\n",
        "                final_weights['conv2_layer1_biases'] = session.run(conv2_layer1_biases())\n",
        "                final_weights['conv2_layer2_biases'] = session.run(conv2_layer2_biases())\n",
        "                final_weights['fc_layer1_weights'] = session.run(fc_layer1_weights)\n",
        "                final_weights['fc_layer2_weights'] = session.run(fc_layer2_weights)\n",
        "                final_weights['fc_layer1_biases'] = session.run(fc_layer1_biases)\n",
        "                final_weights['fc_layer2_biases'] = session.run(fc_layer2_biases)\n",
        "                \n",
        "                #number of back-props\n",
        "                back+=1\n",
        "                \n",
        "                #make new memory \n",
        "                replay_memory = list()\n",
        "                replay_labels = list()\n",
        "                \n",
        "            \n",
        "            if(local_iters%400==0):\n",
        "                print(\"Episode : {}, Score : {}, Iters : {}, Finish : {}\".format(ep,total_score,local_iters,finish))\n",
        "            \n",
        "            local_iters += 1\n",
        "            total_iters += 1\n",
        "            \n",
        "        scores.append(total_score)\n",
        "        if ep%5==0:\n",
        "          print(\"Episode {} finished with score {}, result : {} board : {}, epsilon  : {}, learning rate : {} \".format(ep,total_score,finish,board,epsilon,session.run(learning_rate)))\n",
        "          print()\n",
        "        \n",
        "        if((ep+1)%1000==0):\n",
        "            print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    \n",
        "            print(\"Loss : {}\".format(J[len(J)-1]))\n",
        "            print()\n",
        "            \n",
        "        if(maximum<total_score):\n",
        "            maximum = total_score\n",
        "            episode = ep\n",
        "\n",
        "    print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 119, Loss : 0.38847389817237854\n",
            "Mini-Batch - 1 Back-Prop : 119, Loss : 0.36304253339767456\n",
            "Mini-Batch - 2 Back-Prop : 119, Loss : 0.428275465965271\n",
            "Mini-Batch - 3 Back-Prop : 119, Loss : 0.4230368435382843\n",
            "Mini-Batch - 4 Back-Prop : 119, Loss : 0.3486279547214508\n",
            "Mini-Batch - 5 Back-Prop : 119, Loss : 0.4061506390571594\n",
            "Mini-Batch - 6 Back-Prop : 119, Loss : 0.43235206604003906\n",
            "Mini-Batch - 7 Back-Prop : 119, Loss : 0.3584100604057312\n",
            "Mini-Batch - 8 Back-Prop : 119, Loss : 0.3933515250682831\n",
            "Episode 4960 finished with score 1260.0, result : lose board : [[  8.  16.   2.  16.]\n",
            " [  2.  64. 128.   8.]\n",
            " [  4.  16.   4.   2.]\n",
            " [  8.   4.   2.   4.]], epsilon  : 0.2718865274268254, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4965 finished with score 444.0, result : lose board : [[ 2.  8. 16.  2.]\n",
            " [ 4.  2.  4. 32.]\n",
            " [ 2.  4. 32.  4.]\n",
            " [ 4. 32.  4.  2.]], epsilon  : 0.2718865274268254, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4970 finished with score 512.0, result : lose board : [[4.0, 32.0, 8.0, 2], [16.0, 4.0, 16.0, 32.0], [8.0, 32.0, 2.0, 8.0], [2, 4.0, 8.0, 2.0]], epsilon  : 0.2718865274268254, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4975 finished with score 760.0, result : lose board : [[2.0, 4.0, 16.0, 2.0], [4, 2, 64.0, 4.0], [8.0, 64.0, 16.0, 8.0], [2.0, 4.0, 8.0, 2.0]], epsilon  : 0.2718865274268254, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4980 finished with score 920.0, result : lose board : [[4, 2, 16.0, 32.0], [2.0, 32.0, 64.0, 4.0], [4.0, 64.0, 4.0, 2.0], [2, 4.0, 2.0, 8.0]], epsilon  : 0.2705338581361447, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4985 finished with score 552.0, result : lose board : [[8.0, 2.0, 32.0, 2.0], [4.0, 8.0, 2.0, 4.0], [2.0, 16.0, 64.0, 2.0], [4, 2, 8.0, 16]], epsilon  : 0.2705338581361447, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4990 finished with score 1344.0, result : lose board : [[32.0, 8.0, 32.0, 4.0], [4.0, 2.0, 4.0, 32.0], [8.0, 32.0, 128.0, 8.0], [2, 4, 16.0, 2]], epsilon  : 0.2705338581361447, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 4995 finished with score 768.0, result : lose board : [[2.0, 4.0, 32.0, 4.0], [8.0, 16.0, 64.0, 32.0], [4.0, 2.0, 32.0, 8.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.2705338581361447, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 120, Loss : 0.42096275091171265\n",
            "Mini-Batch - 1 Back-Prop : 120, Loss : 0.41650447249412537\n",
            "Mini-Batch - 2 Back-Prop : 120, Loss : 0.3990843594074249\n",
            "Mini-Batch - 3 Back-Prop : 120, Loss : 0.40128254890441895\n",
            "Mini-Batch - 4 Back-Prop : 120, Loss : 0.46218401193618774\n",
            "Mini-Batch - 5 Back-Prop : 120, Loss : 0.3810849189758301\n",
            "Mini-Batch - 6 Back-Prop : 120, Loss : 0.3971894681453705\n",
            "Mini-Batch - 7 Back-Prop : 120, Loss : 0.35622546076774597\n",
            "Mini-Batch - 8 Back-Prop : 120, Loss : 0.39141809940338135\n",
            "Maximum Score : 4712.0 ,Episode : 4137\n",
            "Loss : 0.40288178788291085\n",
            "\n",
            "Episode 5000 finished with score 416.0, result : lose board : [[ 2.  4. 16.  2.]\n",
            " [ 8. 16. 32.  4.]\n",
            " [ 2.  4. 16. 32.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 0.2691879185434276, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5005 finished with score 1168.0, result : lose board : [[ 2.  4. 64.  4.]\n",
            " [32. 16.  4. 64.]\n",
            " [ 4.  8. 64. 16.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 0.003998521558155529, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5010 finished with score 1780.0, result : lose board : [[  8.  32.  64. 128.]\n",
            " [  4.  16.   4.  64.]\n",
            " [  2.   8.  32.  16.]\n",
            " [  4.   2.  16.   2.]], epsilon  : 0.00012059355244720462, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5015 finished with score 1492.0, result : lose board : [[  2.   8.  64.   8.]\n",
            " [  8.   2. 128.  64.]\n",
            " [  4.   8.  16.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 2.502039167732412e-06, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5020 finished with score 1408.0, result : lose board : [[8.0, 32.0, 64.0, 128.0], [2.0, 8.0, 16.0, 2.0], [4, 2.0, 4.0, 32.0], [2, 4.0, 8.0, 4]], epsilon  : 5.511335639123586e-08, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5025 finished with score 956.0, result : lose board : [[16. 32.  4. 64.]\n",
            " [ 8. 16. 64. 16.]\n",
            " [ 2.  4. 16.  4.]\n",
            " [ 4.  8.  4.  2.]], epsilon  : 1.8365499401141739e-09, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 121, Loss : 0.32903170585632324\n",
            "Mini-Batch - 1 Back-Prop : 121, Loss : 0.29412639141082764\n",
            "Mini-Batch - 2 Back-Prop : 121, Loss : 0.2903304398059845\n",
            "Mini-Batch - 3 Back-Prop : 121, Loss : 0.3077440857887268\n",
            "Mini-Batch - 4 Back-Prop : 121, Loss : 0.3289163112640381\n",
            "Mini-Batch - 5 Back-Prop : 121, Loss : 0.2911921739578247\n",
            "Mini-Batch - 6 Back-Prop : 121, Loss : 0.3052274286746979\n",
            "Mini-Batch - 7 Back-Prop : 121, Loss : 0.31117093563079834\n",
            "Mini-Batch - 8 Back-Prop : 121, Loss : 0.27586492896080017\n",
            "Episode 5030 finished with score 1236.0, result : lose board : [[16.0, 64.0, 4.0, 64.0], [8.0, 32.0, 64.0, 16.0], [4.0, 2.0, 16.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 4.06566471255153e-11, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5035 finished with score 1548.0, result : lose board : [[ 16.  64.   4.  16.]\n",
            " [  8.  16. 128.   8.]\n",
            " [  2.   8.  64.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.196168600286338e-13, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5040 finished with score 1516.0, result : lose board : [[ 32.   2.   4.   2.]\n",
            " [  2.  16. 128.  32.]\n",
            " [  4.  64.   8.   4.]\n",
            " [  2.  32.   4.   2.]], epsilon  : 1.2910463184823379e-14, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5045 finished with score 1016.0, result : lose board : [[16. 32.  4. 64.]\n",
            " [ 8. 64.  2.  8.]\n",
            " [ 4.  8. 32.  4.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 2.036003134066419e-16, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5050 finished with score 1428.0, result : lose board : [[16.0, 32.0, 128.0, 32.0], [2.0, 8.0, 32.0, 16.0], [8.0, 32.0, 16.0, 4.0], [2, 8, 4.0, 2]], epsilon  : 4.07930356643951e-18, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5055 finished with score 2608.0, result : lose board : [[ 16.  32. 256.  32.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.938799216474956e-20, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 122, Loss : 0.25154900550842285\n",
            "Mini-Batch - 1 Back-Prop : 122, Loss : 0.2686433792114258\n",
            "Mini-Batch - 2 Back-Prop : 122, Loss : 0.3097206652164459\n",
            "Mini-Batch - 3 Back-Prop : 122, Loss : 0.29724371433258057\n",
            "Mini-Batch - 4 Back-Prop : 122, Loss : 0.30757004022598267\n",
            "Mini-Batch - 5 Back-Prop : 122, Loss : 0.29903683066368103\n",
            "Mini-Batch - 6 Back-Prop : 122, Loss : 0.2785797417163849\n",
            "Mini-Batch - 7 Back-Prop : 122, Loss : 0.254055917263031\n",
            "Mini-Batch - 8 Back-Prop : 122, Loss : 0.23596647381782532\n",
            "Episode 5060 finished with score 1868.0, result : lose board : [[2.0, 32.0, 64.0, 128.0], [8.0, 16.0, 32.0, 64.0], [4.0, 2.0, 16.0, 32.0], [2.0, 4.0, 8.0, 2]], epsilon  : 5.27843493000699e-22, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5065 finished with score 1760.0, result : lose board : [[ 32.   2. 128.   8.]\n",
            " [  8.  16.   8. 128.]\n",
            " [  4.   8.   4.   8.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 9.71604919721858e-24, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5070 finished with score 2108.0, result : lose board : [[  4.  16.   4. 256.]\n",
            " [  8.  32.   2.   8.]\n",
            " [  4.  16.  32.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 1.1763188343528384e-25, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5075 finished with score 1364.0, result : lose board : [[2, 4.0, 128.0, 8.0], [16.0, 64.0, 32.0, 2.0], [4.0, 16.0, 8.0, 16.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 3.0546949357888597e-27, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5080 finished with score 1192.0, result : lose board : [[  4.  16.  32. 128.]\n",
            " [  8.   2.  16.   2.]\n",
            " [  4.   8.  32.   8.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 6.562968086057574e-29, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5085 finished with score 736.0, result : lose board : [[ 4.  2.  8.  2.]\n",
            " [16. 32.  2. 32.]\n",
            " [ 8. 16. 64. 16.]\n",
            " [ 4.  2.  4.  8.]], epsilon  : 5.5485460069025315e-31, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 123, Loss : 0.21520137786865234\n",
            "Mini-Batch - 1 Back-Prop : 123, Loss : 0.2552618384361267\n",
            "Mini-Batch - 2 Back-Prop : 123, Loss : 0.27077800035476685\n",
            "Mini-Batch - 3 Back-Prop : 123, Loss : 0.21728160977363586\n",
            "Mini-Batch - 4 Back-Prop : 123, Loss : 0.23029424250125885\n",
            "Mini-Batch - 5 Back-Prop : 123, Loss : 0.246008962392807\n",
            "Mini-Batch - 6 Back-Prop : 123, Loss : 0.24039994180202484\n",
            "Mini-Batch - 7 Back-Prop : 123, Loss : 0.2319183647632599\n",
            "Mini-Batch - 8 Back-Prop : 123, Loss : 0.23227059841156006\n",
            "Episode 5090 finished with score 444.0, result : lose board : [[4.0, 16.0, 64.0, 4.0], [2.0, 8.0, 16.0, 2], [4, 2, 4.0, 8.0], [8.0, 4.0, 2, 4]], epsilon  : 1.2344516122090334e-32, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5095 finished with score 2528.0, result : lose board : [[  8.  32.  64. 256.]\n",
            " [  4.  16.  32.   4.]\n",
            " [  2.   4.  16.  32.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 1.2551546958346317e-34, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5100 finished with score 244.0, result : lose board : [[ 2.  8. 16.  8.]\n",
            " [16.  2.  8.  2.]\n",
            " [ 4. 16.  2. 16.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 2.806455735605073e-36, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5105 finished with score 3008.0, result : lose board : [[ 16.  64.   4.   2.]\n",
            " [  8.   4. 128. 256.]\n",
            " [  2.  16.   8.  16.]\n",
            " [  4.   8.   2.   4.]], epsilon  : 9.121657683230602e-38, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5110 finished with score 2004.0, result : lose board : [[8.0, 16.0, 128.0, 8.0], [2.0, 8.0, 2.0, 16.0], [8.0, 128.0, 16.0, 4.0], [2, 4.0, 64.0, 2.0]], epsilon  : 9.414454033744347e-40, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5115 finished with score 1208.0, result : lose board : [[  2.  16. 128.   2.]\n",
            " [  8.   4.  16.   4.]\n",
            " [  2.   8.   4.  64.]\n",
            " [  8.   4.   2.   8.]], epsilon  : 1.1117321779092153e-41, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5120 finished with score 616.0, result : lose board : [[ 2. 16. 32.  2.]\n",
            " [ 8.  4.  8. 64.]\n",
            " [ 4.  2.  4.  2.]\n",
            " [ 2. 16.  2. 16.]], epsilon  : 8.86761573796242e-43, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 124, Loss : 0.23872752487659454\n",
            "Mini-Batch - 1 Back-Prop : 124, Loss : 0.2706894278526306\n",
            "Mini-Batch - 2 Back-Prop : 124, Loss : 0.2769886553287506\n",
            "Mini-Batch - 3 Back-Prop : 124, Loss : 0.23641963303089142\n",
            "Mini-Batch - 4 Back-Prop : 124, Loss : 0.24213474988937378\n",
            "Mini-Batch - 5 Back-Prop : 124, Loss : 0.2666541337966919\n",
            "Mini-Batch - 6 Back-Prop : 124, Loss : 0.271742045879364\n",
            "Mini-Batch - 7 Back-Prop : 124, Loss : 0.2659388482570648\n",
            "Mini-Batch - 8 Back-Prop : 124, Loss : 0.28864678740501404\n",
            "Episode 5125 finished with score 1888.0, result : lose board : [[  2.   8.  64. 128.]\n",
            " [ 16.  32.   4.  64.]\n",
            " [  2.  64.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 9.912546163496763e-45, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5130 finished with score 1060.0, result : lose board : [[4.0, 32.0, 2.0, 64.0], [16.0, 8.0, 64.0, 8.0], [4.0, 16.0, 32.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 3.84909373949319e-47, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5135 finished with score 2956.0, result : lose board : [[  2.   8.  32.   2.]\n",
            " [  8.  16. 256.  32.]\n",
            " [  4.   8. 128.   4.]\n",
            " [  2.   4.  32.   2.]], epsilon  : 2.665599612802939e-49, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5140 finished with score 648.0, result : lose board : [[2, 4.0, 16.0, 32.0], [16.0, 8.0, 64.0, 2.0], [4.0, 16.0, 4.0, 16.0], [2.0, 4.0, 2.0, 8.0]], epsilon  : 4.2458403375986034e-51, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5145 finished with score 1100.0, result : lose board : [[  8.  32.   2. 128.]\n",
            " [  2.   8.  32.   8.]\n",
            " [  4.   2.  16.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 7.180011534372007e-53, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 125, Loss : 0.2663143575191498\n",
            "Mini-Batch - 1 Back-Prop : 125, Loss : 0.21600396931171417\n",
            "Mini-Batch - 2 Back-Prop : 125, Loss : 0.2264852523803711\n",
            "Mini-Batch - 3 Back-Prop : 125, Loss : 0.2604072690010071\n",
            "Mini-Batch - 4 Back-Prop : 125, Loss : 0.2194824367761612\n",
            "Mini-Batch - 5 Back-Prop : 125, Loss : 0.286367267370224\n",
            "Mini-Batch - 6 Back-Prop : 125, Loss : 0.2537589967250824\n",
            "Mini-Batch - 7 Back-Prop : 125, Loss : 0.2683045268058777\n",
            "Mini-Batch - 8 Back-Prop : 125, Loss : 0.3007552921772003\n",
            "Episode 5150 finished with score 1284.0, result : lose board : [[ 8. 64. 16. 64.]\n",
            " [ 4. 16. 64. 16.]\n",
            " [ 2. 32. 16.  4.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 5.774886106127812e-55, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5155 finished with score 2104.0, result : lose board : [[2.0, 8.0, 32.0, 128.0], [4.0, 64.0, 8.0, 4.0], [16.0, 128.0, 4.0, 16.0], [8.0, 4.0, 8.0, 2]], epsilon  : 2.20177518572195e-56, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5160 finished with score 1664.0, result : lose board : [[16.0, 4.0, 64.0, 128.0], [8.0, 16.0, 2.0, 64.0], [2, 4.0, 16.0, 32.0], [4.0, 16.0, 4, 2]], epsilon  : 1.7445887558407698e-58, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5165 finished with score 1504.0, result : lose board : [[32.0, 64.0, 128.0, 16.0], [8.0, 16.0, 32.0, 4.0], [2, 4.0, 8.0, 16.0], [4, 2, 16.0, 2]], epsilon  : 1.1007656176610889e-59, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5170 finished with score 3832.0, result : lose board : [[16.0, 4.0, 128.0, 2.0], [2.0, 64.0, 4.0, 128.0], [4.0, 16.0, 32.0, 256.0], [2, 4.0, 16.0, 2.0]], epsilon  : 1.2552708980861954e-61, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5175 finished with score 2900.0, result : lose board : [[  2.  32.   2.   4.]\n",
            " [  8.  16. 128. 256.]\n",
            " [  4.  32.  16.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 2.1016811062728482e-63, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 126, Loss : 0.2386396825313568\n",
            "Mini-Batch - 1 Back-Prop : 126, Loss : 0.28673088550567627\n",
            "Mini-Batch - 2 Back-Prop : 126, Loss : 0.30418115854263306\n",
            "Mini-Batch - 3 Back-Prop : 126, Loss : 0.2450292706489563\n",
            "Mini-Batch - 4 Back-Prop : 126, Loss : 0.22931097447872162\n",
            "Mini-Batch - 5 Back-Prop : 126, Loss : 0.24910475313663483\n",
            "Mini-Batch - 6 Back-Prop : 126, Loss : 0.2967796325683594\n",
            "Mini-Batch - 7 Back-Prop : 126, Loss : 0.309987336397171\n",
            "Mini-Batch - 8 Back-Prop : 126, Loss : 0.29120737314224243\n",
            "Episode 5180 finished with score 888.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 16. 64.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 7.398426802531347e-65, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5185 finished with score 1464.0, result : lose board : [[ 32. 128.   2.   4.]\n",
            " [  8.   2.  32.  64.]\n",
            " [  4.  32.   8.   2.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 1.0559777436205767e-66, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5190 finished with score 1292.0, result : lose board : [[  4.   8. 128.   2.]\n",
            " [ 16.  64.   4.   8.]\n",
            " [  4.   2.  32.   4.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 2.457220899317351e-68, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5195 finished with score 1108.0, result : lose board : [[  4.  32. 128.   8.]\n",
            " [  2.   4.   2.  32.]\n",
            " [  8.   2.  16.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 6.640724889304331e-70, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5200 finished with score 2928.0, result : lose board : [[2.0, 16.0, 4.0, 2.0], [16.0, 128.0, 256.0, 32.0], [8.0, 16.0, 32.0, 8.0], [2, 4, 8.0, 2.0]], epsilon  : 1.0844625015748907e-71, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5205 finished with score 600.0, result : lose board : [[4.0, 16.0, 4.0, 64.0], [2.0, 4.0, 32.0, 16.0], [4.0, 16.0, 8.0, 4.0], [2, 8.0, 4, 2]], epsilon  : 3.353277503423829e-73, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5210 finished with score 788.0, result : lose board : [[16.0, 32.0, 2.0, 32.0], [8.0, 64.0, 8.0, 4.0], [4.0, 32.0, 4.0, 8.0], [2, 8.0, 2, 4]], epsilon  : 1.7504952453559425e-74, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 127, Loss : 0.2830137312412262\n",
            "Mini-Batch - 1 Back-Prop : 127, Loss : 0.2079380601644516\n",
            "Mini-Batch - 2 Back-Prop : 127, Loss : 0.24281466007232666\n",
            "Mini-Batch - 3 Back-Prop : 127, Loss : 0.24679142236709595\n",
            "Mini-Batch - 4 Back-Prop : 127, Loss : 0.26346561312675476\n",
            "Mini-Batch - 5 Back-Prop : 127, Loss : 0.2651830315589905\n",
            "Mini-Batch - 6 Back-Prop : 127, Loss : 0.23840247094631195\n",
            "Mini-Batch - 7 Back-Prop : 127, Loss : 0.2298499494791031\n",
            "Mini-Batch - 8 Back-Prop : 127, Loss : 0.27258479595184326\n",
            "Episode 5215 finished with score 676.0, result : lose board : [[2.0, 4.0, 64.0, 4.0], [4.0, 16.0, 32.0, 8.0], [2.0, 8.0, 16.0, 32.0], [4.0, 2.0, 4.0, 2]], epsilon  : 2.858643422845557e-76, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5220 finished with score 1044.0, result : lose board : [[16. 32. 64.  2.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  8. 16.  8.]\n",
            " [ 2.  4.  2.  4.]], epsilon  : 5.531018829603369e-78, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5225 finished with score 1580.0, result : lose board : [[ 32.   4.   2.  64.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   8. 128.  32.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 8.465359088980196e-80, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5230 finished with score 996.0, result : lose board : [[2.0, 64.0, 2.0, 64.0], [16.0, 32.0, 8.0, 4.0], [4.0, 16.0, 32.0, 8.0], [8.0, 4.0, 2, 4]], epsilon  : 4.1210886851539873e-81, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5235 finished with score 828.0, result : lose board : [[32.  2. 16.  2.]\n",
            " [ 8. 64.  4. 32.]\n",
            " [ 4. 16. 32.  8.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 1.2553612850527836e-82, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5240 finished with score 1048.0, result : lose board : [[  2.  16.  32. 128.]\n",
            " [  4.   2.   4.  16.]\n",
            " [  2.  16.   8.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 3.0099171197721583e-84, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 128, Loss : 0.244994655251503\n",
            "Mini-Batch - 1 Back-Prop : 128, Loss : 0.2273973971605301\n",
            "Mini-Batch - 2 Back-Prop : 128, Loss : 0.20117120444774628\n",
            "Mini-Batch - 3 Back-Prop : 128, Loss : 0.22792470455169678\n",
            "Mini-Batch - 4 Back-Prop : 128, Loss : 0.22107812762260437\n",
            "Mini-Batch - 5 Back-Prop : 128, Loss : 0.2243095487356186\n",
            "Mini-Batch - 6 Back-Prop : 128, Loss : 0.23814433813095093\n",
            "Mini-Batch - 7 Back-Prop : 128, Loss : 0.23862096667289734\n",
            "Mini-Batch - 8 Back-Prop : 128, Loss : 0.240766704082489\n",
            "Episode 5245 finished with score 2276.0, result : lose board : [[2.0, 64.0, 4.0, 128.0], [16.0, 2.0, 128.0, 2.0], [4.0, 8.0, 32.0, 64.0], [2, 4.0, 8.0, 2.0]], epsilon  : 1.291365076670073e-86, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode : 5249, Score : 5652.0, Iters : 400, Finish : Game not over\n",
            "Episode 5250 finished with score 452.0, result : lose board : [[4.0, 2.0, 8.0, 32.0], [8.0, 4.0, 32.0, 2.0], [4.0, 32.0, 2.0, 16.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.8666031372648626e-89, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5255 finished with score 1184.0, result : lose board : [[8.0, 16.0, 32.0, 128.0], [2.0, 4.0, 2.0, 32.0], [4.0, 8.0, 16.0, 8.0], [2, 16.0, 4, 2]], epsilon  : 1.0935859830250365e-90, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5260 finished with score 3000.0, result : lose board : [[16.0, 64.0, 2.0, 256.0], [4.0, 2.0, 128.0, 2.0], [2, 4.0, 8.0, 16.0], [4, 8, 16.0, 4]], epsilon  : 2.5574575417599244e-92, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5265 finished with score 1388.0, result : lose board : [[16.0, 4.0, 64.0, 128.0], [2, 8.0, 32.0, 4.0], [4.0, 32.0, 4, 2], [2, 8.0, 2, 4]], epsilon  : 6.318159845278484e-94, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5270 finished with score 1288.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [8.0, 16.0, 32.0, 64.0], [2.0, 64.0, 2, 4], [4.0, 2.0, 4.0, 2.0]], epsilon  : 2.433056992536436e-95, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5275 finished with score 1204.0, result : lose board : [[16.0, 8.0, 32.0, 128.0], [8.0, 16.0, 4.0, 32.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 5.746982873956573e-97, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 129, Loss : 0.21044065058231354\n",
            "Mini-Batch - 1 Back-Prop : 129, Loss : 0.2980648875236511\n",
            "Mini-Batch - 2 Back-Prop : 129, Loss : 0.2562989890575409\n",
            "Mini-Batch - 3 Back-Prop : 129, Loss : 0.30787110328674316\n",
            "Mini-Batch - 4 Back-Prop : 129, Loss : 0.2569679617881775\n",
            "Mini-Batch - 5 Back-Prop : 129, Loss : 0.23885974287986755\n",
            "Mini-Batch - 6 Back-Prop : 129, Loss : 0.2279464602470398\n",
            "Mini-Batch - 7 Back-Prop : 129, Loss : 0.2751181125640869\n",
            "Mini-Batch - 8 Back-Prop : 129, Loss : 0.2622242569923401\n",
            "Episode 5280 finished with score 2324.0, result : lose board : [[  2.   4.  32. 256.]\n",
            " [  8.   2.  16.  64.]\n",
            " [  4.  16.   8.   2.]\n",
            " [  2.   8.   2.   8.]], epsilon  : 1.0578508417619312e-98, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5285 finished with score 1696.0, result : lose board : [[16.0, 64.0, 4.0, 32.0], [8.0, 4.0, 128.0, 16.0], [4.0, 8.0, 64.0, 8.0], [2, 16.0, 4, 2]], epsilon  : 5.297449807878476e-101, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5290 finished with score 808.0, result : lose board : [[ 2. 32. 64. 32.]\n",
            " [ 8. 16.  4.  2.]\n",
            " [ 2.  8. 32. 16.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 9.558442601852227e-103, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5295 finished with score 2564.0, result : lose board : [[16.0, 32.0, 256.0, 4.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 16.0]], epsilon  : 1.2286133305613197e-104, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5300 finished with score 1508.0, result : lose board : [[2.0, 64.0, 4.0, 2], [8.0, 4.0, 128.0, 32.0], [4.0, 16.0, 32.0, 8.0], [2, 32.0, 4, 2]], epsilon  : 8.810774459458084e-107, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 130, Loss : 0.21916186809539795\n",
            "Mini-Batch - 1 Back-Prop : 130, Loss : 0.21557432413101196\n",
            "Mini-Batch - 2 Back-Prop : 130, Loss : 0.22369913756847382\n",
            "Mini-Batch - 3 Back-Prop : 130, Loss : 0.2570275664329529\n",
            "Mini-Batch - 4 Back-Prop : 130, Loss : 0.2480594962835312\n",
            "Mini-Batch - 5 Back-Prop : 130, Loss : 0.23779305815696716\n",
            "Mini-Batch - 6 Back-Prop : 130, Loss : 0.2658138871192932\n",
            "Mini-Batch - 7 Back-Prop : 130, Loss : 0.2409866750240326\n",
            "Mini-Batch - 8 Back-Prop : 130, Loss : 0.2424674779176712\n",
            "Episode 5305 finished with score 2540.0, result : lose board : [[16.0, 32.0, 64.0, 256.0], [4.0, 16.0, 2.0, 16.0], [2.0, 32.0, 8.0, 4.0], [16.0, 8, 4, 2]], epsilon  : 1.5199867929249473e-108, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5310 finished with score 1728.0, result : lose board : [[2.0, 64.0, 2.0, 4.0], [8.0, 32.0, 128.0, 64.0], [4.0, 8.0, 32.0, 16.0], [2, 4.0, 16.0, 4.0]], epsilon  : 1.7594648865279612e-110, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5315 finished with score 852.0, result : lose board : [[8.0, 2.0, 64.0, 2.0], [4.0, 8.0, 16.0, 64.0], [2.0, 4.0, 8.0, 32.0], [8.0, 2.0, 4.0, 2]], epsilon  : 8.2303572275752775e-112, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5320 finished with score 788.0, result : lose board : [[8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 64.0], [2.0, 4.0, 8.0, 2.0], [4, 2.0, 4.0, 8.0]], epsilon  : 2.2022055375866004e-113, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5325 finished with score 3120.0, result : lose board : [[ 16.  32.   4.   2.]\n",
            " [  8.  16. 256. 128.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 2.2058849065678368e-115, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5330 finished with score 2608.0, result : lose board : [[16.0, 4.0, 64.0, 4.0], [8.0, 64.0, 256.0, 16.0], [4.0, 8.0, 16.0, 8.0], [2.0, 16.0, 8.0, 2]], epsilon  : 3.960381957995433e-117, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5335 finished with score 1712.0, result : lose board : [[8.0, 32.0, 64.0, 128.0], [4.0, 8.0, 32.0, 64.0], [2.0, 4.0, 16.0, 4.0], [4, 2, 8, 2]], epsilon  : 1.46544745937089e-118, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 131, Loss : 0.23794780671596527\n",
            "Mini-Batch - 1 Back-Prop : 131, Loss : 0.25008413195610046\n",
            "Mini-Batch - 2 Back-Prop : 131, Loss : 0.21198512613773346\n",
            "Mini-Batch - 3 Back-Prop : 131, Loss : 0.2801011800765991\n",
            "Mini-Batch - 4 Back-Prop : 131, Loss : 0.23246793448925018\n",
            "Mini-Batch - 5 Back-Prop : 131, Loss : 0.28061339259147644\n",
            "Mini-Batch - 6 Back-Prop : 131, Loss : 0.27505043148994446\n",
            "Mini-Batch - 7 Back-Prop : 131, Loss : 0.23631057143211365\n",
            "Mini-Batch - 8 Back-Prop : 131, Loss : 0.20401662588119507\n",
            "Episode 5340 finished with score 1636.0, result : lose board : [[ 16.  32. 128.   8.]\n",
            " [  8.  16.  32.  64.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.310866666151782e-120, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5345 finished with score 1060.0, result : lose board : [[16.0, 32.0, 2.0, 64.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 4]], epsilon  : 1.0918854427284834e-121, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5350 finished with score 1376.0, result : lose board : [[ 16.   4. 128.  16.]\n",
            " [  8.  64.  16.   4.]\n",
            " [  4.   8.   2.  32.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 5.991411292403284e-123, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5355 finished with score 2808.0, result : lose board : [[4.0, 2.0, 32.0, 2.0], [2.0, 8.0, 128.0, 8.0], [8.0, 256.0, 32.0, 2.0], [2, 4.0, 16.0, 4.0]], epsilon  : 8.340924849805573e-125, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5360 finished with score 1608.0, result : lose board : [[32.0, 128.0, 2.0, 32.0], [4.0, 8.0, 64.0, 16.0], [8.0, 32.0, 16.0, 4.0], [2, 4, 8.0, 16.0]], epsilon  : 1.0828652532326596e-126, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5365 finished with score 1252.0, result : lose board : [[2.0, 8.0, 4.0, 32.0], [8.0, 32.0, 128.0, 4.0], [4.0, 8.0, 16.0, 32.0], [2, 16, 4, 2]], epsilon  : 3.1069799290966456e-128, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 132, Loss : 0.21928715705871582\n",
            "Mini-Batch - 1 Back-Prop : 132, Loss : 0.19336621463298798\n",
            "Mini-Batch - 2 Back-Prop : 132, Loss : 0.24945002794265747\n",
            "Mini-Batch - 3 Back-Prop : 132, Loss : 0.26803743839263916\n",
            "Mini-Batch - 4 Back-Prop : 132, Loss : 0.2394469976425171\n",
            "Mini-Batch - 5 Back-Prop : 132, Loss : 0.23313625156879425\n",
            "Mini-Batch - 6 Back-Prop : 132, Loss : 0.20750939846038818\n",
            "Mini-Batch - 7 Back-Prop : 132, Loss : 0.20632679760456085\n",
            "Mini-Batch - 8 Back-Prop : 132, Loss : 0.2440805435180664\n",
            "Episode 5370 finished with score 660.0, result : lose board : [[16.  4. 32. 64.]\n",
            " [ 4. 32.  2. 16.]\n",
            " [ 2.  4.  8.  4.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 7.338817174040294e-130, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5375 finished with score 840.0, result : lose board : [[ 2.  4. 32. 64.]\n",
            " [32.  2. 16.  4.]\n",
            " [ 4. 16. 32.  2.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 2.911951331298009e-131, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5380 finished with score 2380.0, result : lose board : [[16.0, 2.0, 256.0, 8.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 3.4045289017472748e-133, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5385 finished with score 540.0, result : lose board : [[ 2. 16.  2. 32.]\n",
            " [ 4. 32.  4.  2.]\n",
            " [16.  8. 32. 16.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 4.419948767928797e-135, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5390 finished with score 972.0, result : lose board : [[8.0, 2.0, 16.0, 64.0], [2.0, 16.0, 64.0, 8.0], [4.0, 2.0, 16.0, 32.0], [2, 4.0, 8.0, 16.0]], epsilon  : 7.437254734866091e-137, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5395 finished with score 1244.0, result : lose board : [[  2.  16.   2. 128.]\n",
            " [ 32.   4.  32.   8.]\n",
            " [  4.  32.  16.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 1.045754771996983e-138, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5400 finished with score 1576.0, result : lose board : [[4, 2, 16.0, 128.0], [2.0, 64.0, 4.0, 2], [4.0, 2.0, 32.0, 64.0], [8.0, 16.0, 4.0, 2.0]], epsilon  : 3.433029630384673e-140, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 133, Loss : 0.2523308992385864\n",
            "Mini-Batch - 1 Back-Prop : 133, Loss : 0.2929413318634033\n",
            "Mini-Batch - 2 Back-Prop : 133, Loss : 0.2220381200313568\n",
            "Mini-Batch - 3 Back-Prop : 133, Loss : 0.23171323537826538\n",
            "Mini-Batch - 4 Back-Prop : 133, Loss : 0.22316479682922363\n",
            "Mini-Batch - 5 Back-Prop : 133, Loss : 0.206180140376091\n",
            "Mini-Batch - 6 Back-Prop : 133, Loss : 0.17395922541618347\n",
            "Mini-Batch - 7 Back-Prop : 133, Loss : 0.22902101278305054\n",
            "Mini-Batch - 8 Back-Prop : 133, Loss : 0.22970351576805115\n",
            "Episode 5405 finished with score 180.0, result : lose board : [[4.0, 8.0, 16.0, 2.0], [2.0, 4.0, 8.0, 16.0], [4, 8.0, 4, 2], [2, 4, 8.0, 4]], epsilon  : 2.600776858597523e-142, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5410 finished with score 1524.0, result : lose board : [[64.0, 4.0, 128.0, 16.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 2.0, 4.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.060762475985523e-144, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5415 finished with score 1428.0, result : lose board : [[16.0, 32.0, 128.0, 2.0], [32.0, 4.0, 2.0, 8.0], [4.0, 16.0, 8.0, 64.0], [8.0, 2.0, 4.0, 2]], epsilon  : 5.040495618345024e-146, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5420 finished with score 348.0, result : lose board : [[4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0], [4.0, 16.0, 4.0, 2], [2, 4, 16, 4]], epsilon  : 2.1446486313384255e-147, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5425 finished with score 984.0, result : lose board : [[8.0, 2.0, 16.0, 64.0], [2.0, 16.0, 64.0, 32.0], [4.0, 8.0, 16.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 8.136162939093688e-149, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5430 finished with score 396.0, result : lose board : [[2.0, 8.0, 16.0, 32.0], [8.0, 32.0, 4.0, 2.0], [2, 4.0, 16.0, 8.0], [4, 8.0, 2, 4]], epsilon  : 9.049653127331163e-151, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 134, Loss : 0.27143731713294983\n",
            "Mini-Batch - 1 Back-Prop : 134, Loss : 0.23296086490154266\n",
            "Mini-Batch - 2 Back-Prop : 134, Loss : 0.22077207267284393\n",
            "Mini-Batch - 3 Back-Prop : 134, Loss : 0.20902188122272491\n",
            "Mini-Batch - 4 Back-Prop : 134, Loss : 0.21089717745780945\n",
            "Mini-Batch - 5 Back-Prop : 134, Loss : 0.29300472140312195\n",
            "Mini-Batch - 6 Back-Prop : 134, Loss : 0.25549614429473877\n",
            "Mini-Batch - 7 Back-Prop : 134, Loss : 0.24782897531986237\n",
            "Mini-Batch - 8 Back-Prop : 134, Loss : 0.2328709363937378\n",
            "Episode 5435 finished with score 2156.0, result : lose board : [[16.0, 32.0, 256.0, 4.0], [4.0, 16.0, 32.0, 8.0], [2, 4.0, 16.0, 2.0], [4.0, 2.0, 4.0, 16.0]], epsilon  : 3.793295326026086e-152, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5440 finished with score 432.0, result : lose board : [[8.0, 16.0, 32.0, 4.0], [2.0, 4.0, 16.0, 32.0], [4, 2, 8, 16.0], [2, 4, 2, 8.0]], epsilon  : 4.412894119374515e-154, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5445 finished with score 2480.0, result : lose board : [[ 32.   4.   8. 256.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.  64.   2.  16.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 6.236009487921727e-156, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5450 finished with score 1540.0, result : lose board : [[  2.  16. 128.   4.]\n",
            " [  8.  32.  16.  64.]\n",
            " [  2.  16.   8.  32.]\n",
            " [ 16.   8.   2.   4.]], epsilon  : 1.7626764871972228e-157, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5455 finished with score 2016.0, result : lose board : [[16.0, 32.0, 128.0, 8.0], [4.0, 2.0, 8.0, 128.0], [2.0, 8.0, 2.0, 64.0], [4, 2, 8.0, 2]], epsilon  : 4.716412439637227e-159, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5460 finished with score 1588.0, result : lose board : [[  8.  64. 128.   2.]\n",
            " [  4.  32.  64.   8.]\n",
            " [  2.   4.  16.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 1.1827477705799304e-160, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 135, Loss : 0.2174796760082245\n",
            "Mini-Batch - 1 Back-Prop : 135, Loss : 0.20220017433166504\n",
            "Mini-Batch - 2 Back-Prop : 135, Loss : 0.22540457546710968\n",
            "Mini-Batch - 3 Back-Prop : 135, Loss : 0.22344228625297546\n",
            "Mini-Batch - 4 Back-Prop : 135, Loss : 0.24276971817016602\n",
            "Mini-Batch - 5 Back-Prop : 135, Loss : 0.22735440731048584\n",
            "Mini-Batch - 6 Back-Prop : 135, Loss : 0.22173373401165009\n",
            "Mini-Batch - 7 Back-Prop : 135, Loss : 0.22255384922027588\n",
            "Mini-Batch - 8 Back-Prop : 135, Loss : 0.22305455803871155\n",
            "Episode 5465 finished with score 1496.0, result : lose board : [[16.0, 32.0, 64.0, 4.0], [8.0, 16.0, 128.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 4]], epsilon  : 1.7568553908786536e-162, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5470 finished with score 1316.0, result : lose board : [[16.0, 4.0, 8.0, 128.0], [2.0, 16.0, 64.0, 32.0], [4.0, 8.0, 2.0, 8.0], [2, 4.0, 8.0, 2.0]], epsilon  : 5.942649045668868e-164, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5475 finished with score 1264.0, result : lose board : [[  8.   2.   8.  32.]\n",
            " [  2.   8.   2. 128.]\n",
            " [  4.  16.  64.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 1.5742986542326596e-165, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5480 finished with score 1740.0, result : lose board : [[16.0, 64.0, 128.0, 16.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8, 2]], epsilon  : 2.702382330746771e-167, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5485 finished with score 1360.0, result : lose board : [[4.0, 2.0, 128.0, 2.0], [32.0, 64.0, 8.0, 32.0], [2, 4.0, 16.0, 2.0], [4, 2, 8.0, 4]], epsilon  : 7.52513770214698e-169, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5490 finished with score 1472.0, result : lose board : [[ 16.  32.  64.   2.]\n",
            " [  8.  16. 128.   8.]\n",
            " [  4.   8.   2.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 1.0372116893983918e-170, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5495 finished with score 1268.0, result : lose board : [[  2.  64.   8.   2.]\n",
            " [  8.   4. 128.   8.]\n",
            " [  4.   2.  32.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.156785071467928e-172, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 136, Loss : 0.18460455536842346\n",
            "Mini-Batch - 1 Back-Prop : 136, Loss : 0.1958335041999817\n",
            "Mini-Batch - 2 Back-Prop : 136, Loss : 0.23973429203033447\n",
            "Mini-Batch - 3 Back-Prop : 136, Loss : 0.28213730454444885\n",
            "Mini-Batch - 4 Back-Prop : 136, Loss : 0.22110366821289062\n",
            "Mini-Batch - 5 Back-Prop : 136, Loss : 0.24694550037384033\n",
            "Mini-Batch - 6 Back-Prop : 136, Loss : 0.27453142404556274\n",
            "Mini-Batch - 7 Back-Prop : 136, Loss : 0.2487141191959381\n",
            "Mini-Batch - 8 Back-Prop : 136, Loss : 0.22420135140419006\n",
            "Episode 5500 finished with score 2464.0, result : lose board : [[ 16.  32.   2. 256.]\n",
            " [ 64.  16.   4.   2.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.226498835942059e-174, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5505 finished with score 2420.0, result : lose board : [[  2.   8.  32. 256.]\n",
            " [ 16.  32.  16.  32.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 1.4439659241939838e-175, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5510 finished with score 764.0, result : lose board : [[16.0, 2.0, 16.0, 2.0], [8.0, 32.0, 64.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.398592354245471e-177, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5515 finished with score 464.0, result : lose board : [[8.0, 16.0, 4.0, 16.0], [4.0, 8.0, 32.0, 8.0], [2.0, 32.0, 8.0, 2.0], [4, 2.0, 16.0, 4.0]], epsilon  : 2.2173932586152967e-178, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5520 finished with score 2516.0, result : lose board : [[16.0, 32.0, 128.0, 2.0], [8.0, 16.0, 64.0, 128.0], [2.0, 4.0, 32.0, 64.0], [4, 2, 8.0, 16.0]], epsilon  : 1.3488434456297937e-180, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5525 finished with score 4184.0, result : lose board : [[ 16.  32. 256.   4.]\n",
            " [  8.  16.  32. 256.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.  32.   4.]], epsilon  : 6.822382804147988e-183, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 137, Loss : 0.252964049577713\n",
            "Mini-Batch - 1 Back-Prop : 137, Loss : 0.26353657245635986\n",
            "Mini-Batch - 2 Back-Prop : 137, Loss : 0.25888651609420776\n",
            "Mini-Batch - 3 Back-Prop : 137, Loss : 0.20944419503211975\n",
            "Mini-Batch - 4 Back-Prop : 137, Loss : 0.23106777667999268\n",
            "Mini-Batch - 5 Back-Prop : 137, Loss : 0.23490014672279358\n",
            "Mini-Batch - 6 Back-Prop : 137, Loss : 0.2388884723186493\n",
            "Mini-Batch - 7 Back-Prop : 137, Loss : 0.23775170743465424\n",
            "Mini-Batch - 8 Back-Prop : 137, Loss : 0.25690120458602905\n",
            "Episode 5530 finished with score 440.0, result : lose board : [[16.  4. 32.  4.]\n",
            " [ 8.  2.  8. 32.]\n",
            " [ 4. 16.  4. 16.]\n",
            " [ 2.  4.  2.  8.]], epsilon  : 1.587543081354867e-184, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5535 finished with score 2392.0, result : lose board : [[4.0, 16.0, 2.0, 256.0], [16.0, 4.0, 64.0, 16.0], [8.0, 32.0, 8.0, 4.0], [2, 4.0, 16.0, 2.0]], epsilon  : 1.6141678893647316e-186, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5540 finished with score 1436.0, result : lose board : [[16.0, 2.0, 4.0, 128.0], [8.0, 32.0, 64.0, 4.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 2.137829968253144e-188, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5545 finished with score 1596.0, result : lose board : [[ 16.  32.  64.   8.]\n",
            " [  8.  16.  32. 128.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 1.4368559111103245e-190, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5550 finished with score 2216.0, result : lose board : [[ 16.  32.   4.  16.]\n",
            " [  8.  16. 128.   2.]\n",
            " [  4.   8.  64. 128.]\n",
            " [  2.   4.   8.  32.]], epsilon  : 6.721269360667755e-192, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5555 finished with score 2388.0, result : lose board : [[2.0, 32.0, 2.0, 4.0], [8.0, 256.0, 32.0, 2.0], [4.0, 8.0, 2.0, 64.0], [2, 4.0, 16.0, 2.0]], epsilon  : 9.545542644357008e-194, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 138, Loss : 0.26516959071159363\n",
            "Mini-Batch - 1 Back-Prop : 138, Loss : 0.21357592940330505\n",
            "Mini-Batch - 2 Back-Prop : 138, Loss : 0.2591949701309204\n",
            "Mini-Batch - 3 Back-Prop : 138, Loss : 0.21741679310798645\n",
            "Mini-Batch - 4 Back-Prop : 138, Loss : 0.23593157529830933\n",
            "Mini-Batch - 5 Back-Prop : 138, Loss : 0.1896485984325409\n",
            "Mini-Batch - 6 Back-Prop : 138, Loss : 0.20105639100074768\n",
            "Mini-Batch - 7 Back-Prop : 138, Loss : 0.21537326276302338\n",
            "Mini-Batch - 8 Back-Prop : 138, Loss : 0.20152007043361664\n",
            "Episode 5560 finished with score 1844.0, result : lose board : [[2.0, 64.0, 128.0, 2.0], [16.0, 32.0, 64.0, 32.0], [4.0, 16.0, 32.0, 8.0], [2, 4.0, 8.0, 4.0]], epsilon  : 1.5981957882838827e-195, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5565 finished with score 1200.0, result : lose board : [[32.0, 2.0, 64.0, 4.0], [4.0, 64.0, 32.0, 64.0], [2, 4.0, 2.0, 8.0], [4, 2, 8, 2]], epsilon  : 1.3511665367030415e-197, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5570 finished with score 1820.0, result : lose board : [[4.0, 32.0, 2.0, 128.0], [8.0, 128.0, 4.0, 2.0], [4.0, 16.0, 32.0, 8.0], [2, 8.0, 4.0, 2]], epsilon  : 2.2735489143228838e-199, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5575 finished with score 1652.0, result : lose board : [[  8.  16.  64. 128.]\n",
            " [  4.   8.  32.  64.]\n",
            " [  2.   4.   8.   4.]\n",
            " [  4.   8.  16.   2.]], epsilon  : 7.767486249735901e-201, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5580 finished with score 2208.0, result : lose board : [[2.0, 8.0, 16.0, 4.0], [8.0, 32.0, 256.0, 32.0], [4.0, 2.0, 32.0, 8.0], [2, 4, 8.0, 2]], epsilon  : 1.0867549563640817e-202, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5585 finished with score 1284.0, result : lose board : [[ 2. 64.  8.  2.]\n",
            " [ 4. 32. 64.  4.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  2.  4.  8.]], epsilon  : 4.420994573910301e-204, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 139, Loss : 0.22270183265209198\n",
            "Mini-Batch - 1 Back-Prop : 139, Loss : 0.2280765324831009\n",
            "Mini-Batch - 2 Back-Prop : 139, Loss : 0.19983206689357758\n",
            "Mini-Batch - 3 Back-Prop : 139, Loss : 0.26205381751060486\n",
            "Mini-Batch - 4 Back-Prop : 139, Loss : 0.23548659682273865\n",
            "Mini-Batch - 5 Back-Prop : 139, Loss : 0.22832010686397552\n",
            "Mini-Batch - 6 Back-Prop : 139, Loss : 0.2371215969324112\n",
            "Mini-Batch - 7 Back-Prop : 139, Loss : 0.21929650008678436\n",
            "Mini-Batch - 8 Back-Prop : 139, Loss : 0.20360557734966278\n",
            "Episode 5590 finished with score 3008.0, result : lose board : [[ 16.  32. 128.  32.]\n",
            " [  8. 256.   2.  16.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 8.016897475658934e-206, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5595 finished with score 1452.0, result : lose board : [[4.0, 32.0, 128.0, 32.0], [2.0, 4.0, 64.0, 8.0], [4.0, 16.0, 2.0, 16.0], [2, 4.0, 16.0, 4.0]], epsilon  : 3.915781366632385e-208, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5600 finished with score 664.0, result : lose board : [[8.0, 16.0, 2.0, 64.0], [2.0, 4.0, 32.0, 16.0], [4.0, 2.0, 16.0, 8.0], [2, 16.0, 8, 2]], epsilon  : 2.3040683473569558e-209, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5605 finished with score 1524.0, result : lose board : [[2.0, 32.0, 64.0, 128.0], [8.0, 16.0, 2.0, 32.0], [2.0, 4.0, 32.0, 8.0], [4, 8.0, 4, 2]], epsilon  : 2.296435726571095e-211, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5610 finished with score 2748.0, result : lose board : [[ 16.  32.  64. 256.]\n",
            " [  4.   8.  32.  64.]\n",
            " [  2.   4.  16.   4.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 2.221349330008878e-213, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5615 finished with score 2436.0, result : lose board : [[2.0, 32.0, 2.0, 8.0], [8.0, 16.0, 256.0, 64.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8, 2]], epsilon  : 5.570539051392455e-215, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 140, Loss : 0.19649502635002136\n",
            "Mini-Batch - 1 Back-Prop : 140, Loss : 0.23497094213962555\n",
            "Mini-Batch - 2 Back-Prop : 140, Loss : 0.2101927250623703\n",
            "Mini-Batch - 3 Back-Prop : 140, Loss : 0.2626033127307892\n",
            "Mini-Batch - 4 Back-Prop : 140, Loss : 0.23313599824905396\n",
            "Mini-Batch - 5 Back-Prop : 140, Loss : 0.22484225034713745\n",
            "Mini-Batch - 6 Back-Prop : 140, Loss : 0.25756144523620605\n",
            "Mini-Batch - 7 Back-Prop : 140, Loss : 0.23251202702522278\n",
            "Mini-Batch - 8 Back-Prop : 140, Loss : 0.18557749688625336\n",
            "Episode 5620 finished with score 1412.0, result : lose board : [[  2.   4.   8. 128.]\n",
            " [  8.  32.  64.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 7.451673259955637e-217, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5625 finished with score 2368.0, result : lose board : [[  2.  16. 128.   2.]\n",
            " [  8.  32.  64. 128.]\n",
            " [  4.  64.   2.  16.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 1.0530210762582831e-218, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5630 finished with score 1736.0, result : lose board : [[  2.   4. 128.   2.]\n",
            " [ 16.  32.  64.   8.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 2.6406900292502037e-220, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5635 finished with score 3224.0, result : lose board : [[2.0, 8.0, 32.0, 64.0], [16.0, 128.0, 256.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8, 16.0]], epsilon  : 6.556403358168867e-222, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5640 finished with score 852.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 4. 16. 64.  8.]\n",
            " [ 8. 32.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 2.8035908501954834e-223, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5645 finished with score 1444.0, result : lose board : [[2, 8.0, 128.0, 2.0], [16.0, 32.0, 64.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 2, 8.0]], epsilon  : 2.908051309939072e-225, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 141, Loss : 0.24045750498771667\n",
            "Mini-Batch - 1 Back-Prop : 141, Loss : 0.19390727579593658\n",
            "Mini-Batch - 2 Back-Prop : 141, Loss : 0.23012889921665192\n",
            "Mini-Batch - 3 Back-Prop : 141, Loss : 0.1923288106918335\n",
            "Mini-Batch - 4 Back-Prop : 141, Loss : 0.17582790553569794\n",
            "Mini-Batch - 5 Back-Prop : 141, Loss : 0.1755039542913437\n",
            "Mini-Batch - 6 Back-Prop : 141, Loss : 0.2236117422580719\n",
            "Mini-Batch - 7 Back-Prop : 141, Loss : 0.1821974366903305\n",
            "Mini-Batch - 8 Back-Prop : 141, Loss : 0.1761682629585266\n",
            "Episode 5650 finished with score 1068.0, result : lose board : [[16.0, 32.0, 128.0, 4.0], [8.0, 16.0, 4.0, 2.0], [2.0, 8.0, 16.0, 8.0], [8, 4.0, 2, 4]], epsilon  : 2.2030664936778604e-227, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5655 finished with score 1192.0, result : lose board : [[2.0, 32.0, 64.0, 4.0], [8.0, 64.0, 4.0, 64.0], [4.0, 8.0, 16.0, 4.0], [2, 16.0, 4, 2]], epsilon  : 5.000192590109899e-229, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5660 finished with score 1172.0, result : lose board : [[4.0, 128.0, 4.0, 2.0], [32.0, 8.0, 2.0, 16.0], [8.0, 32.0, 16.0, 4.0], [2, 16.0, 4, 2]], epsilon  : 7.353574322238144e-231, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5665 finished with score 668.0, result : lose board : [[8.0, 16.0, 32.0, 64.0], [2, 4.0, 16.0, 4.0], [4, 2, 8.0, 16.0], [2, 4, 16.0, 2]], epsilon  : 1.466020378608009e-232, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5670 finished with score 2192.0, result : lose board : [[ 16.  32. 128.   2.]\n",
            " [  8.  16.  64. 128.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 5.9243644383344544e-235, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5675 finished with score 1272.0, result : lose board : [[  4.  16. 128.  32.]\n",
            " [  2.  32.  16.   4.]\n",
            " [  4.   8.   2.  32.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 1.1292464441695274e-236, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 142, Loss : 0.25143060088157654\n",
            "Mini-Batch - 1 Back-Prop : 142, Loss : 0.22568856179714203\n",
            "Mini-Batch - 2 Back-Prop : 142, Loss : 0.19956746697425842\n",
            "Mini-Batch - 3 Back-Prop : 142, Loss : 0.20496085286140442\n",
            "Mini-Batch - 4 Back-Prop : 142, Loss : 0.25369560718536377\n",
            "Mini-Batch - 5 Back-Prop : 142, Loss : 0.27825266122817993\n",
            "Mini-Batch - 6 Back-Prop : 142, Loss : 0.193775475025177\n",
            "Mini-Batch - 7 Back-Prop : 142, Loss : 0.1904776245355606\n",
            "Mini-Batch - 8 Back-Prop : 142, Loss : 0.22173543274402618\n",
            "Episode 5680 finished with score 1640.0, result : lose board : [[16.0, 2.0, 128.0, 4.0], [8.0, 64.0, 4.0, 16.0], [4.0, 32.0, 64.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 2.9915466043696046e-238, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5685 finished with score 1292.0, result : lose board : [[ 16.  32. 128.   8.]\n",
            " [ 32.   2.  16.   2.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.  16.   2.]], epsilon  : 5.160853169019765e-240, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5690 finished with score 324.0, result : lose board : [[ 2.  4. 16. 32.]\n",
            " [ 8. 16.  8. 16.]\n",
            " [ 4.  2.  4.  8.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 2.342951044190382e-241, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5695 finished with score 1504.0, result : lose board : [[ 16.   4.  64. 128.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 7.846485164502599e-243, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5700 finished with score 1776.0, result : lose board : [[16.0, 2.0, 128.0, 2.0], [2, 16.0, 4.0, 128.0], [4.0, 2.0, 16.0, 32.0], [2.0, 8.0, 2.0, 4.0]], epsilon  : 2.0683124086026e-244, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5705 finished with score 1604.0, result : lose board : [[ 16.   2.  64. 128.]\n",
            " [  8.   4.  16.   2.]\n",
            " [  4.  32.   8.  64.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 6.084297980400283e-246, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5710 finished with score 2836.0, result : lose board : [[4.0, 8.0, 32.0, 4.0], [2.0, 32.0, 4.0, 256.0], [4.0, 16.0, 128.0, 16.0], [2, 4, 2, 4.0]], epsilon  : 2.4587378943216956e-248, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 143, Loss : 0.219066321849823\n",
            "Mini-Batch - 1 Back-Prop : 143, Loss : 0.20833012461662292\n",
            "Mini-Batch - 2 Back-Prop : 143, Loss : 0.2411690056324005\n",
            "Mini-Batch - 3 Back-Prop : 143, Loss : 0.20747560262680054\n",
            "Mini-Batch - 4 Back-Prop : 143, Loss : 0.2407381534576416\n",
            "Mini-Batch - 5 Back-Prop : 143, Loss : 0.25030818581581116\n",
            "Mini-Batch - 6 Back-Prop : 143, Loss : 0.21209558844566345\n",
            "Mini-Batch - 7 Back-Prop : 143, Loss : 0.22709327936172485\n",
            "Mini-Batch - 8 Back-Prop : 143, Loss : 0.2298273742198944\n",
            "Episode : 5712, Score : 6040.0, Iters : 400, Finish : Game not over\n",
            "Episode 5715 finished with score 1440.0, result : lose board : [[16.0, 64.0, 128.0, 8.0], [8.0, 4.0, 32.0, 2.0], [4.0, 2.0, 16.0, 32.0], [2.0, 8.0, 4.0, 2]], epsilon  : 7.628035765187113e-251, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5720 finished with score 1596.0, result : lose board : [[  4. 128.   4.   2.]\n",
            " [  8.  64.  16.  64.]\n",
            " [  4.   8.  32.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 3.445786537015121e-252, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5725 finished with score 1844.0, result : lose board : [[  2.  16.  32.   2.]\n",
            " [  8.  32. 128.   4.]\n",
            " [  4.   2.  16. 128.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 1.5643361476393615e-253, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5730 finished with score 2104.0, result : lose board : [[16.0, 64.0, 4.0, 128.0], [2.0, 8.0, 128.0, 16.0], [4.0, 32.0, 16.0, 4.0], [2, 8, 4.0, 2]], epsilon  : 7.101854849461964e-255, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5735 finished with score 976.0, result : lose board : [[16.0, 4.0, 16.0, 64.0], [4.0, 16.0, 64.0, 8.0], [2, 8.0, 16.0, 32.0], [4.0, 2.0, 8.0, 2]], epsilon  : 2.4142482254694386e-256, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5740 finished with score 604.0, result : lose board : [[8.0, 16.0, 32.0, 64.0], [2.0, 4.0, 16.0, 4.0], [4.0, 2.0, 4.0, 2], [2, 4, 2, 16.0]], epsilon  : 1.3447209278578871e-257, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5745 finished with score 1648.0, result : lose board : [[  2.  32.   4.  64.]\n",
            " [ 16. 128.  64.  16.]\n",
            " [  4.  16.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 2.7485522275006107e-259, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 144, Loss : 0.24952296912670135\n",
            "Mini-Batch - 1 Back-Prop : 144, Loss : 0.2534586489200592\n",
            "Mini-Batch - 2 Back-Prop : 144, Loss : 0.21172234416007996\n",
            "Mini-Batch - 3 Back-Prop : 144, Loss : 0.1961463838815689\n",
            "Mini-Batch - 4 Back-Prop : 144, Loss : 0.20158961415290833\n",
            "Mini-Batch - 5 Back-Prop : 144, Loss : 0.19390203058719635\n",
            "Mini-Batch - 6 Back-Prop : 144, Loss : 0.2138005495071411\n",
            "Mini-Batch - 7 Back-Prop : 144, Loss : 0.265299528837204\n",
            "Mini-Batch - 8 Back-Prop : 144, Loss : 0.18624946475028992\n",
            "Episode 5750 finished with score 1288.0, result : lose board : [[2, 8.0, 32.0, 128.0], [16.0, 2.0, 4.0, 32.0], [4.0, 16.0, 32.0, 2.0], [2.0, 4.0, 8.0, 16.0]], epsilon  : 2.671976424726724e-261, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5755 finished with score 1692.0, result : lose board : [[  2.   8.  16. 128.]\n",
            " [  4.  32.  64.   8.]\n",
            " [  2.   8.  16.  64.]\n",
            " [  4.   2.   4.  16.]], epsilon  : 4.773322575538138e-263, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5760 finished with score 2556.0, result : lose board : [[ 16.  64.   4. 256.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.8776432199496165e-265, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5765 finished with score 1520.0, result : lose board : [[16.0, 32.0, 128.0, 16.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 32.0, 2.0], [2, 4.0, 16.0, 4]], epsilon  : 1.0851878184224704e-266, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode : 5768, Score : 5592.0, Iters : 400, Finish : Game not over\n",
            "Episode 5770 finished with score 1840.0, result : lose board : [[16.0, 32.0, 64.0, 128.0], [4.0, 8.0, 32.0, 64.0], [2.0, 4.0, 16.0, 32.0], [4, 2, 4, 2]], epsilon  : 3.890641249083377e-269, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 145, Loss : 0.2285526543855667\n",
            "Mini-Batch - 1 Back-Prop : 145, Loss : 0.215437114238739\n",
            "Mini-Batch - 2 Back-Prop : 145, Loss : 0.20489493012428284\n",
            "Mini-Batch - 3 Back-Prop : 145, Loss : 0.21135923266410828\n",
            "Mini-Batch - 4 Back-Prop : 145, Loss : 0.2596507966518402\n",
            "Mini-Batch - 5 Back-Prop : 145, Loss : 0.2388199120759964\n",
            "Mini-Batch - 6 Back-Prop : 145, Loss : 0.21372568607330322\n",
            "Mini-Batch - 7 Back-Prop : 145, Loss : 0.23383308947086334\n",
            "Mini-Batch - 8 Back-Prop : 145, Loss : 0.2622281014919281\n",
            "Episode 5775 finished with score 1304.0, result : lose board : [[16.0, 32.0, 4.0, 64.0], [8.0, 16.0, 64.0, 4.0], [4.0, 8.0, 16.0, 64.0], [2, 4, 8, 16.0]], epsilon  : 7.233322746324799e-271, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5780 finished with score 2912.0, result : lose board : [[ 16.  32. 128.   2.]\n",
            " [  2.   4.  32. 256.]\n",
            " [  4.   8.   4.  16.]\n",
            " [  8.   4.   2.   8.]], epsilon  : 7.76940403518236e-273, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5785 finished with score 1532.0, result : lose board : [[  4.   2.  32.   4.]\n",
            " [  2.   4.  64. 128.]\n",
            " [ 32.  16.  32.   4.]\n",
            " [  4.   8.  16.   2.]], epsilon  : 1.2624689219220574e-274, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5790 finished with score 1212.0, result : lose board : [[4, 64.0, 128.0, 4], [8.0, 2.0, 4.0, 16.0], [4.0, 8.0, 16.0, 8.0], [2.0, 4.0, 8.0, 4.0]], epsilon  : 1.5827724188926467e-276, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5795 finished with score 860.0, result : lose board : [[2, 4.0, 64.0, 2.0], [8.0, 16.0, 32.0, 64.0], [4.0, 2.0, 4.0, 16.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 3.2838891510470324e-278, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5800 finished with score 792.0, result : lose board : [[16.0, 32.0, 2.0, 64.0], [4.0, 2.0, 32.0, 4.0], [2.0, 8.0, 16.0, 8.0], [4.0, 32.0, 2.0, 4]], epsilon  : 1.705744058893783e-279, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5805 finished with score 1340.0, result : lose board : [[ 16.   2.   4.   8.]\n",
            " [  8.  16. 128.   2.]\n",
            " [  4.   8.  64.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 7.666964542236871e-281, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 146, Loss : 0.19797749817371368\n",
            "Mini-Batch - 1 Back-Prop : 146, Loss : 0.23080381751060486\n",
            "Mini-Batch - 2 Back-Prop : 146, Loss : 0.1882813423871994\n",
            "Mini-Batch - 3 Back-Prop : 146, Loss : 0.23958562314510345\n",
            "Mini-Batch - 4 Back-Prop : 146, Loss : 0.19125258922576904\n",
            "Mini-Batch - 5 Back-Prop : 146, Loss : 0.22611472010612488\n",
            "Mini-Batch - 6 Back-Prop : 146, Loss : 0.24244806170463562\n",
            "Mini-Batch - 7 Back-Prop : 146, Loss : 0.2034565657377243\n",
            "Mini-Batch - 8 Back-Prop : 146, Loss : 0.18090441823005676\n",
            "Episode 5810 finished with score 768.0, result : lose board : [[8.0, 16.0, 64.0, 4.0], [2.0, 8.0, 4.0, 64.0], [4.0, 2.0, 16.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 1.2458232853152459e-282, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5815 finished with score 844.0, result : lose board : [[ 2. 32. 64. 32.]\n",
            " [16.  4. 32.  8.]\n",
            " [ 2. 16.  4.  2.]\n",
            " [ 4.  8.  2. 16.]], epsilon  : 1.8321802522288793e-284, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5820 finished with score 1296.0, result : lose board : [[ 16.  32. 128.  32.]\n",
            " [  8.  16.   4.   2.]\n",
            " [  2.   4.  16.  32.]\n",
            " [  4.   2.   8.   4.]], epsilon  : 1.3560757849981545e-285, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5825 finished with score 2812.0, result : lose board : [[2, 4.0, 16.0, 256.0], [32.0, 64.0, 32.0, 2.0], [16.0, 8.0, 16.0, 64.0], [4.0, 2.0, 4.0, 16.0]], epsilon  : 5.407643666259716e-287, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5830 finished with score 1460.0, result : lose board : [[ 16.   8.  64.   8.]\n",
            " [  8. 128.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 1.2646302432636068e-288, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5835 finished with score 2040.0, result : lose board : [[ 16.  32. 128.   4.]\n",
            " [  8.  16.  32. 128.]\n",
            " [  2.   8.  16.  32.]\n",
            " [  4.   2.   8.   4.]], epsilon  : 1.6093834341060477e-290, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 147, Loss : 0.23200370371341705\n",
            "Mini-Batch - 1 Back-Prop : 147, Loss : 0.2969929277896881\n",
            "Mini-Batch - 2 Back-Prop : 147, Loss : 0.21487776935100555\n",
            "Mini-Batch - 3 Back-Prop : 147, Loss : 0.23527495563030243\n",
            "Mini-Batch - 4 Back-Prop : 147, Loss : 0.20942533016204834\n",
            "Mini-Batch - 5 Back-Prop : 147, Loss : 0.22235813736915588\n",
            "Mini-Batch - 6 Back-Prop : 147, Loss : 0.18552064895629883\n",
            "Mini-Batch - 7 Back-Prop : 147, Loss : 0.2315438687801361\n",
            "Mini-Batch - 8 Back-Prop : 147, Loss : 0.22812633216381073\n",
            "Episode 5840 finished with score 2448.0, result : lose board : [[16.0, 64.0, 256.0, 32.0], [4.0, 16.0, 32.0, 4.0], [2, 4.0, 16.0, 2.0], [4.0, 8.0, 2, 4]], epsilon  : 2.7351873021154306e-292, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5845 finished with score 632.0, result : lose board : [[ 8. 16.  4. 32.]\n",
            " [ 4.  8. 64. 16.]\n",
            " [ 2.  4. 16.  4.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 4.837746535618407e-294, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5850 finished with score 1684.0, result : lose board : [[2.0, 4.0, 128.0, 2.0], [64.0, 32.0, 64.0, 8.0], [2.0, 8.0, 32.0, 2.0], [4, 2, 16.0, 4.0]], epsilon  : 8.429483488677157e-296, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5855 finished with score 1336.0, result : lose board : [[8.0, 32.0, 2.0, 128.0], [4.0, 16.0, 64.0, 8.0], [2, 4.0, 8.0, 4.0], [4.0, 8.0, 16.0, 2.0]], epsilon  : 9.612659715623816e-298, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5860 finished with score 1100.0, result : lose board : [[2.0, 64.0, 4.0, 2], [8.0, 32.0, 2.0, 64.0], [4.0, 64.0, 8.0, 4.0], [8.0, 2.0, 4.0, 2.0]], epsilon  : 2.0652660989690042e-299, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5865 finished with score 2568.0, result : lose board : [[ 16.  64. 256.  32.]\n",
            " [  8.  32.   2.  16.]\n",
            " [  4.   2.  32.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 2.8466165329542134e-301, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5870 finished with score 1172.0, result : lose board : [[16.0, 2.0, 32.0, 128.0], [2.0, 16.0, 8.0, 32.0], [4.0, 8.0, 4.0, 16.0], [2, 4.0, 8.0, 2.0]], epsilon  : 1.0692034011847836e-302, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 148, Loss : 0.20329506695270538\n",
            "Mini-Batch - 1 Back-Prop : 148, Loss : 0.2028222531080246\n",
            "Mini-Batch - 2 Back-Prop : 148, Loss : 0.2116064429283142\n",
            "Mini-Batch - 3 Back-Prop : 148, Loss : 0.21571402251720428\n",
            "Mini-Batch - 4 Back-Prop : 148, Loss : 0.23276737332344055\n",
            "Mini-Batch - 5 Back-Prop : 148, Loss : 0.17235028743743896\n",
            "Mini-Batch - 6 Back-Prop : 148, Loss : 0.2038581222295761\n",
            "Mini-Batch - 7 Back-Prop : 148, Loss : 0.2009718418121338\n",
            "Mini-Batch - 8 Back-Prop : 148, Loss : 0.23972663283348083\n",
            "Episode 5875 finished with score 2496.0, result : lose board : [[  2.  32. 256.   2.]\n",
            " [ 16.  64.  32.  16.]\n",
            " [  4.   8.  16.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 1.4302663208277306e-304, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5880 finished with score 1580.0, result : lose board : [[2.0, 4.0, 128.0, 2.0], [16.0, 32.0, 64.0, 8.0], [4.0, 16.0, 32.0, 2.0], [2, 4.0, 16.0, 32.0]], epsilon  : 1.3766179145025401e-306, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5885 finished with score 1308.0, result : lose board : [[4.0, 2.0, 64.0, 16.0], [2.0, 8.0, 128.0, 8.0], [4.0, 2.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 2.8561659153339765e-308, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5890 finished with score 1764.0, result : lose board : [[2.0, 8.0, 64.0, 128.0], [4.0, 32.0, 16.0, 8.0], [16.0, 8.0, 64.0, 2.0], [2, 4, 8, 32.0]], epsilon  : 2.9040668951772e-310, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5895 finished with score 1588.0, result : lose board : [[16.0, 32.0, 2.0, 128.0], [4.0, 16.0, 32.0, 64.0], [2, 4.0, 16.0, 32.0], [4.0, 8.0, 4, 2]], epsilon  : 6.025271641795e-312, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5900 finished with score 1156.0, result : lose board : [[  2.  32.   2.  16.]\n",
            " [  8.   2. 128.   8.]\n",
            " [  4.  16.  32.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 1.95835853274e-313, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 149, Loss : 0.20355050265789032\n",
            "Mini-Batch - 1 Back-Prop : 149, Loss : 0.1860738843679428\n",
            "Mini-Batch - 2 Back-Prop : 149, Loss : 0.21078580617904663\n",
            "Mini-Batch - 3 Back-Prop : 149, Loss : 0.25205472111701965\n",
            "Mini-Batch - 4 Back-Prop : 149, Loss : 0.21429041028022766\n",
            "Mini-Batch - 5 Back-Prop : 149, Loss : 0.27752482891082764\n",
            "Mini-Batch - 6 Back-Prop : 149, Loss : 0.2843579053878784\n",
            "Mini-Batch - 7 Back-Prop : 149, Loss : 0.20579306781291962\n",
            "Mini-Batch - 8 Back-Prop : 149, Loss : 0.19421041011810303\n",
            "Episode 5905 finished with score 752.0, result : lose board : [[16. 32.  4. 16.]\n",
            " [ 8. 16.  2.  8.]\n",
            " [ 4.  2. 32. 64.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.91102975e-315, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5910 finished with score 876.0, result : lose board : [[16. 32. 64.  4.]\n",
            " [ 8. 16. 32.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 1.90064203e-316, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5915 finished with score 1204.0, result : lose board : [[2, 8.0, 16.0, 2.0], [8.0, 16.0, 64.0, 8.0], [4.0, 64.0, 4.0, 64.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 2.25563e-318, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5920 finished with score 760.0, result : lose board : [[8.0, 32.0, 4.0, 32.0], [2.0, 8.0, 64.0, 4.0], [4, 2, 4, 16.0], [2, 4, 32, 2]], epsilon  : 5.0686e-320, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5925 finished with score 3116.0, result : lose board : [[16.0, 2.0, 16.0, 32.0], [8.0, 64.0, 256.0, 16.0], [4.0, 8.0, 128.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5930 finished with score 1276.0, result : lose board : [[  2.  32.   8.  32.]\n",
            " [  4.  16. 128.   2.]\n",
            " [ 16.   4.  16.  32.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 150, Loss : 0.18871089816093445\n",
            "Mini-Batch - 1 Back-Prop : 150, Loss : 0.17526505887508392\n",
            "Mini-Batch - 2 Back-Prop : 150, Loss : 0.202531635761261\n",
            "Mini-Batch - 3 Back-Prop : 150, Loss : 0.23124118149280548\n",
            "Mini-Batch - 4 Back-Prop : 150, Loss : 0.22906793653964996\n",
            "Mini-Batch - 5 Back-Prop : 150, Loss : 0.2356296330690384\n",
            "Mini-Batch - 6 Back-Prop : 150, Loss : 0.21639534831047058\n",
            "Mini-Batch - 7 Back-Prop : 150, Loss : 0.2058856189250946\n",
            "Mini-Batch - 8 Back-Prop : 150, Loss : 0.18842411041259766\n",
            "Episode 5935 finished with score 1184.0, result : lose board : [[  2.   4.  16.   4.]\n",
            " [  8. 128.   4.   8.]\n",
            " [  4.   8.  64.   2.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5940 finished with score 1292.0, result : lose board : [[ 16.   2. 128.  16.]\n",
            " [  4.  64.   2.   8.]\n",
            " [  8.  16.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5945 finished with score 2488.0, result : lose board : [[ 16.  32. 256.  32.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  4.   8.  16.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5950 finished with score 1324.0, result : lose board : [[2.0, 8.0, 2.0, 128.0], [8.0, 32.0, 64.0, 16.0], [4.0, 16.0, 4.0, 2], [8.0, 4, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5955 finished with score 2692.0, result : lose board : [[ 32.   2.   8.  64.]\n",
            " [  8.  64. 256.   2.]\n",
            " [  4.   8.  32.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 151, Loss : 0.20552973449230194\n",
            "Mini-Batch - 1 Back-Prop : 151, Loss : 0.2690183222293854\n",
            "Mini-Batch - 2 Back-Prop : 151, Loss : 0.2686830163002014\n",
            "Mini-Batch - 3 Back-Prop : 151, Loss : 0.20535056293010712\n",
            "Mini-Batch - 4 Back-Prop : 151, Loss : 0.2050313651561737\n",
            "Mini-Batch - 5 Back-Prop : 151, Loss : 0.19937625527381897\n",
            "Mini-Batch - 6 Back-Prop : 151, Loss : 0.22178034484386444\n",
            "Mini-Batch - 7 Back-Prop : 151, Loss : 0.21044722199440002\n",
            "Mini-Batch - 8 Back-Prop : 151, Loss : 0.2076394408941269\n",
            "Episode 5960 finished with score 3284.0, result : lose board : [[ 32.  64. 128. 256.]\n",
            " [  8.  32.   2.   4.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5965 finished with score 1316.0, result : lose board : [[ 16.  32.   4.  32.]\n",
            " [  4.  16. 128.  16.]\n",
            " [  8.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5970 finished with score 780.0, result : lose board : [[ 2.  8. 16. 64.]\n",
            " [ 8.  4.  8.  2.]\n",
            " [ 4.  2.  4. 64.]\n",
            " [ 2.  4. 16.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5975 finished with score 1352.0, result : lose board : [[2, 4.0, 8.0, 2.0], [4.0, 8.0, 128.0, 4.0], [16.0, 32.0, 64.0, 16.0], [2.0, 4.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5980 finished with score 1724.0, result : lose board : [[  8.  64. 128.   8.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.   8.  32.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5985 finished with score 992.0, result : lose board : [[2, 8.0, 64.0, 2.0], [16.0, 2.0, 32.0, 4.0], [4.0, 8.0, 16.0, 64.0], [2.0, 32.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 5990 finished with score 1652.0, result : lose board : [[16.0, 2.0, 4.0, 8.0], [8.0, 64.0, 128.0, 32.0], [4.0, 16.0, 64.0, 16.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 152, Loss : 0.22396442294120789\n",
            "Mini-Batch - 1 Back-Prop : 152, Loss : 0.23887936770915985\n",
            "Mini-Batch - 2 Back-Prop : 152, Loss : 0.220653235912323\n",
            "Mini-Batch - 3 Back-Prop : 152, Loss : 0.23190122842788696\n",
            "Mini-Batch - 4 Back-Prop : 152, Loss : 0.19922128319740295\n",
            "Mini-Batch - 5 Back-Prop : 152, Loss : 0.2659190595149994\n",
            "Mini-Batch - 6 Back-Prop : 152, Loss : 0.1881907433271408\n",
            "Mini-Batch - 7 Back-Prop : 152, Loss : 0.18985342979431152\n",
            "Mini-Batch - 8 Back-Prop : 152, Loss : 0.24354185163974762\n",
            "Episode 5995 finished with score 1172.0, result : lose board : [[  2.   4.  32.   4.]\n",
            " [ 32.   2.  16. 128.]\n",
            " [  4.  16.   8.  16.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Maximum Score : 6356.0 ,Episode : 5768\n",
            "Loss : 0.22245829138490888\n",
            "\n",
            "Episode 6000 finished with score 384.0, result : lose board : [[4.0, 16.0, 2.0, 8.0], [2.0, 8.0, 16.0, 32.0], [4, 2.0, 32.0, 2], [2, 4, 2, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6005 finished with score 748.0, result : lose board : [[16.0, 32.0, 64.0, 8.0], [4.0, 8.0, 16.0, 2.0], [2.0, 4.0, 32.0, 16.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6010 finished with score 1720.0, result : lose board : [[  8.  32. 128.   2.]\n",
            " [  4.   8.  16. 128.]\n",
            " [  2.   4.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6015 finished with score 2612.0, result : lose board : [[16.0, 32.0, 256.0, 32.0], [8.0, 16.0, 64.0, 4.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6020 finished with score 1176.0, result : lose board : [[16.0, 32.0, 2.0, 32.0], [8.0, 16.0, 128.0, 2.0], [2.0, 4.0, 16.0, 8.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 153, Loss : 0.20862261950969696\n",
            "Mini-Batch - 1 Back-Prop : 153, Loss : 0.2181164175271988\n",
            "Mini-Batch - 2 Back-Prop : 153, Loss : 0.18680253624916077\n",
            "Mini-Batch - 3 Back-Prop : 153, Loss : 0.23783478140830994\n",
            "Mini-Batch - 4 Back-Prop : 153, Loss : 0.19038821756839752\n",
            "Mini-Batch - 5 Back-Prop : 153, Loss : 0.21058617532253265\n",
            "Mini-Batch - 6 Back-Prop : 153, Loss : 0.2168242335319519\n",
            "Mini-Batch - 7 Back-Prop : 153, Loss : 0.18395324051380157\n",
            "Mini-Batch - 8 Back-Prop : 153, Loss : 0.19908952713012695\n",
            "Episode 6025 finished with score 1616.0, result : lose board : [[  2.   4. 128.   8.]\n",
            " [  8.  32.  64.   2.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6030 finished with score 1356.0, result : lose board : [[ 16.  32. 128.  32.]\n",
            " [  8.  16.   2.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6035 finished with score 1376.0, result : lose board : [[8.0, 32.0, 128.0, 16.0], [4.0, 8.0, 64.0, 4.0], [2.0, 4.0, 16.0, 2.0], [4, 2, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6040 finished with score 1628.0, result : lose board : [[ 16.  32.  64. 128.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode : 6041, Score : 5644.0, Iters : 400, Finish : lose\n",
            "Episode 6045 finished with score 1876.0, result : lose board : [[16.0, 32.0, 64.0, 128.0], [2.0, 8.0, 32.0, 64.0], [32.0, 4.0, 8.0, 4.0], [2, 8, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6050 finished with score 688.0, result : lose board : [[16. 64. 16. 32.]\n",
            " [ 2. 16.  2. 16.]\n",
            " [ 4.  8. 16.  4.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 154, Loss : 0.23493501543998718\n",
            "Mini-Batch - 1 Back-Prop : 154, Loss : 0.2296888381242752\n",
            "Mini-Batch - 2 Back-Prop : 154, Loss : 0.20571067929267883\n",
            "Mini-Batch - 3 Back-Prop : 154, Loss : 0.1980867236852646\n",
            "Mini-Batch - 4 Back-Prop : 154, Loss : 0.22603467106819153\n",
            "Mini-Batch - 5 Back-Prop : 154, Loss : 0.24117368459701538\n",
            "Mini-Batch - 6 Back-Prop : 154, Loss : 0.19594748318195343\n",
            "Mini-Batch - 7 Back-Prop : 154, Loss : 0.22401879727840424\n",
            "Mini-Batch - 8 Back-Prop : 154, Loss : 0.28593868017196655\n",
            "Episode 6055 finished with score 2496.0, result : lose board : [[16.0, 2.0, 64.0, 256.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6060 finished with score 2752.0, result : lose board : [[16.0, 32.0, 128.0, 256.0], [4.0, 8.0, 2.0, 4.0], [8.0, 16.0, 8.0, 2.0], [4, 2, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6065 finished with score 964.0, result : lose board : [[  2.   8.  32. 128.]\n",
            " [  8.   4.   8.   2.]\n",
            " [  4.   2.   4.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6070 finished with score 2432.0, result : lose board : [[  4.  32.   8.  16.]\n",
            " [  2.   4.  64. 256.]\n",
            " [  8.   2.  32.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6075 finished with score 1804.0, result : lose board : [[8.0, 32.0, 128.0, 2.0], [4.0, 8.0, 16.0, 128.0], [2.0, 16.0, 8.0, 2.0], [4, 8.0, 2.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6080 finished with score 2044.0, result : lose board : [[16.0, 32.0, 256.0, 2.0], [2.0, 8.0, 16.0, 4.0], [8.0, 2.0, 4.0, 2.0], [2, 4, 2, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 155, Loss : 0.21136991679668427\n",
            "Mini-Batch - 1 Back-Prop : 155, Loss : 0.2124316543340683\n",
            "Mini-Batch - 2 Back-Prop : 155, Loss : 0.19325877726078033\n",
            "Mini-Batch - 3 Back-Prop : 155, Loss : 0.21941304206848145\n",
            "Mini-Batch - 4 Back-Prop : 155, Loss : 0.21364133059978485\n",
            "Mini-Batch - 5 Back-Prop : 155, Loss : 0.23293018341064453\n",
            "Mini-Batch - 6 Back-Prop : 155, Loss : 0.20205631852149963\n",
            "Mini-Batch - 7 Back-Prop : 155, Loss : 0.20055054128170013\n",
            "Mini-Batch - 8 Back-Prop : 155, Loss : 0.19757455587387085\n",
            "Episode 6085 finished with score 1028.0, result : lose board : [[16.  2. 64.  4.]\n",
            " [ 8. 32.  4. 64.]\n",
            " [ 4. 16. 32.  2.]\n",
            " [ 2.  8.  2. 16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6090 finished with score 2488.0, result : lose board : [[16.0, 64.0, 4.0, 256.0], [8.0, 16.0, 32.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6095 finished with score 296.0, result : lose board : [[4.0, 8.0, 16.0, 8.0], [2, 4, 8.0, 32.0], [4.0, 8.0, 4.0, 2], [2, 4, 2, 16]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6100 finished with score 892.0, result : lose board : [[32.0, 2.0, 32.0, 8.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6105 finished with score 1484.0, result : lose board : [[ 32.  64. 128.   8.]\n",
            " [ 16.   2.  16.   4.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6110 finished with score 308.0, result : lose board : [[8.0, 32.0, 4.0, 16.0], [2.0, 4.0, 16.0, 2.0], [4.0, 2.0, 8.0, 16.0], [2, 4.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6115 finished with score 2456.0, result : lose board : [[2.0, 16.0, 128.0, 2.0], [8.0, 128.0, 4.0, 128.0], [4.0, 32.0, 8.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 156, Loss : 0.1723899394273758\n",
            "Mini-Batch - 1 Back-Prop : 156, Loss : 0.21070444583892822\n",
            "Mini-Batch - 2 Back-Prop : 156, Loss : 0.21486708521842957\n",
            "Mini-Batch - 3 Back-Prop : 156, Loss : 0.21028657257556915\n",
            "Mini-Batch - 4 Back-Prop : 156, Loss : 0.23650193214416504\n",
            "Mini-Batch - 5 Back-Prop : 156, Loss : 0.19760288298130035\n",
            "Mini-Batch - 6 Back-Prop : 156, Loss : 0.25011348724365234\n",
            "Mini-Batch - 7 Back-Prop : 156, Loss : 0.23602822422981262\n",
            "Mini-Batch - 8 Back-Prop : 156, Loss : 0.20818378031253815\n",
            "Episode 6120 finished with score 1836.0, result : lose board : [[ 32.  64.   4. 128.]\n",
            " [  4.  32.  64.  16.]\n",
            " [  2.   8.  32.   4.]\n",
            " [  4.   2.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6125 finished with score 1196.0, result : lose board : [[16.0, 128.0, 4.0, 2.0], [8.0, 32.0, 2.0, 16.0], [32.0, 16.0, 8.0, 4.0], [16.0, 2, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6130 finished with score 1752.0, result : lose board : [[  4.  32.  64. 128.]\n",
            " [  2.   8.  32.  64.]\n",
            " [  4.   2.   4.  32.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6135 finished with score 760.0, result : lose board : [[8.0, 16.0, 32.0, 8.0], [4.0, 8.0, 16.0, 64.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6140 finished with score 1192.0, result : lose board : [[ 2. 64.  2. 64.]\n",
            " [ 4. 32. 64.  8.]\n",
            " [ 8.  4.  8. 16.]\n",
            " [ 4. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6145 finished with score 1328.0, result : lose board : [[16.0, 2.0, 128.0, 4.0], [8.0, 64.0, 8.0, 2.0], [2.0, 16.0, 4.0, 32.0], [8.0, 4, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 157, Loss : 0.1857486367225647\n",
            "Mini-Batch - 1 Back-Prop : 157, Loss : 0.26699137687683105\n",
            "Mini-Batch - 2 Back-Prop : 157, Loss : 0.2140168398618698\n",
            "Mini-Batch - 3 Back-Prop : 157, Loss : 0.17787876725196838\n",
            "Mini-Batch - 4 Back-Prop : 157, Loss : 0.1964513659477234\n",
            "Mini-Batch - 5 Back-Prop : 157, Loss : 0.21049144864082336\n",
            "Mini-Batch - 6 Back-Prop : 157, Loss : 0.18975096940994263\n",
            "Mini-Batch - 7 Back-Prop : 157, Loss : 0.2173406481742859\n",
            "Mini-Batch - 8 Back-Prop : 157, Loss : 0.19615580141544342\n",
            "Episode 6150 finished with score 1944.0, result : lose board : [[16.0, 32.0, 2.0, 128.0], [4.0, 16.0, 128.0, 16.0], [32.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6155 finished with score 2856.0, result : lose board : [[2, 8.0, 256.0, 2.0], [8.0, 32.0, 128.0, 8.0], [4.0, 8.0, 32.0, 16.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6160 finished with score 1532.0, result : lose board : [[ 16.  32. 128.   2.]\n",
            " [  8.   4.  32.   4.]\n",
            " [  4.  32.  64.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6165 finished with score 724.0, result : lose board : [[ 8. 16. 32.  4.]\n",
            " [ 4. 64. 16.  2.]\n",
            " [ 2.  8. 32.  4.]\n",
            " [ 4.  2. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6170 finished with score 2808.0, result : lose board : [[16.0, 4.0, 256.0, 2.0], [8.0, 2.0, 128.0, 32.0], [4.0, 16.0, 8.0, 16.0], [2, 8.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6175 finished with score 1148.0, result : lose board : [[16.0, 32.0, 2.0, 128.0], [4.0, 8.0, 32.0, 8.0], [2, 4.0, 8.0, 16.0], [4.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6180 finished with score 784.0, result : lose board : [[16.0, 2.0, 32.0, 4.0], [4.0, 64.0, 4.0, 16.0], [2.0, 32.0, 16.0, 8.0], [16.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 158, Loss : 0.22985665500164032\n",
            "Mini-Batch - 1 Back-Prop : 158, Loss : 0.23523938655853271\n",
            "Mini-Batch - 2 Back-Prop : 158, Loss : 0.21328198909759521\n",
            "Mini-Batch - 3 Back-Prop : 158, Loss : 0.2131180465221405\n",
            "Mini-Batch - 4 Back-Prop : 158, Loss : 0.22355926036834717\n",
            "Mini-Batch - 5 Back-Prop : 158, Loss : 0.1966819018125534\n",
            "Mini-Batch - 6 Back-Prop : 158, Loss : 0.2150341123342514\n",
            "Mini-Batch - 7 Back-Prop : 158, Loss : 0.19805505871772766\n",
            "Mini-Batch - 8 Back-Prop : 158, Loss : 0.1909269392490387\n",
            "Episode 6185 finished with score 3328.0, result : lose board : [[ 32.   2.   4. 256.]\n",
            " [  8.  64.   2. 128.]\n",
            " [  2.  16.  64.  16.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6190 finished with score 744.0, result : lose board : [[16.  2. 64. 16.]\n",
            " [ 8. 32. 16.  4.]\n",
            " [ 4.  8. 32.  2.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6195 finished with score 544.0, result : lose board : [[8.0, 16.0, 2.0, 32.0], [4.0, 8.0, 32.0, 8.0], [2.0, 32.0, 8.0, 4.0], [4, 8.0, 16.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6200 finished with score 1024.0, result : lose board : [[2.0, 32.0, 64.0, 8.0], [8.0, 16.0, 8.0, 64.0], [4.0, 8.0, 32.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6205 finished with score 1128.0, result : lose board : [[16.0, 32.0, 2.0, 8.0], [4.0, 128.0, 4.0, 2.0], [2.0, 16.0, 32.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6210 finished with score 1996.0, result : lose board : [[2.0, 4.0, 32.0, 128.0], [16.0, 2.0, 128.0, 4.0], [4.0, 8.0, 4.0, 64.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 159, Loss : 0.17948676645755768\n",
            "Mini-Batch - 1 Back-Prop : 159, Loss : 0.21147647500038147\n",
            "Mini-Batch - 2 Back-Prop : 159, Loss : 0.23140385746955872\n",
            "Mini-Batch - 3 Back-Prop : 159, Loss : 0.238692507147789\n",
            "Mini-Batch - 4 Back-Prop : 159, Loss : 0.24324284493923187\n",
            "Mini-Batch - 5 Back-Prop : 159, Loss : 0.19886258244514465\n",
            "Mini-Batch - 6 Back-Prop : 159, Loss : 0.2144366353750229\n",
            "Mini-Batch - 7 Back-Prop : 159, Loss : 0.17787335813045502\n",
            "Mini-Batch - 8 Back-Prop : 159, Loss : 0.21915394067764282\n",
            "Episode 6215 finished with score 2096.0, result : lose board : [[16.0, 8.0, 4.0, 128.0], [8.0, 128.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6220 finished with score 612.0, result : lose board : [[2.0, 4.0, 16.0, 64.0], [16.0, 2.0, 8.0, 4.0], [4.0, 16.0, 32.0, 8.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6225 finished with score 2752.0, result : lose board : [[2.0, 128.0, 256.0, 16.0], [4.0, 16.0, 4.0, 2.0], [2.0, 8.0, 32.0, 8.0], [4.0, 2.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6230 finished with score 716.0, result : lose board : [[2, 4.0, 32.0, 4.0], [4.0, 8.0, 64.0, 16.0], [8.0, 16.0, 32.0, 8.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6235 finished with score 1172.0, result : lose board : [[16. 32.  2. 64.]\n",
            " [ 8. 16. 64. 32.]\n",
            " [ 4.  8. 32.  8.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 160, Loss : 0.24694137275218964\n",
            "Mini-Batch - 1 Back-Prop : 160, Loss : 0.2148457169532776\n",
            "Mini-Batch - 2 Back-Prop : 160, Loss : 0.17939811944961548\n",
            "Mini-Batch - 3 Back-Prop : 160, Loss : 0.23254749178886414\n",
            "Mini-Batch - 4 Back-Prop : 160, Loss : 0.18022632598876953\n",
            "Mini-Batch - 5 Back-Prop : 160, Loss : 0.1961725354194641\n",
            "Mini-Batch - 6 Back-Prop : 160, Loss : 0.21434177458286285\n",
            "Mini-Batch - 7 Back-Prop : 160, Loss : 0.1999138444662094\n",
            "Mini-Batch - 8 Back-Prop : 160, Loss : 0.17030677199363708\n",
            "Episode 6240 finished with score 1444.0, result : lose board : [[8.0, 32.0, 64.0, 4.0], [2.0, 16.0, 128.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6245 finished with score 3000.0, result : lose board : [[  4.  16. 256.   2.]\n",
            " [  8.  64. 128.   4.]\n",
            " [  4.  16.   8.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6250 finished with score 968.0, result : lose board : [[16.0, 2.0, 4.0, 64.0], [8.0, 16.0, 64.0, 4.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6255 finished with score 1708.0, result : lose board : [[16.0, 64.0, 128.0, 2.0], [2.0, 32.0, 2.0, 4.0], [4.0, 2.0, 32.0, 64.0], [2, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6260 finished with score 1480.0, result : lose board : [[16.0, 32.0, 4.0, 128.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6265 finished with score 3380.0, result : lose board : [[16.0, 64.0, 128.0, 16.0], [8.0, 4.0, 256.0, 2.0], [4.0, 2.0, 32.0, 64.0], [2.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 161, Loss : 0.1863604187965393\n",
            "Mini-Batch - 1 Back-Prop : 161, Loss : 0.2155565321445465\n",
            "Mini-Batch - 2 Back-Prop : 161, Loss : 0.2301742285490036\n",
            "Mini-Batch - 3 Back-Prop : 161, Loss : 0.1973990499973297\n",
            "Mini-Batch - 4 Back-Prop : 161, Loss : 0.2128002643585205\n",
            "Mini-Batch - 5 Back-Prop : 161, Loss : 0.23012515902519226\n",
            "Mini-Batch - 6 Back-Prop : 161, Loss : 0.22558459639549255\n",
            "Mini-Batch - 7 Back-Prop : 161, Loss : 0.1975095123052597\n",
            "Mini-Batch - 8 Back-Prop : 161, Loss : 0.21376453340053558\n",
            "Episode 6270 finished with score 1220.0, result : lose board : [[16.0, 64.0, 2.0, 16.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 16.0, 64.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6275 finished with score 1764.0, result : lose board : [[ 16.   4.  32.  64.]\n",
            " [  8.   2. 128.   4.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6280 finished with score 1668.0, result : lose board : [[  2.   8.  64.   8.]\n",
            " [  8.  32. 128.   2.]\n",
            " [  2.  64.  32.   8.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6285 finished with score 1684.0, result : lose board : [[8.0, 64.0, 2.0, 64.0], [4.0, 16.0, 128.0, 16.0], [2.0, 8.0, 32.0, 4.0], [4.0, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6290 finished with score 2208.0, result : lose board : [[ 16.  32. 128.   4.]\n",
            " [  4.   8.  64. 128.]\n",
            " [  8.  16.  32.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6295 finished with score 760.0, result : lose board : [[16.0, 4.0, 16.0, 64.0], [8.0, 32.0, 4.0, 2.0], [2.0, 8.0, 16.0, 32.0], [4.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6300 finished with score 500.0, result : lose board : [[ 4. 32.  8. 32.]\n",
            " [16.  4.  2. 16.]\n",
            " [ 4. 32.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 162, Loss : 0.24266600608825684\n",
            "Mini-Batch - 1 Back-Prop : 162, Loss : 0.16155660152435303\n",
            "Mini-Batch - 2 Back-Prop : 162, Loss : 0.23428744077682495\n",
            "Mini-Batch - 3 Back-Prop : 162, Loss : 0.20236656069755554\n",
            "Mini-Batch - 4 Back-Prop : 162, Loss : 0.1849430352449417\n",
            "Mini-Batch - 5 Back-Prop : 162, Loss : 0.1842215359210968\n",
            "Mini-Batch - 6 Back-Prop : 162, Loss : 0.20419301092624664\n",
            "Mini-Batch - 7 Back-Prop : 162, Loss : 0.17696182429790497\n",
            "Mini-Batch - 8 Back-Prop : 162, Loss : 0.17765562236309052\n",
            "Episode 6305 finished with score 756.0, result : lose board : [[2.0, 8.0, 4.0, 64.0], [8.0, 16.0, 64.0, 8.0], [2.0, 4.0, 8.0, 2.0], [4, 2, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6310 finished with score 1360.0, result : lose board : [[16.0, 2.0, 4.0, 128.0], [4.0, 16.0, 32.0, 4.0], [2.0, 8.0, 16.0, 64.0], [4, 2, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6315 finished with score 2416.0, result : lose board : [[  4.   8.  32.   4.]\n",
            " [  8.  64.   8. 256.]\n",
            " [  4.  16.  32.   2.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6320 finished with score 556.0, result : lose board : [[4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 32.0], [4.0, 8.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6325 finished with score 1436.0, result : lose board : [[2.0, 4.0, 128.0, 4.0], [8.0, 16.0, 32.0, 64.0], [2.0, 32.0, 8.0, 16.0], [8.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6330 finished with score 2384.0, result : lose board : [[16.0, 4.0, 256.0, 32.0], [4.0, 16.0, 64.0, 8.0], [2.0, 4.0, 16.0, 2.0], [4, 2, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 163, Loss : 0.24748504161834717\n",
            "Mini-Batch - 1 Back-Prop : 163, Loss : 0.2750736474990845\n",
            "Mini-Batch - 2 Back-Prop : 163, Loss : 0.27806758880615234\n",
            "Mini-Batch - 3 Back-Prop : 163, Loss : 0.1952860802412033\n",
            "Mini-Batch - 4 Back-Prop : 163, Loss : 0.21806295216083527\n",
            "Mini-Batch - 5 Back-Prop : 163, Loss : 0.2250804901123047\n",
            "Mini-Batch - 6 Back-Prop : 163, Loss : 0.19300363957881927\n",
            "Mini-Batch - 7 Back-Prop : 163, Loss : 0.19014345109462738\n",
            "Mini-Batch - 8 Back-Prop : 163, Loss : 0.18155962228775024\n",
            "Episode 6335 finished with score 1080.0, result : lose board : [[  8.  16. 128.   8.]\n",
            " [ 16.   2.  16.   4.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6340 finished with score 2788.0, result : lose board : [[ 16.  64.   4.   2.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  2.  16.  32.  16.]\n",
            " [  8.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6345 finished with score 728.0, result : lose board : [[2.0, 16.0, 32.0, 8.0], [8.0, 64.0, 16.0, 4.0], [2, 8.0, 2.0, 32.0], [4.0, 16.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6350 finished with score 1664.0, result : lose board : [[  2.   4. 128.  32.]\n",
            " [  8.  16.  64.   4.]\n",
            " [  4.  64.   4.  16.]\n",
            " [  2.  16.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6355 finished with score 1048.0, result : lose board : [[8.0, 16.0, 4.0, 128.0], [2.0, 4.0, 16.0, 2], [4.0, 2.0, 32.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6360 finished with score 576.0, result : lose board : [[16.  2. 64.  2.]\n",
            " [ 8. 16.  4. 16.]\n",
            " [ 4.  8. 16.  2.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 164, Loss : 0.22608740627765656\n",
            "Mini-Batch - 1 Back-Prop : 164, Loss : 0.21422114968299866\n",
            "Mini-Batch - 2 Back-Prop : 164, Loss : 0.20105835795402527\n",
            "Mini-Batch - 3 Back-Prop : 164, Loss : 0.17719903588294983\n",
            "Mini-Batch - 4 Back-Prop : 164, Loss : 0.22488605976104736\n",
            "Mini-Batch - 5 Back-Prop : 164, Loss : 0.23824551701545715\n",
            "Mini-Batch - 6 Back-Prop : 164, Loss : 0.21539752185344696\n",
            "Mini-Batch - 7 Back-Prop : 164, Loss : 0.2094036340713501\n",
            "Mini-Batch - 8 Back-Prop : 164, Loss : 0.20822860300540924\n",
            "Episode 6365 finished with score 3056.0, result : lose board : [[  8.  16. 128.   4.]\n",
            " [  2.   8.  64. 256.]\n",
            " [  4.  16.  32.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6370 finished with score 384.0, result : lose board : [[8.0, 32.0, 2.0, 16.0], [4.0, 16.0, 32.0, 4.0], [2.0, 8.0, 4.0, 2.0], [4, 2, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6375 finished with score 948.0, result : lose board : [[ 8. 32. 64.  4.]\n",
            " [ 2.  4. 16. 64.]\n",
            " [ 8.  2. 32.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6380 finished with score 2460.0, result : lose board : [[32.0, 4.0, 16.0, 256.0], [4.0, 32.0, 64.0, 16.0], [2.0, 4.0, 16.0, 8.0], [4, 2, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6385 finished with score 3480.0, result : lose board : [[ 16.  64. 128. 256.]\n",
            " [  8.  32.  64.   8.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6390 finished with score 1024.0, result : lose board : [[32.  2. 64.  4.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 2.  8.  4. 16.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6395 finished with score 600.0, result : lose board : [[8.0, 16.0, 32.0, 64.0], [2, 4.0, 8.0, 16.0], [4.0, 16.0, 2.0, 4], [2, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 165, Loss : 0.21634748578071594\n",
            "Mini-Batch - 1 Back-Prop : 165, Loss : 0.24354204535484314\n",
            "Mini-Batch - 2 Back-Prop : 165, Loss : 0.20292925834655762\n",
            "Mini-Batch - 3 Back-Prop : 165, Loss : 0.19371050596237183\n",
            "Mini-Batch - 4 Back-Prop : 165, Loss : 0.22937819361686707\n",
            "Mini-Batch - 5 Back-Prop : 165, Loss : 0.20309507846832275\n",
            "Mini-Batch - 6 Back-Prop : 165, Loss : 0.17885835468769073\n",
            "Mini-Batch - 7 Back-Prop : 165, Loss : 0.1625809520483017\n",
            "Mini-Batch - 8 Back-Prop : 165, Loss : 0.1825248897075653\n",
            "Episode 6400 finished with score 1908.0, result : lose board : [[16.0, 32.0, 4.0, 128.0], [4.0, 2.0, 128.0, 4.0], [8.0, 16.0, 32.0, 2], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6405 finished with score 1192.0, result : lose board : [[ 2.  8. 32. 64.]\n",
            " [16. 32.  4.  8.]\n",
            " [ 8. 16. 64. 32.]\n",
            " [ 4.  2.  4. 16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6410 finished with score 1636.0, result : lose board : [[  2.   8.  64.   8.]\n",
            " [ 16.  64. 128.   4.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6415 finished with score 1344.0, result : lose board : [[  2.   4.   8.   2.]\n",
            " [  8.  32.  64.   4.]\n",
            " [ 16. 128.  16.   8.]\n",
            " [  4.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6420 finished with score 1364.0, result : lose board : [[2.0, 16.0, 8.0, 128.0], [16.0, 64.0, 2.0, 4.0], [4, 8.0, 16.0, 32.0], [2.0, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6425 finished with score 320.0, result : lose board : [[4.0, 8.0, 2.0, 32.0], [2.0, 4.0, 32.0, 2.0], [8.0, 16.0, 2.0, 8.0], [4, 2.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 166, Loss : 0.14587494730949402\n",
            "Mini-Batch - 1 Back-Prop : 166, Loss : 0.2081189602613449\n",
            "Mini-Batch - 2 Back-Prop : 166, Loss : 0.21631678938865662\n",
            "Mini-Batch - 3 Back-Prop : 166, Loss : 0.1689528524875641\n",
            "Mini-Batch - 4 Back-Prop : 166, Loss : 0.23465928435325623\n",
            "Mini-Batch - 5 Back-Prop : 166, Loss : 0.1904413104057312\n",
            "Mini-Batch - 6 Back-Prop : 166, Loss : 0.19061365723609924\n",
            "Mini-Batch - 7 Back-Prop : 166, Loss : 0.18604424595832825\n",
            "Mini-Batch - 8 Back-Prop : 166, Loss : 0.21072852611541748\n",
            "Episode 6430 finished with score 1732.0, result : lose board : [[ 32.  64. 128.  16.]\n",
            " [  2.   4.  64.   4.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6435 finished with score 304.0, result : lose board : [[2.0, 8.0, 16.0, 32.0], [4.0, 2.0, 4.0, 16.0], [2.0, 4.0, 8.0, 4.0], [4, 2, 4, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6440 finished with score 840.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [2.0, 16.0, 32.0, 4.0], [32.0, 8.0, 4.0, 2.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6445 finished with score 980.0, result : lose board : [[4, 2, 8.0, 128.0], [16.0, 8.0, 16.0, 8.0], [8.0, 4.0, 8.0, 2.0], [2.0, 16.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6450 finished with score 2080.0, result : lose board : [[  2.   8.   2. 128.]\n",
            " [  4.  16.  64.   8.]\n",
            " [128.  32.  16.   2.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6455 finished with score 2432.0, result : lose board : [[ 16.  32.   4. 256.]\n",
            " [  8.  16.  64.  16.]\n",
            " [  4.   8.  16.   4.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 167, Loss : 0.21198824048042297\n",
            "Mini-Batch - 1 Back-Prop : 167, Loss : 0.20502199232578278\n",
            "Mini-Batch - 2 Back-Prop : 167, Loss : 0.22420938313007355\n",
            "Mini-Batch - 3 Back-Prop : 167, Loss : 0.1944286823272705\n",
            "Mini-Batch - 4 Back-Prop : 167, Loss : 0.20849233865737915\n",
            "Mini-Batch - 5 Back-Prop : 167, Loss : 0.20074725151062012\n",
            "Mini-Batch - 6 Back-Prop : 167, Loss : 0.22651387751102448\n",
            "Mini-Batch - 7 Back-Prop : 167, Loss : 0.23408958315849304\n",
            "Mini-Batch - 8 Back-Prop : 167, Loss : 0.21668504178524017\n",
            "Episode 6460 finished with score 1240.0, result : lose board : [[32. 64.  4. 64.]\n",
            " [ 8.  2. 64.  8.]\n",
            " [ 4. 16. 32.  2.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6465 finished with score 320.0, result : lose board : [[8.0, 16.0, 2.0, 16.0], [4.0, 8.0, 32.0, 4.0], [2, 4, 2, 16.0], [4, 8, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6470 finished with score 2528.0, result : lose board : [[ 16.  32.   4. 256.]\n",
            " [  8.  16.  32.  16.]\n",
            " [  4.   8.  64.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6475 finished with score 744.0, result : lose board : [[16. 32.  2. 16.]\n",
            " [ 4. 16. 64.  8.]\n",
            " [ 8. 32.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6480 finished with score 296.0, result : lose board : [[16.  4. 32.  4.]\n",
            " [ 4.  2.  4. 16.]\n",
            " [ 2. 16.  8.  4.]\n",
            " [ 8.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6485 finished with score 2856.0, result : lose board : [[  2.   4.   2.  16.]\n",
            " [  4. 256.  32.   4.]\n",
            " [128.  32.  16.   2.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 168, Loss : 0.2053827941417694\n",
            "Mini-Batch - 1 Back-Prop : 168, Loss : 0.19620905816555023\n",
            "Mini-Batch - 2 Back-Prop : 168, Loss : 0.171746626496315\n",
            "Mini-Batch - 3 Back-Prop : 168, Loss : 0.20029467344284058\n",
            "Mini-Batch - 4 Back-Prop : 168, Loss : 0.17677448689937592\n",
            "Mini-Batch - 5 Back-Prop : 168, Loss : 0.1978718340396881\n",
            "Mini-Batch - 6 Back-Prop : 168, Loss : 0.2179742008447647\n",
            "Mini-Batch - 7 Back-Prop : 168, Loss : 0.18346159160137177\n",
            "Mini-Batch - 8 Back-Prop : 168, Loss : 0.22464561462402344\n",
            "Episode 6490 finished with score 2172.0, result : lose board : [[2.0, 128.0, 2.0, 16.0], [128.0, 8.0, 32.0, 2.0], [4.0, 32.0, 16.0, 64.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6495 finished with score 936.0, result : lose board : [[16.0, 32.0, 64.0, 16.0], [8.0, 16.0, 32.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6500 finished with score 2948.0, result : lose board : [[ 16.   2. 256.   4.]\n",
            " [  8.  16. 128.   2.]\n",
            " [  4.   8.  64.   8.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6505 finished with score 1148.0, result : lose board : [[8.0, 4.0, 8.0, 128.0], [2.0, 8.0, 64.0, 2], [4.0, 2.0, 4.0, 16.0], [2.0, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6510 finished with score 672.0, result : lose board : [[4.0, 16.0, 32.0, 64.0], [2.0, 4.0, 2.0, 32.0], [8.0, 2.0, 16.0, 4.0], [2, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6515 finished with score 1396.0, result : lose board : [[ 16.  32. 128.  32.]\n",
            " [  8.  16.  32.  16.]\n",
            " [  4.   8.  16.   8.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 169, Loss : 0.17956027388572693\n",
            "Mini-Batch - 1 Back-Prop : 169, Loss : 0.21557928621768951\n",
            "Mini-Batch - 2 Back-Prop : 169, Loss : 0.17073148488998413\n",
            "Mini-Batch - 3 Back-Prop : 169, Loss : 0.1889493465423584\n",
            "Mini-Batch - 4 Back-Prop : 169, Loss : 0.20653235912322998\n",
            "Mini-Batch - 5 Back-Prop : 169, Loss : 0.23640646040439606\n",
            "Mini-Batch - 6 Back-Prop : 169, Loss : 0.1976633369922638\n",
            "Mini-Batch - 7 Back-Prop : 169, Loss : 0.22007396817207336\n",
            "Mini-Batch - 8 Back-Prop : 169, Loss : 0.18803875148296356\n",
            "Episode 6520 finished with score 1012.0, result : lose board : [[  8.   2.  32. 128.]\n",
            " [  4.  16.   4.   2.]\n",
            " [  2.   8.   2.  16.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6525 finished with score 1148.0, result : lose board : [[16.0, 4.0, 8.0, 128.0], [8.0, 32.0, 2.0, 32.0], [4.0, 8.0, 16.0, 2.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6530 finished with score 2580.0, result : lose board : [[ 16.  32.  64. 256.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6535 finished with score 1696.0, result : lose board : [[16.0, 32.0, 4.0, 8.0], [8.0, 16.0, 64.0, 128.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6540 finished with score 1480.0, result : lose board : [[4.0, 16.0, 2.0, 8.0], [8.0, 64.0, 128.0, 32.0], [4.0, 32.0, 16.0, 2.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6545 finished with score 508.0, result : lose board : [[4.0, 32.0, 16.0, 32.0], [2.0, 8.0, 32.0, 16.0], [4.0, 2.0, 8.0, 4.0], [2, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6550 finished with score 2652.0, result : lose board : [[ 16. 256.  32.   2.]\n",
            " [  8.  16.  64.   4.]\n",
            " [  4.  32.  16.  32.]\n",
            " [  2.  16.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 170, Loss : 0.20542417466640472\n",
            "Mini-Batch - 1 Back-Prop : 170, Loss : 0.16959400475025177\n",
            "Mini-Batch - 2 Back-Prop : 170, Loss : 0.19017356634140015\n",
            "Mini-Batch - 3 Back-Prop : 170, Loss : 0.19161604344844818\n",
            "Mini-Batch - 4 Back-Prop : 170, Loss : 0.23870044946670532\n",
            "Mini-Batch - 5 Back-Prop : 170, Loss : 0.22311535477638245\n",
            "Mini-Batch - 6 Back-Prop : 170, Loss : 0.2290171980857849\n",
            "Mini-Batch - 7 Back-Prop : 170, Loss : 0.230128213763237\n",
            "Mini-Batch - 8 Back-Prop : 170, Loss : 0.18939292430877686\n",
            "Episode 6555 finished with score 2188.0, result : lose board : [[8.0, 32.0, 4.0, 256.0], [4.0, 16.0, 32.0, 2.0], [2, 4.0, 8.0, 32.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6560 finished with score 672.0, result : lose board : [[ 4. 32. 64.  2.]\n",
            " [16.  4.  2.  4.]\n",
            " [ 4. 32.  4.  2.]\n",
            " [ 2. 16.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6565 finished with score 1168.0, result : lose board : [[ 16.  32. 128.   2.]\n",
            " [  2.  16.   8.  16.]\n",
            " [  4.  32.   2.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6570 finished with score 480.0, result : lose board : [[4.0, 16.0, 64.0, 4.0], [2, 8.0, 2.0, 16.0], [4, 2.0, 16.0, 4], [2.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6575 finished with score 1364.0, result : lose board : [[  8.  32.   2. 128.]\n",
            " [  2.   4.  64.   8.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6580 finished with score 3044.0, result : lose board : [[4.0, 16.0, 4.0, 2.0], [16.0, 128.0, 8.0, 256.0], [4.0, 16.0, 64.0, 16.0], [2, 4, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 171, Loss : 0.18608660995960236\n",
            "Mini-Batch - 1 Back-Prop : 171, Loss : 0.22373826801776886\n",
            "Mini-Batch - 2 Back-Prop : 171, Loss : 0.24566437304019928\n",
            "Mini-Batch - 3 Back-Prop : 171, Loss : 0.24778351187705994\n",
            "Mini-Batch - 4 Back-Prop : 171, Loss : 0.2136635184288025\n",
            "Mini-Batch - 5 Back-Prop : 171, Loss : 0.20320937037467957\n",
            "Mini-Batch - 6 Back-Prop : 171, Loss : 0.1570041924715042\n",
            "Mini-Batch - 7 Back-Prop : 171, Loss : 0.21116304397583008\n",
            "Mini-Batch - 8 Back-Prop : 171, Loss : 0.23296292126178741\n",
            "Episode 6585 finished with score 1772.0, result : lose board : [[4.0, 32.0, 128.0, 4.0], [2, 4.0, 16.0, 128.0], [4.0, 8.0, 2.0, 4.0], [2, 4, 16, 8]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6590 finished with score 1804.0, result : lose board : [[  8.  32. 128.   4.]\n",
            " [  4.  16.   2. 128.]\n",
            " [  2.   8.  32.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6595 finished with score 1476.0, result : lose board : [[ 16.  64. 128.  32.]\n",
            " [  4.  16.  32.   8.]\n",
            " [  8.   2.   8.   4.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6600 finished with score 768.0, result : lose board : [[16. 32.  2. 16.]\n",
            " [ 4. 16. 64.  2.]\n",
            " [ 2.  8. 16. 32.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6605 finished with score 1776.0, result : lose board : [[  4.   8. 128.   2.]\n",
            " [  8.  32.  64.   4.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6610 finished with score 556.0, result : lose board : [[ 4. 16.  2. 16.]\n",
            " [32.  4. 32.  8.]\n",
            " [ 4. 32. 16.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 172, Loss : 0.2578319013118744\n",
            "Mini-Batch - 1 Back-Prop : 172, Loss : 0.21887145936489105\n",
            "Mini-Batch - 2 Back-Prop : 172, Loss : 0.1950148493051529\n",
            "Mini-Batch - 3 Back-Prop : 172, Loss : 0.20788176357746124\n",
            "Mini-Batch - 4 Back-Prop : 172, Loss : 0.2151319682598114\n",
            "Mini-Batch - 5 Back-Prop : 172, Loss : 0.19799433648586273\n",
            "Mini-Batch - 6 Back-Prop : 172, Loss : 0.19824951887130737\n",
            "Mini-Batch - 7 Back-Prop : 172, Loss : 0.20925462245941162\n",
            "Mini-Batch - 8 Back-Prop : 172, Loss : 0.1864604651927948\n",
            "Episode 6615 finished with score 1840.0, result : lose board : [[16.0, 64.0, 128.0, 64.0], [8.0, 16.0, 64.0, 4.0], [4, 2, 16.0, 2.0], [2.0, 8.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6620 finished with score 1112.0, result : lose board : [[ 2. 32.  2. 64.]\n",
            " [16. 64. 32.  8.]\n",
            " [ 4. 32.  8.  4.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6625 finished with score 664.0, result : lose board : [[ 2.  8. 32.  2.]\n",
            " [ 8.  4.  8. 64.]\n",
            " [ 4.  2. 16. 32.]\n",
            " [ 2.  8.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6630 finished with score 1768.0, result : lose board : [[16.0, 64.0, 128.0, 2.0], [8.0, 4.0, 32.0, 64.0], [4.0, 2.0, 16.0, 32.0], [2.0, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6635 finished with score 852.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [2.0, 16.0, 2.0, 32.0], [4.0, 8.0, 32.0, 16.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6640 finished with score 2196.0, result : lose board : [[ 16.   2.  16.   2.]\n",
            " [  8.  16.  32. 256.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6645 finished with score 3256.0, result : lose board : [[ 16.  32.  64.   8.]\n",
            " [  8.  16.  32. 256.]\n",
            " [  4.   8. 128.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 173, Loss : 0.20608952641487122\n",
            "Mini-Batch - 1 Back-Prop : 173, Loss : 0.1910950243473053\n",
            "Mini-Batch - 2 Back-Prop : 173, Loss : 0.19859358668327332\n",
            "Mini-Batch - 3 Back-Prop : 173, Loss : 0.19753330945968628\n",
            "Mini-Batch - 4 Back-Prop : 173, Loss : 0.20408868789672852\n",
            "Mini-Batch - 5 Back-Prop : 173, Loss : 0.2035737782716751\n",
            "Mini-Batch - 6 Back-Prop : 173, Loss : 0.17717424035072327\n",
            "Mini-Batch - 7 Back-Prop : 173, Loss : 0.19484025239944458\n",
            "Mini-Batch - 8 Back-Prop : 173, Loss : 0.18364575505256653\n",
            "Episode 6650 finished with score 1044.0, result : lose board : [[ 2.  4. 32.  4.]\n",
            " [16.  8.  2. 64.]\n",
            " [ 4. 64. 32. 16.]\n",
            " [ 2. 16.  2.  8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6655 finished with score 740.0, result : lose board : [[16.  4.  2. 32.]\n",
            " [ 8. 16. 64.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6660 finished with score 1544.0, result : lose board : [[32.0, 2.0, 4.0, 32.0], [8.0, 16.0, 128.0, 4.0], [4.0, 8.0, 32.0, 64.0], [2, 4, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6665 finished with score 1044.0, result : lose board : [[16.  2. 64.  4.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6670 finished with score 764.0, result : lose board : [[8.0, 32.0, 64.0, 16.0], [4.0, 16.0, 32.0, 4.0], [2.0, 8.0, 16.0, 2.0], [4, 2, 4, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6675 finished with score 1432.0, result : lose board : [[  8.  16.  64. 128.]\n",
            " [  2.   8.  16.  32.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 174, Loss : 0.1898461878299713\n",
            "Mini-Batch - 1 Back-Prop : 174, Loss : 0.21885579824447632\n",
            "Mini-Batch - 2 Back-Prop : 174, Loss : 0.23431694507598877\n",
            "Mini-Batch - 3 Back-Prop : 174, Loss : 0.19975459575653076\n",
            "Mini-Batch - 4 Back-Prop : 174, Loss : 0.20691396296024323\n",
            "Mini-Batch - 5 Back-Prop : 174, Loss : 0.19310405850410461\n",
            "Mini-Batch - 6 Back-Prop : 174, Loss : 0.18193769454956055\n",
            "Mini-Batch - 7 Back-Prop : 174, Loss : 0.21192236244678497\n",
            "Mini-Batch - 8 Back-Prop : 174, Loss : 0.2569173574447632\n",
            "Episode 6680 finished with score 1184.0, result : lose board : [[  2.  16. 128.   4.]\n",
            " [  8.  32.   2.  32.]\n",
            " [  4.   8.  16.   8.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6685 finished with score 1764.0, result : lose board : [[  2.   4. 128.  16.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4. 128.   8.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6690 finished with score 1880.0, result : lose board : [[16.0, 64.0, 2.0, 4.0], [4.0, 32.0, 128.0, 64.0], [2.0, 64.0, 8.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6695 finished with score 1416.0, result : lose board : [[2.0, 32.0, 2.0, 8.0], [16.0, 128.0, 64.0, 2.0], [4.0, 16.0, 32.0, 4.0], [8, 2, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6700 finished with score 2760.0, result : lose board : [[32.0, 64.0, 256.0, 16.0], [4.0, 16.0, 64.0, 32.0], [2.0, 4.0, 16.0, 8.0], [4, 8.0, 2.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6705 finished with score 2684.0, result : lose board : [[  2.   4. 256.   4.]\n",
            " [ 16.  64.  32.  64.]\n",
            " [  8.  16.   8.  16.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 175, Loss : 0.2229347825050354\n",
            "Mini-Batch - 1 Back-Prop : 175, Loss : 0.2060396820306778\n",
            "Mini-Batch - 2 Back-Prop : 175, Loss : 0.22315168380737305\n",
            "Mini-Batch - 3 Back-Prop : 175, Loss : 0.16629064083099365\n",
            "Mini-Batch - 4 Back-Prop : 175, Loss : 0.1866954267024994\n",
            "Mini-Batch - 5 Back-Prop : 175, Loss : 0.2264329046010971\n",
            "Mini-Batch - 6 Back-Prop : 175, Loss : 0.19255894422531128\n",
            "Mini-Batch - 7 Back-Prop : 175, Loss : 0.22591015696525574\n",
            "Mini-Batch - 8 Back-Prop : 175, Loss : 0.17776043713092804\n",
            "Episode 6710 finished with score 712.0, result : lose board : [[ 2.  8. 32. 64.]\n",
            " [16.  4.  8. 16.]\n",
            " [ 4.  8. 32.  8.]\n",
            " [ 2.  4.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6715 finished with score 3316.0, result : lose board : [[ 16.   4. 128. 256.]\n",
            " [  4.   2.  64.   8.]\n",
            " [  2.  64.  32.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6720 finished with score 244.0, result : lose board : [[4.0, 8.0, 16.0, 4.0], [2.0, 4.0, 8.0, 32.0], [4.0, 2.0, 4.0, 8.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6725 finished with score 396.0, result : lose board : [[ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8. 16.]\n",
            " [ 4.  2. 32.  4.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6730 finished with score 2132.0, result : lose board : [[16.0, 8.0, 2.0, 128.0], [8.0, 64.0, 128.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6735 finished with score 2708.0, result : lose board : [[  2.   4.   8.   2.]\n",
            " [  8. 256. 128.  16.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 176, Loss : 0.19928883016109467\n",
            "Mini-Batch - 1 Back-Prop : 176, Loss : 0.15994487702846527\n",
            "Mini-Batch - 2 Back-Prop : 176, Loss : 0.23729291558265686\n",
            "Mini-Batch - 3 Back-Prop : 176, Loss : 0.20202608406543732\n",
            "Mini-Batch - 4 Back-Prop : 176, Loss : 0.22920922935009003\n",
            "Mini-Batch - 5 Back-Prop : 176, Loss : 0.21272698044776917\n",
            "Mini-Batch - 6 Back-Prop : 176, Loss : 0.21910794079303741\n",
            "Mini-Batch - 7 Back-Prop : 176, Loss : 0.23930303752422333\n",
            "Mini-Batch - 8 Back-Prop : 176, Loss : 0.2466333508491516\n",
            "Episode 6740 finished with score 1724.0, result : lose board : [[  2.  16.   8.   2.]\n",
            " [  8.  32. 128.  64.]\n",
            " [  4.  64.  32.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6745 finished with score 4048.0, result : lose board : [[4.0, 64.0, 128.0, 256.0], [16.0, 32.0, 8.0, 128.0], [4, 8.0, 2.0, 64.0], [2, 4.0, 16.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6750 finished with score 2388.0, result : lose board : [[16.0, 2.0, 4.0, 16.0], [8.0, 64.0, 256.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6755 finished with score 3412.0, result : lose board : [[2.0, 8.0, 128.0, 256.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 32.0, 64.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6760 finished with score 412.0, result : lose board : [[ 8. 16.  4. 32.]\n",
            " [ 2.  8. 32. 16.]\n",
            " [ 8.  2.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 177, Loss : 0.2239035815000534\n",
            "Mini-Batch - 1 Back-Prop : 177, Loss : 0.21935245394706726\n",
            "Mini-Batch - 2 Back-Prop : 177, Loss : 0.197267085313797\n",
            "Mini-Batch - 3 Back-Prop : 177, Loss : 0.1908094584941864\n",
            "Mini-Batch - 4 Back-Prop : 177, Loss : 0.19018878042697906\n",
            "Mini-Batch - 5 Back-Prop : 177, Loss : 0.20941227674484253\n",
            "Mini-Batch - 6 Back-Prop : 177, Loss : 0.19422714412212372\n",
            "Mini-Batch - 7 Back-Prop : 177, Loss : 0.19938701391220093\n",
            "Mini-Batch - 8 Back-Prop : 177, Loss : 0.2005014717578888\n",
            "Episode 6765 finished with score 796.0, result : lose board : [[4.0, 32.0, 2.0, 32.0], [2.0, 4.0, 64.0, 8.0], [8.0, 16.0, 32.0, 4.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6770 finished with score 624.0, result : lose board : [[16.  2. 16. 64.]\n",
            " [ 2. 16.  4.  8.]\n",
            " [ 8.  2. 32.  2.]\n",
            " [ 4.  8.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6775 finished with score 1256.0, result : lose board : [[ 16.   4. 128.   2.]\n",
            " [  8.  16.   8.  64.]\n",
            " [  4.   8.   2.  16.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6780 finished with score 364.0, result : lose board : [[ 2. 32.  8.  2.]\n",
            " [ 8. 16. 32.  8.]\n",
            " [ 4.  2.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6785 finished with score 1280.0, result : lose board : [[2.0, 16.0, 128.0, 16.0], [16.0, 8.0, 4.0, 2.0], [8.0, 16.0, 64.0, 8.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6790 finished with score 5072.0, result : lose board : [[  2.   4.   8.   2.]\n",
            " [ 16.  32. 512.   8.]\n",
            " [  4.  16. 128.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6795 finished with score 1316.0, result : lose board : [[  2.  64.   2. 128.]\n",
            " [  8.  32.  16.   4.]\n",
            " [  4.  16.   4.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 178, Loss : 0.17321830987930298\n",
            "Mini-Batch - 1 Back-Prop : 178, Loss : 0.17864903807640076\n",
            "Mini-Batch - 2 Back-Prop : 178, Loss : 0.19822770357131958\n",
            "Mini-Batch - 3 Back-Prop : 178, Loss : 0.21288341283798218\n",
            "Mini-Batch - 4 Back-Prop : 178, Loss : 0.19130098819732666\n",
            "Mini-Batch - 5 Back-Prop : 178, Loss : 0.2003086805343628\n",
            "Mini-Batch - 6 Back-Prop : 178, Loss : 0.21683579683303833\n",
            "Mini-Batch - 7 Back-Prop : 178, Loss : 0.22107039391994476\n",
            "Mini-Batch - 8 Back-Prop : 178, Loss : 0.16306214034557343\n",
            "Episode 6800 finished with score 1864.0, result : lose board : [[16.0, 64.0, 4.0, 128.0], [8.0, 4.0, 64.0, 16.0], [4.0, 64.0, 8.0, 4.0], [16.0, 8, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6805 finished with score 2520.0, result : lose board : [[8.0, 32.0, 64.0, 8.0], [4.0, 16.0, 256.0, 32.0], [2, 4.0, 32.0, 8.0], [4.0, 2.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6810 finished with score 1196.0, result : lose board : [[16. 64.  8. 64.]\n",
            " [ 2.  8. 64.  8.]\n",
            " [ 4.  2. 32.  4.]\n",
            " [ 2. 16.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6815 finished with score 3124.0, result : lose board : [[  8.  32. 128. 256.]\n",
            " [  4.   8.  32.  64.]\n",
            " [  2.   4.  16.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6820 finished with score 3060.0, result : lose board : [[16.0, 32.0, 64.0, 256.0], [2.0, 4.0, 8.0, 128.0], [4.0, 16.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6825 finished with score 756.0, result : lose board : [[2.0, 8.0, 64.0, 2.0], [8.0, 64.0, 4.0, 16.0], [2.0, 4.0, 16.0, 8.0], [4.0, 2, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 179, Loss : 0.21589575707912445\n",
            "Mini-Batch - 1 Back-Prop : 179, Loss : 0.19555634260177612\n",
            "Mini-Batch - 2 Back-Prop : 179, Loss : 0.18509593605995178\n",
            "Mini-Batch - 3 Back-Prop : 179, Loss : 0.2556900382041931\n",
            "Mini-Batch - 4 Back-Prop : 179, Loss : 0.2099364697933197\n",
            "Mini-Batch - 5 Back-Prop : 179, Loss : 0.22631704807281494\n",
            "Mini-Batch - 6 Back-Prop : 179, Loss : 0.1895286738872528\n",
            "Mini-Batch - 7 Back-Prop : 179, Loss : 0.1962231695652008\n",
            "Mini-Batch - 8 Back-Prop : 179, Loss : 0.19264516234397888\n",
            "Episode 6830 finished with score 1180.0, result : lose board : [[2, 32.0, 128.0, 2.0], [4.0, 2.0, 4.0, 32.0], [2.0, 4.0, 32.0, 4.0], [4, 2.0, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6835 finished with score 1168.0, result : lose board : [[16.0, 32.0, 2.0, 4.0], [8.0, 16.0, 32.0, 128.0], [2.0, 4.0, 16.0, 4.0], [4, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6840 finished with score 1364.0, result : lose board : [[  2.  32.  64. 128.]\n",
            " [  8.  16.   2.   4.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6845 finished with score 480.0, result : lose board : [[ 4.  8. 16.  2.]\n",
            " [ 2.  4.  8. 64.]\n",
            " [ 4. 16.  4.  8.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6850 finished with score 732.0, result : lose board : [[2.0, 4.0, 16.0, 2.0], [16.0, 32.0, 4.0, 64.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 180, Loss : 0.19806914031505585\n",
            "Mini-Batch - 1 Back-Prop : 180, Loss : 0.2134895920753479\n",
            "Mini-Batch - 2 Back-Prop : 180, Loss : 0.20680508017539978\n",
            "Mini-Batch - 3 Back-Prop : 180, Loss : 0.24392342567443848\n",
            "Mini-Batch - 4 Back-Prop : 180, Loss : 0.25082793831825256\n",
            "Mini-Batch - 5 Back-Prop : 180, Loss : 0.24340003728866577\n",
            "Mini-Batch - 6 Back-Prop : 180, Loss : 0.19537201523780823\n",
            "Mini-Batch - 7 Back-Prop : 180, Loss : 0.20047345757484436\n",
            "Mini-Batch - 8 Back-Prop : 180, Loss : 0.17607630789279938\n",
            "Episode 6855 finished with score 1344.0, result : lose board : [[ 4.  2. 64.  2.]\n",
            " [ 2. 32. 16. 64.]\n",
            " [ 4. 64.  2. 32.]\n",
            " [ 2. 32.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6860 finished with score 1900.0, result : lose board : [[ 16.  32.  64. 128.]\n",
            " [  8.  16.  32.  64.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6865 finished with score 1096.0, result : lose board : [[ 2.  8. 64. 32.]\n",
            " [ 4. 32.  4.  2.]\n",
            " [16. 64.  2. 16.]\n",
            " [ 2. 32.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6870 finished with score 2168.0, result : lose board : [[2.0, 16.0, 32.0, 2.0], [8.0, 64.0, 2.0, 128.0], [4.0, 32.0, 128.0, 4.0], [2, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6875 finished with score 1560.0, result : lose board : [[  4.   2.   8.   2.]\n",
            " [  2.  32.  64.   4.]\n",
            " [  4.  64. 128.  16.]\n",
            " [  8.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6880 finished with score 2540.0, result : lose board : [[  2.  64. 256.  16.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  2.   4.  16.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 181, Loss : 0.19618287682533264\n",
            "Mini-Batch - 1 Back-Prop : 181, Loss : 0.16563747823238373\n",
            "Mini-Batch - 2 Back-Prop : 181, Loss : 0.19312483072280884\n",
            "Mini-Batch - 3 Back-Prop : 181, Loss : 0.20636099576950073\n",
            "Mini-Batch - 4 Back-Prop : 181, Loss : 0.21658317744731903\n",
            "Mini-Batch - 5 Back-Prop : 181, Loss : 0.21676868200302124\n",
            "Mini-Batch - 6 Back-Prop : 181, Loss : 0.19664499163627625\n",
            "Mini-Batch - 7 Back-Prop : 181, Loss : 0.17745253443717957\n",
            "Mini-Batch - 8 Back-Prop : 181, Loss : 0.20540034770965576\n",
            "Episode 6885 finished with score 1364.0, result : lose board : [[ 16.  32.   2. 128.]\n",
            " [  4.  16.  64.   8.]\n",
            " [  2.   4.  16.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6890 finished with score 4768.0, result : lose board : [[  2.   4.  16.   8.]\n",
            " [ 32. 512.   4.   2.]\n",
            " [ 16.  64.  32.   8.]\n",
            " [  8.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6895 finished with score 592.0, result : lose board : [[16. 32.  2. 16.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6900 finished with score 1384.0, result : lose board : [[ 16.  32.   2. 128.]\n",
            " [  8.   2.  32.  64.]\n",
            " [  4.   8.   2.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6905 finished with score 460.0, result : lose board : [[ 4.  8. 32.  4.]\n",
            " [16. 32.  2.  8.]\n",
            " [ 4.  8. 16.  2.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6910 finished with score 1840.0, result : lose board : [[2.0, 128.0, 4.0, 128.0], [32.0, 8.0, 32.0, 2.0], [2, 4.0, 16.0, 8.0], [4, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6915 finished with score 2188.0, result : lose board : [[2, 4.0, 128.0, 8.0], [16.0, 64.0, 4.0, 128.0], [4.0, 32.0, 16.0, 32.0], [2.0, 8.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 182, Loss : 0.22894051671028137\n",
            "Mini-Batch - 1 Back-Prop : 182, Loss : 0.23322832584381104\n",
            "Mini-Batch - 2 Back-Prop : 182, Loss : 0.23016437888145447\n",
            "Mini-Batch - 3 Back-Prop : 182, Loss : 0.21550866961479187\n",
            "Mini-Batch - 4 Back-Prop : 182, Loss : 0.1883256882429123\n",
            "Mini-Batch - 5 Back-Prop : 182, Loss : 0.1652548760175705\n",
            "Mini-Batch - 6 Back-Prop : 182, Loss : 0.17884473502635956\n",
            "Mini-Batch - 7 Back-Prop : 182, Loss : 0.17433342337608337\n",
            "Mini-Batch - 8 Back-Prop : 182, Loss : 0.21938945353031158\n",
            "Episode 6920 finished with score 1644.0, result : lose board : [[16.0, 4.0, 2.0, 64.0], [8.0, 32.0, 8.0, 2.0], [2.0, 8.0, 128.0, 64.0], [4.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6925 finished with score 2448.0, result : lose board : [[  4.  16.  32.   2.]\n",
            " [  2.   4. 256.   4.]\n",
            " [  4.  32.  64.   8.]\n",
            " [  2.   8.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6930 finished with score 1424.0, result : lose board : [[ 16.  32. 128.   2.]\n",
            " [  2.   8.  64.  16.]\n",
            " [  4.   2.  32.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6935 finished with score 548.0, result : lose board : [[4.0, 8.0, 16.0, 64.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4.0, 8.0], [2.0, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6940 finished with score 1316.0, result : lose board : [[  2.   4. 128.  16.]\n",
            " [  8.   2.  64.   8.]\n",
            " [  4.  16.   8.  32.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 183, Loss : 0.21159064769744873\n",
            "Mini-Batch - 1 Back-Prop : 183, Loss : 0.1986861377954483\n",
            "Mini-Batch - 2 Back-Prop : 183, Loss : 0.19059906899929047\n",
            "Mini-Batch - 3 Back-Prop : 183, Loss : 0.17145085334777832\n",
            "Mini-Batch - 4 Back-Prop : 183, Loss : 0.18318301439285278\n",
            "Mini-Batch - 5 Back-Prop : 183, Loss : 0.2039366364479065\n",
            "Mini-Batch - 6 Back-Prop : 183, Loss : 0.23540881276130676\n",
            "Mini-Batch - 7 Back-Prop : 183, Loss : 0.1905384063720703\n",
            "Mini-Batch - 8 Back-Prop : 183, Loss : 0.19026871025562286\n",
            "Episode 6945 finished with score 1836.0, result : lose board : [[16.0, 128.0, 4.0, 32.0], [8.0, 16.0, 128.0, 4.0], [4.0, 8.0, 16.0, 2.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6950 finished with score 1364.0, result : lose board : [[16.0, 32.0, 4.0, 32.0], [8.0, 16.0, 128.0, 8.0], [2.0, 8.0, 16.0, 32.0], [4, 2.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6955 finished with score 2148.0, result : lose board : [[  2. 128.  16.   2.]\n",
            " [  8.  32.   4.   8.]\n",
            " [ 16. 128.  16.  64.]\n",
            " [  8.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6960 finished with score 3360.0, result : lose board : [[4.0, 64.0, 256.0, 2.0], [16.0, 4.0, 64.0, 4.0], [4.0, 32.0, 8.0, 128.0], [2, 4.0, 16.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6965 finished with score 2460.0, result : lose board : [[ 16.  32.  64. 256.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.   4.   8.]\n",
            " [  2.  16.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6970 finished with score 2984.0, result : lose board : [[  2.  16.   2.   8.]\n",
            " [  8. 256. 128.   4.]\n",
            " [  4.   8.  64.  16.]\n",
            " [  2.  16.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 184, Loss : 0.19596053659915924\n",
            "Mini-Batch - 1 Back-Prop : 184, Loss : 0.18767859041690826\n",
            "Mini-Batch - 2 Back-Prop : 184, Loss : 0.21261490881443024\n",
            "Mini-Batch - 3 Back-Prop : 184, Loss : 0.22559937834739685\n",
            "Mini-Batch - 4 Back-Prop : 184, Loss : 0.18554693460464478\n",
            "Mini-Batch - 5 Back-Prop : 184, Loss : 0.18034228682518005\n",
            "Mini-Batch - 6 Back-Prop : 184, Loss : 0.2139219343662262\n",
            "Mini-Batch - 7 Back-Prop : 184, Loss : 0.17245420813560486\n",
            "Mini-Batch - 8 Back-Prop : 184, Loss : 0.20348314940929413\n",
            "Episode 6975 finished with score 2520.0, result : lose board : [[32.0, 64.0, 128.0, 2.0], [2.0, 16.0, 32.0, 128.0], [4.0, 8.0, 16.0, 64.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6980 finished with score 604.0, result : lose board : [[2, 4.0, 16.0, 2.0], [16.0, 2.0, 4.0, 64.0], [2.0, 32.0, 8.0, 2.0], [4.0, 16.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6985 finished with score 1208.0, result : lose board : [[16.0, 64.0, 16.0, 2.0], [8.0, 32.0, 2.0, 64.0], [4.0, 64.0, 8.0, 4.0], [2, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6990 finished with score 1016.0, result : lose board : [[16.  2.  4. 64.]\n",
            " [ 2. 32. 64. 16.]\n",
            " [ 4. 16. 32.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 6995 finished with score 720.0, result : lose board : [[ 8. 16. 32. 64.]\n",
            " [ 2.  8. 16. 32.]\n",
            " [ 4.  2.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Maximum Score : 6356.0 ,Episode : 5768\n",
            "Loss : 0.1975113252798716\n",
            "\n",
            "Episode 7000 finished with score 868.0, result : lose board : [[16.  2. 32. 64.]\n",
            " [ 8. 16.  4. 32.]\n",
            " [ 4.  8. 32. 16.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7005 finished with score 2212.0, result : lose board : [[2.0, 8.0, 128.0, 2.0], [32.0, 16.0, 64.0, 128.0], [2.0, 4.0, 16.0, 32.0], [4, 2, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 185, Loss : 0.2061266303062439\n",
            "Mini-Batch - 1 Back-Prop : 185, Loss : 0.21724900603294373\n",
            "Mini-Batch - 2 Back-Prop : 185, Loss : 0.2342350333929062\n",
            "Mini-Batch - 3 Back-Prop : 185, Loss : 0.21633580327033997\n",
            "Mini-Batch - 4 Back-Prop : 185, Loss : 0.19963374733924866\n",
            "Mini-Batch - 5 Back-Prop : 185, Loss : 0.18256130814552307\n",
            "Mini-Batch - 6 Back-Prop : 185, Loss : 0.17090179026126862\n",
            "Mini-Batch - 7 Back-Prop : 185, Loss : 0.1957274079322815\n",
            "Mini-Batch - 8 Back-Prop : 185, Loss : 0.22599714994430542\n",
            "Episode 7010 finished with score 1344.0, result : lose board : [[  2.   8.  16. 128.]\n",
            " [  8.  64.   2.   4.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7015 finished with score 1608.0, result : lose board : [[32.0, 64.0, 128.0, 8.0], [2.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7020 finished with score 816.0, result : lose board : [[ 2. 16.  2. 32.]\n",
            " [ 8. 32. 64.  8.]\n",
            " [ 4.  8. 32.  4.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7025 finished with score 328.0, result : lose board : [[2.0, 8.0, 16.0, 32.0], [8.0, 2.0, 4.0, 16.0], [2.0, 8.0, 16.0, 8.0], [4.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7030 finished with score 1332.0, result : lose board : [[2, 4.0, 128.0, 8.0], [8.0, 64.0, 32.0, 2.0], [4.0, 16.0, 8.0, 16.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7035 finished with score 820.0, result : lose board : [[16. 32.  4. 32.]\n",
            " [ 8.  4.  2. 64.]\n",
            " [ 4. 32. 16.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 186, Loss : 0.20173808932304382\n",
            "Mini-Batch - 1 Back-Prop : 186, Loss : 0.18766263127326965\n",
            "Mini-Batch - 2 Back-Prop : 186, Loss : 0.21394950151443481\n",
            "Mini-Batch - 3 Back-Prop : 186, Loss : 0.22675909101963043\n",
            "Mini-Batch - 4 Back-Prop : 186, Loss : 0.1744457483291626\n",
            "Mini-Batch - 5 Back-Prop : 186, Loss : 0.1675643026828766\n",
            "Mini-Batch - 6 Back-Prop : 186, Loss : 0.21325379610061646\n",
            "Mini-Batch - 7 Back-Prop : 186, Loss : 0.2071143388748169\n",
            "Mini-Batch - 8 Back-Prop : 186, Loss : 0.19967418909072876\n",
            "Episode 7040 finished with score 1336.0, result : lose board : [[  2.  16.  64. 128.]\n",
            " [  4.   2.   4.  16.]\n",
            " [  8.  32.   8.   4.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7045 finished with score 1108.0, result : lose board : [[2, 4.0, 32.0, 128.0], [8.0, 32.0, 4.0, 2.0], [4.0, 8.0, 2.0, 16.0], [2.0, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7050 finished with score 584.0, result : lose board : [[4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 32.0], [4.0, 8.0, 4.0, 2], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7055 finished with score 3012.0, result : lose board : [[2, 4.0, 16.0, 4.0], [8.0, 64.0, 128.0, 256.0], [4.0, 16.0, 8.0, 16.0], [2.0, 4.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7060 finished with score 1720.0, result : lose board : [[  2.   8.  64. 128.]\n",
            " [  8.  32.   8.  64.]\n",
            " [  2.  16.  32.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7065 finished with score 744.0, result : lose board : [[ 4. 16.  2. 16.]\n",
            " [ 8. 32. 64.  4.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 187, Loss : 0.1828501969575882\n",
            "Mini-Batch - 1 Back-Prop : 187, Loss : 0.19854587316513062\n",
            "Mini-Batch - 2 Back-Prop : 187, Loss : 0.22805090248584747\n",
            "Mini-Batch - 3 Back-Prop : 187, Loss : 0.17727258801460266\n",
            "Mini-Batch - 4 Back-Prop : 187, Loss : 0.1856507807970047\n",
            "Mini-Batch - 5 Back-Prop : 187, Loss : 0.1885751485824585\n",
            "Mini-Batch - 6 Back-Prop : 187, Loss : 0.16883313655853271\n",
            "Mini-Batch - 7 Back-Prop : 187, Loss : 0.19312167167663574\n",
            "Mini-Batch - 8 Back-Prop : 187, Loss : 0.1756526231765747\n",
            "Episode 7070 finished with score 2564.0, result : lose board : [[  4.  64. 256.  16.]\n",
            " [  8.   4.  64.   2.]\n",
            " [  2.   8.  16.   4.]\n",
            " [ 16.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7075 finished with score 1820.0, result : lose board : [[ 16.  64. 128.  32.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  2.   8.  16.  32.]\n",
            " [  4.   2.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode : 7079, Score : 5648.0, Iters : 400, Finish : Game not over\n",
            "Episode 7080 finished with score 1300.0, result : lose board : [[4.0, 2.0, 4.0, 2.0], [16.0, 32.0, 128.0, 64.0], [4.0, 8.0, 16.0, 4.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7085 finished with score 680.0, result : lose board : [[ 2.  8. 16. 32.]\n",
            " [16.  4. 64. 16.]\n",
            " [ 4.  8. 16.  8.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7090 finished with score 804.0, result : lose board : [[8.0, 32.0, 64.0, 4.0], [4.0, 8.0, 32.0, 8.0], [2.0, 4.0, 16.0, 32.0], [4, 2, 4, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7095 finished with score 2064.0, result : lose board : [[  4.  16.  32. 256.]\n",
            " [  2.   4.  16.   8.]\n",
            " [  4.   2.   8.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 188, Loss : 0.2091733068227768\n",
            "Mini-Batch - 1 Back-Prop : 188, Loss : 0.22079527378082275\n",
            "Mini-Batch - 2 Back-Prop : 188, Loss : 0.17334289848804474\n",
            "Mini-Batch - 3 Back-Prop : 188, Loss : 0.22774255275726318\n",
            "Mini-Batch - 4 Back-Prop : 188, Loss : 0.19292470812797546\n",
            "Mini-Batch - 5 Back-Prop : 188, Loss : 0.21512481570243835\n",
            "Mini-Batch - 6 Back-Prop : 188, Loss : 0.17981372773647308\n",
            "Mini-Batch - 7 Back-Prop : 188, Loss : 0.18845225870609283\n",
            "Mini-Batch - 8 Back-Prop : 188, Loss : 0.1775004267692566\n",
            "Episode 7100 finished with score 3076.0, result : lose board : [[ 16.  32. 128.   4.]\n",
            " [  8.  16.   8. 256.]\n",
            " [  4.   8.   2.  64.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7105 finished with score 3020.0, result : lose board : [[2.0, 8.0, 4.0, 256.0], [8.0, 64.0, 128.0, 8.0], [2.0, 8.0, 32.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7110 finished with score 972.0, result : lose board : [[32. 64.  4.  8.]\n",
            " [ 4. 16. 64.  2.]\n",
            " [ 2.  8. 16.  8.]\n",
            " [ 8. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7115 finished with score 1056.0, result : lose board : [[16.0, 32.0, 2.0, 64.0], [32.0, 64.0, 16.0, 4.0], [4.0, 16.0, 4.0, 2.0], [2, 4, 16.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7120 finished with score 860.0, result : lose board : [[16.0, 32.0, 2.0, 32.0], [2.0, 4.0, 64.0, 8.0], [8.0, 16.0, 32.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7125 finished with score 5520.0, result : lose board : [[ 16.  32.   4. 512.]\n",
            " [  8. 128.  64.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 189, Loss : 0.1905234009027481\n",
            "Mini-Batch - 1 Back-Prop : 189, Loss : 0.1692897528409958\n",
            "Mini-Batch - 2 Back-Prop : 189, Loss : 0.17253150045871735\n",
            "Mini-Batch - 3 Back-Prop : 189, Loss : 0.18311621248722076\n",
            "Mini-Batch - 4 Back-Prop : 189, Loss : 0.21180135011672974\n",
            "Mini-Batch - 5 Back-Prop : 189, Loss : 0.2225596308708191\n",
            "Mini-Batch - 6 Back-Prop : 189, Loss : 0.22715923190116882\n",
            "Mini-Batch - 7 Back-Prop : 189, Loss : 0.19303549826145172\n",
            "Mini-Batch - 8 Back-Prop : 189, Loss : 0.22632616758346558\n",
            "Episode 7130 finished with score 1124.0, result : lose board : [[ 16.   2.  32. 128.]\n",
            " [  8.  16.   2.  16.]\n",
            " [  2.   8.  16.   4.]\n",
            " [  4.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7135 finished with score 488.0, result : lose board : [[ 8. 32.  2. 32.]\n",
            " [ 4.  8. 32.  8.]\n",
            " [ 2.  4. 16.  4.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7140 finished with score 788.0, result : lose board : [[16. 32.  2. 16.]\n",
            " [ 8. 16. 64.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7145 finished with score 1348.0, result : lose board : [[16.0, 64.0, 4.0, 32.0], [8.0, 32.0, 64.0, 16.0], [4.0, 64.0, 16.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7150 finished with score 300.0, result : lose board : [[ 4.  8. 16. 32.]\n",
            " [ 8. 16.  4.  2.]\n",
            " [ 4.  8.  2.  8.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7155 finished with score 1360.0, result : lose board : [[  8.   2.   4.   2.]\n",
            " [ 16.  32. 128.  32.]\n",
            " [  4.   8.  32.   8.]\n",
            " [  8.  32.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 190, Loss : 0.16944144666194916\n",
            "Mini-Batch - 1 Back-Prop : 190, Loss : 0.19525906443595886\n",
            "Mini-Batch - 2 Back-Prop : 190, Loss : 0.1907760202884674\n",
            "Mini-Batch - 3 Back-Prop : 190, Loss : 0.17725002765655518\n",
            "Mini-Batch - 4 Back-Prop : 190, Loss : 0.20945028960704803\n",
            "Mini-Batch - 5 Back-Prop : 190, Loss : 0.17249059677124023\n",
            "Mini-Batch - 6 Back-Prop : 190, Loss : 0.21534043550491333\n",
            "Mini-Batch - 7 Back-Prop : 190, Loss : 0.21387328207492828\n",
            "Mini-Batch - 8 Back-Prop : 190, Loss : 0.20394010841846466\n",
            "Episode 7160 finished with score 968.0, result : lose board : [[8.0, 2.0, 4.0, 64.0], [2, 16.0, 64.0, 4.0], [4.0, 32.0, 8.0, 32.0], [2.0, 8.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7165 finished with score 2520.0, result : lose board : [[ 16.  32. 256.  16.]\n",
            " [  4.  16.  64.   8.]\n",
            " [  2.   8.  32.   4.]\n",
            " [  4.   2.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7170 finished with score 1600.0, result : lose board : [[16.0, 64.0, 128.0, 16.0], [2.0, 16.0, 64.0, 8.0], [4.0, 8.0, 16.0, 4.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7175 finished with score 2956.0, result : lose board : [[16.0, 4.0, 256.0, 32.0], [8.0, 16.0, 128.0, 16.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7180 finished with score 1384.0, result : lose board : [[16.0, 4.0, 16.0, 4.0], [8.0, 16.0, 128.0, 8.0], [4.0, 32.0, 64.0, 4.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7185 finished with score 2944.0, result : lose board : [[  2.   4.   2.   4.]\n",
            " [  8.  16. 256.   8.]\n",
            " [  4.   8.  64. 128.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 191, Loss : 0.19672845304012299\n",
            "Mini-Batch - 1 Back-Prop : 191, Loss : 0.15768960118293762\n",
            "Mini-Batch - 2 Back-Prop : 191, Loss : 0.19500476121902466\n",
            "Mini-Batch - 3 Back-Prop : 191, Loss : 0.15880706906318665\n",
            "Mini-Batch - 4 Back-Prop : 191, Loss : 0.20598283410072327\n",
            "Mini-Batch - 5 Back-Prop : 191, Loss : 0.22291234135627747\n",
            "Mini-Batch - 6 Back-Prop : 191, Loss : 0.2001294493675232\n",
            "Mini-Batch - 7 Back-Prop : 191, Loss : 0.21489317715168\n",
            "Mini-Batch - 8 Back-Prop : 191, Loss : 0.23798078298568726\n",
            "Episode 7190 finished with score 860.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 64.  8.]\n",
            " [ 4.  2. 32.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7195 finished with score 2740.0, result : lose board : [[2.0, 64.0, 2.0, 4.0], [16.0, 256.0, 64.0, 2.0], [2, 64.0, 8.0, 4.0], [4.0, 16.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7200 finished with score 1412.0, result : lose board : [[  8.   2. 128.   8.]\n",
            " [ 16.  32.  64.  16.]\n",
            " [  4.   8.  16.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7205 finished with score 2764.0, result : lose board : [[8.0, 32.0, 2.0, 256.0], [2.0, 8.0, 128.0, 8.0], [4.0, 2.0, 16.0, 2.0], [2, 4, 2.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7210 finished with score 3124.0, result : lose board : [[ 16.   4. 128.   2.]\n",
            " [  8.  16.  32. 256.]\n",
            " [  4.   2.  16.  64.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7215 finished with score 1584.0, result : lose board : [[16.0, 32.0, 128.0, 32.0], [8.0, 16.0, 64.0, 2.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 192, Loss : 0.18643882870674133\n",
            "Mini-Batch - 1 Back-Prop : 192, Loss : 0.20403176546096802\n",
            "Mini-Batch - 2 Back-Prop : 192, Loss : 0.16724881529808044\n",
            "Mini-Batch - 3 Back-Prop : 192, Loss : 0.17856310307979584\n",
            "Mini-Batch - 4 Back-Prop : 192, Loss : 0.17345964908599854\n",
            "Mini-Batch - 5 Back-Prop : 192, Loss : 0.18138441443443298\n",
            "Mini-Batch - 6 Back-Prop : 192, Loss : 0.2269413024187088\n",
            "Mini-Batch - 7 Back-Prop : 192, Loss : 0.18321378529071808\n",
            "Mini-Batch - 8 Back-Prop : 192, Loss : 0.16937026381492615\n",
            "Episode 7220 finished with score 2464.0, result : lose board : [[32.0, 64.0, 4.0, 128.0], [8.0, 16.0, 128.0, 32.0], [4.0, 8.0, 64.0, 8.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7225 finished with score 1676.0, result : lose board : [[4, 16.0, 2.0, 4.0], [16.0, 32.0, 128.0, 64.0], [4.0, 64.0, 16.0, 2.0], [2.0, 8.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7230 finished with score 1144.0, result : lose board : [[16.0, 64.0, 4.0, 2.0], [4.0, 16.0, 2.0, 64.0], [8.0, 64.0, 32.0, 2], [2, 4, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7235 finished with score 2744.0, result : lose board : [[  2.   4. 256.   8.]\n",
            " [ 16.   8.  64.   4.]\n",
            " [  4.  32.  16.  64.]\n",
            " [  2.   4.   2.  32.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7240 finished with score 2272.0, result : lose board : [[  4.   2.   8.   2.]\n",
            " [  8.   4.  64. 256.]\n",
            " [  4.  32.   4.  16.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7245 finished with score 716.0, result : lose board : [[8.0, 2.0, 64.0, 2.0], [4.0, 8.0, 2.0, 64.0], [2.0, 4.0, 8.0, 4.0], [4, 2, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 193, Loss : 0.20134875178337097\n",
            "Mini-Batch - 1 Back-Prop : 193, Loss : 0.22092531621456146\n",
            "Mini-Batch - 2 Back-Prop : 193, Loss : 0.17573273181915283\n",
            "Mini-Batch - 3 Back-Prop : 193, Loss : 0.2117917388677597\n",
            "Mini-Batch - 4 Back-Prop : 193, Loss : 0.18339374661445618\n",
            "Mini-Batch - 5 Back-Prop : 193, Loss : 0.1620723456144333\n",
            "Mini-Batch - 6 Back-Prop : 193, Loss : 0.21942238509655\n",
            "Mini-Batch - 7 Back-Prop : 193, Loss : 0.20366059243679047\n",
            "Mini-Batch - 8 Back-Prop : 193, Loss : 0.1976727694272995\n",
            "Episode 7250 finished with score 1004.0, result : lose board : [[8.0, 32.0, 64.0, 4.0], [4.0, 2.0, 16.0, 64.0], [2.0, 4.0, 32.0, 16.0], [4, 2.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7255 finished with score 1632.0, result : lose board : [[ 16. 128.  64.   4.]\n",
            " [  4.  64.   2.  16.]\n",
            " [  8.  32.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7260 finished with score 968.0, result : lose board : [[16.0, 2.0, 8.0, 64.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7265 finished with score 1820.0, result : lose board : [[32.0, 64.0, 2.0, 16.0], [8.0, 32.0, 128.0, 8.0], [4.0, 8.0, 32.0, 64.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7270 finished with score 928.0, result : lose board : [[32.  8. 64. 16.]\n",
            " [ 8. 16. 32.  4.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7275 finished with score 1496.0, result : lose board : [[ 16.  32.   2. 128.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  4.   2.  16.   4.]\n",
            " [  2.   8.  32.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7280 finished with score 976.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [8.0, 4.0, 2.0, 64.0], [4.0, 32.0, 16.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 194, Loss : 0.17129158973693848\n",
            "Mini-Batch - 1 Back-Prop : 194, Loss : 0.1943897008895874\n",
            "Mini-Batch - 2 Back-Prop : 194, Loss : 0.1936565339565277\n",
            "Mini-Batch - 3 Back-Prop : 194, Loss : 0.1910524219274521\n",
            "Mini-Batch - 4 Back-Prop : 194, Loss : 0.20834074914455414\n",
            "Mini-Batch - 5 Back-Prop : 194, Loss : 0.18447047472000122\n",
            "Mini-Batch - 6 Back-Prop : 194, Loss : 0.19191324710845947\n",
            "Mini-Batch - 7 Back-Prop : 194, Loss : 0.16647404432296753\n",
            "Mini-Batch - 8 Back-Prop : 194, Loss : 0.19106435775756836\n",
            "Episode 7285 finished with score 2660.0, result : lose board : [[ 16.  64. 256.   8.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7290 finished with score 676.0, result : lose board : [[4.0, 16.0, 32.0, 64.0], [2, 4, 2, 32.0], [8.0, 16.0, 4.0, 2.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7295 finished with score 776.0, result : lose board : [[ 2. 16. 32. 64.]\n",
            " [16.  8. 16.  2.]\n",
            " [ 4. 16. 32.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7300 finished with score 864.0, result : lose board : [[ 4. 64.  8.  4.]\n",
            " [ 8.  4. 64.  8.]\n",
            " [ 4. 32. 16.  2.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7305 finished with score 1036.0, result : lose board : [[16. 32. 16. 64.]\n",
            " [ 8. 64.  8.  2.]\n",
            " [ 4. 32.  2.  4.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7310 finished with score 1464.0, result : lose board : [[2.0, 16.0, 64.0, 4.0], [32.0, 8.0, 128.0, 8.0], [8.0, 32.0, 8.0, 4.0], [2, 4.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7315 finished with score 1412.0, result : lose board : [[32.0, 2.0, 4.0, 64.0], [8.0, 16.0, 32.0, 128.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 195, Loss : 0.18604525923728943\n",
            "Mini-Batch - 1 Back-Prop : 195, Loss : 0.18003644049167633\n",
            "Mini-Batch - 2 Back-Prop : 195, Loss : 0.18428227305412292\n",
            "Mini-Batch - 3 Back-Prop : 195, Loss : 0.20406551659107208\n",
            "Mini-Batch - 4 Back-Prop : 195, Loss : 0.2017306238412857\n",
            "Mini-Batch - 5 Back-Prop : 195, Loss : 0.15985409915447235\n",
            "Mini-Batch - 6 Back-Prop : 195, Loss : 0.15535299479961395\n",
            "Mini-Batch - 7 Back-Prop : 195, Loss : 0.18329975008964539\n",
            "Mini-Batch - 8 Back-Prop : 195, Loss : 0.21249252557754517\n",
            "Episode 7320 finished with score 624.0, result : lose board : [[ 4. 16. 64.  2.]\n",
            " [16. 32.  8.  4.]\n",
            " [ 4.  8. 16.  2.]\n",
            " [ 8.  2.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7325 finished with score 1344.0, result : lose board : [[4.0, 8.0, 128.0, 2.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 32.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7330 finished with score 1784.0, result : lose board : [[  2.   4.  16.  32.]\n",
            " [  4.   2. 128.   8.]\n",
            " [  8. 128.   8.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7335 finished with score 564.0, result : lose board : [[2.0, 16.0, 4.0, 32.0], [8.0, 64.0, 2.0, 4.0], [2, 4.0, 8.0, 16.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7340 finished with score 2448.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [8.0, 16.0, 256.0, 4.0], [4.0, 8.0, 32.0, 8.0], [8, 4, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7345 finished with score 1616.0, result : lose board : [[4.0, 32.0, 2.0, 16.0], [2.0, 8.0, 128.0, 64.0], [4, 16.0, 64.0, 8.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 196, Loss : 0.19770707190036774\n",
            "Mini-Batch - 1 Back-Prop : 196, Loss : 0.20392009615898132\n",
            "Mini-Batch - 2 Back-Prop : 196, Loss : 0.18773533403873444\n",
            "Mini-Batch - 3 Back-Prop : 196, Loss : 0.1719348430633545\n",
            "Mini-Batch - 4 Back-Prop : 196, Loss : 0.16914701461791992\n",
            "Mini-Batch - 5 Back-Prop : 196, Loss : 0.22349336743354797\n",
            "Mini-Batch - 6 Back-Prop : 196, Loss : 0.1915828138589859\n",
            "Mini-Batch - 7 Back-Prop : 196, Loss : 0.1665780246257782\n",
            "Mini-Batch - 8 Back-Prop : 196, Loss : 0.18297246098518372\n",
            "Episode 7350 finished with score 2432.0, result : lose board : [[  2.   4.  16.   2.]\n",
            " [  4.  64. 256.   4.]\n",
            " [ 32.  16.  32.  16.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7355 finished with score 1156.0, result : lose board : [[16.0, 2.0, 64.0, 8.0], [4.0, 16.0, 32.0, 64.0], [2.0, 32.0, 8.0, 32.0], [4.0, 2.0, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7360 finished with score 1576.0, result : lose board : [[ 16.  32.  64. 128.]\n",
            " [  8.  16.  32.   4.]\n",
            " [  4.   8.   2.  32.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7365 finished with score 896.0, result : lose board : [[16.0, 64.0, 8.0, 32.0], [8.0, 4.0, 64.0, 2.0], [4.0, 16.0, 2.0, 8.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7370 finished with score 512.0, result : lose board : [[4.0, 8.0, 16.0, 64.0], [2.0, 4.0, 8.0, 16.0], [4, 16.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7375 finished with score 1552.0, result : lose board : [[ 16.  32. 128.  16.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7380 finished with score 1076.0, result : lose board : [[16. 32. 64.  8.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 16. 64.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 197, Loss : 0.1685926914215088\n",
            "Mini-Batch - 1 Back-Prop : 197, Loss : 0.1667705923318863\n",
            "Mini-Batch - 2 Back-Prop : 197, Loss : 0.16492365300655365\n",
            "Mini-Batch - 3 Back-Prop : 197, Loss : 0.1772129088640213\n",
            "Mini-Batch - 4 Back-Prop : 197, Loss : 0.21326462924480438\n",
            "Mini-Batch - 5 Back-Prop : 197, Loss : 0.19385497272014618\n",
            "Mini-Batch - 6 Back-Prop : 197, Loss : 0.20250779390335083\n",
            "Mini-Batch - 7 Back-Prop : 197, Loss : 0.17216065526008606\n",
            "Mini-Batch - 8 Back-Prop : 197, Loss : 0.18640445172786713\n",
            "Episode 7385 finished with score 1952.0, result : lose board : [[2.0, 16.0, 4.0, 128.0], [8.0, 32.0, 128.0, 2.0], [4.0, 2.0, 8.0, 32.0], [2.0, 32.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7390 finished with score 1972.0, result : lose board : [[  4.  64. 128.   8.]\n",
            " [  2.   8.  32. 128.]\n",
            " [  4.   2.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7395 finished with score 1452.0, result : lose board : [[2.0, 16.0, 32.0, 128.0], [16.0, 4.0, 64.0, 2.0], [2, 8.0, 32.0, 8.0], [8.0, 2.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7400 finished with score 708.0, result : lose board : [[64.0, 4.0, 2.0, 16.0], [8.0, 2.0, 8.0, 32.0], [4.0, 8.0, 32.0, 4.0], [8, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7405 finished with score 1700.0, result : lose board : [[ 64. 128.  16.  64.]\n",
            " [  8.  32.   8.   4.]\n",
            " [  4.   8.  16.   8.]\n",
            " [  2.  16.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7410 finished with score 3148.0, result : lose board : [[32.0, 64.0, 256.0, 8.0], [16.0, 32.0, 64.0, 2.0], [2.0, 16.0, 32.0, 64.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7415 finished with score 1500.0, result : lose board : [[16.0, 2.0, 64.0, 2.0], [2.0, 32.0, 16.0, 128.0], [8.0, 16.0, 32.0, 8.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 198, Loss : 0.2038167119026184\n",
            "Mini-Batch - 1 Back-Prop : 198, Loss : 0.18347172439098358\n",
            "Mini-Batch - 2 Back-Prop : 198, Loss : 0.14973868429660797\n",
            "Mini-Batch - 3 Back-Prop : 198, Loss : 0.2023727148771286\n",
            "Mini-Batch - 4 Back-Prop : 198, Loss : 0.20985688269138336\n",
            "Mini-Batch - 5 Back-Prop : 198, Loss : 0.20464228093624115\n",
            "Mini-Batch - 6 Back-Prop : 198, Loss : 0.22483403980731964\n",
            "Mini-Batch - 7 Back-Prop : 198, Loss : 0.21644213795661926\n",
            "Mini-Batch - 8 Back-Prop : 198, Loss : 0.19264914095401764\n",
            "Episode 7420 finished with score 4004.0, result : lose board : [[ 16.  32. 128.   8.]\n",
            " [  8. 128.  64. 256.]\n",
            " [  4.  16.  32.   8.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7425 finished with score 2468.0, result : lose board : [[16.0, 64.0, 16.0, 128.0], [8.0, 16.0, 128.0, 8.0], [4.0, 8.0, 32.0, 64.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7430 finished with score 1944.0, result : lose board : [[16.0, 4.0, 16.0, 4.0], [2.0, 64.0, 2.0, 128.0], [4.0, 128.0, 16.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7435 finished with score 2800.0, result : lose board : [[  4.   2.   4.   8.]\n",
            " [  2. 128. 256.   4.]\n",
            " [ 16.  32.  16.   8.]\n",
            " [  4.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7440 finished with score 412.0, result : lose board : [[4.0, 16.0, 2.0, 32.0], [2.0, 8.0, 32.0, 16.0], [8.0, 4.0, 16.0, 4.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7445 finished with score 2632.0, result : lose board : [[16.0, 64.0, 8.0, 2.0], [4.0, 16.0, 64.0, 4.0], [2, 4.0, 32.0, 256.0], [4.0, 8.0, 2.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 199, Loss : 0.16543491184711456\n",
            "Mini-Batch - 1 Back-Prop : 199, Loss : 0.19805908203125\n",
            "Mini-Batch - 2 Back-Prop : 199, Loss : 0.21171024441719055\n",
            "Mini-Batch - 3 Back-Prop : 199, Loss : 0.19502343237400055\n",
            "Mini-Batch - 4 Back-Prop : 199, Loss : 0.20205000042915344\n",
            "Mini-Batch - 5 Back-Prop : 199, Loss : 0.18954576551914215\n",
            "Mini-Batch - 6 Back-Prop : 199, Loss : 0.19954025745391846\n",
            "Mini-Batch - 7 Back-Prop : 199, Loss : 0.1746009886264801\n",
            "Mini-Batch - 8 Back-Prop : 199, Loss : 0.2140105962753296\n",
            "Episode 7450 finished with score 1452.0, result : lose board : [[ 16.  32.  64.   2.]\n",
            " [  2.   8.  16. 128.]\n",
            " [  4.   2.  32.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7455 finished with score 904.0, result : lose board : [[8.0, 32.0, 64.0, 16.0], [4.0, 16.0, 32.0, 8.0], [8.0, 32.0, 16.0, 2.0], [4, 2, 4.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7460 finished with score 1052.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 64.  8.]\n",
            " [ 2.  8. 16. 64.]\n",
            " [ 4.  2.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7465 finished with score 1340.0, result : lose board : [[ 16. 128.   2.  16.]\n",
            " [  2.  32.  64.   8.]\n",
            " [  4.   8.  16.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7470 finished with score 2172.0, result : lose board : [[16.0, 32.0, 256.0, 4.0], [8.0, 16.0, 8.0, 32.0], [4.0, 8.0, 4, 2], [2, 4, 2, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7475 finished with score 1292.0, result : lose board : [[2.0, 8.0, 32.0, 128.0], [16.0, 4.0, 8.0, 32.0], [4.0, 16.0, 32.0, 8.0], [2, 4.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 200, Loss : 0.22310477495193481\n",
            "Mini-Batch - 1 Back-Prop : 200, Loss : 0.18752002716064453\n",
            "Mini-Batch - 2 Back-Prop : 200, Loss : 0.183442622423172\n",
            "Mini-Batch - 3 Back-Prop : 200, Loss : 0.17602960765361786\n",
            "Mini-Batch - 4 Back-Prop : 200, Loss : 0.16221219301223755\n",
            "Mini-Batch - 5 Back-Prop : 200, Loss : 0.21124878525733948\n",
            "Mini-Batch - 6 Back-Prop : 200, Loss : 0.21419799327850342\n",
            "Mini-Batch - 7 Back-Prop : 200, Loss : 0.18967106938362122\n",
            "Mini-Batch - 8 Back-Prop : 200, Loss : 0.19962078332901\n",
            "Episode 7480 finished with score 1560.0, result : lose board : [[32.0, 64.0, 128.0, 2.0], [8.0, 16.0, 2.0, 32.0], [4.0, 8.0, 32.0, 16.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7485 finished with score 1952.0, result : lose board : [[2.0, 4.0, 128.0, 4.0], [8.0, 128.0, 16.0, 2.0], [2, 64.0, 8.0, 4], [4.0, 2.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7490 finished with score 1856.0, result : lose board : [[ 32.   4. 128.   8.]\n",
            " [  8.   2.  32. 128.]\n",
            " [  4.   8.  16.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7495 finished with score 1008.0, result : lose board : [[16.0, 32.0, 128.0, 2], [4.0, 2.0, 8.0, 16.0], [2, 4.0, 2.0, 8.0], [4, 8, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7500 finished with score 2220.0, result : lose board : [[4.0, 2.0, 32.0, 256.0], [8.0, 32.0, 4.0, 2.0], [4.0, 8.0, 32.0, 16.0], [2, 4, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7505 finished with score 1928.0, result : lose board : [[16.0, 2.0, 128.0, 4.0], [8.0, 16.0, 32.0, 128.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 201, Loss : 0.21473096311092377\n",
            "Mini-Batch - 1 Back-Prop : 201, Loss : 0.17804409563541412\n",
            "Mini-Batch - 2 Back-Prop : 201, Loss : 0.16416431963443756\n",
            "Mini-Batch - 3 Back-Prop : 201, Loss : 0.22044280171394348\n",
            "Mini-Batch - 4 Back-Prop : 201, Loss : 0.1689661741256714\n",
            "Mini-Batch - 5 Back-Prop : 201, Loss : 0.19486838579177856\n",
            "Mini-Batch - 6 Back-Prop : 201, Loss : 0.17130185663700104\n",
            "Mini-Batch - 7 Back-Prop : 201, Loss : 0.1783665418624878\n",
            "Mini-Batch - 8 Back-Prop : 201, Loss : 0.1695878505706787\n",
            "Episode 7510 finished with score 1520.0, result : lose board : [[16.0, 64.0, 2.0, 32.0], [4.0, 16.0, 128.0, 16.0], [2.0, 4.0, 32.0, 8.0], [16.0, 8, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7515 finished with score 852.0, result : lose board : [[ 2. 16.  4. 32.]\n",
            " [16. 64. 32.  8.]\n",
            " [ 8. 32. 16.  4.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7520 finished with score 1304.0, result : lose board : [[ 16.  32.   4. 128.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7525 finished with score 3324.0, result : lose board : [[2.0, 32.0, 64.0, 4.0], [8.0, 2.0, 128.0, 256.0], [4.0, 8.0, 64.0, 16.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7530 finished with score 1480.0, result : lose board : [[2, 4.0, 128.0, 2.0], [32.0, 2.0, 32.0, 16.0], [8.0, 64.0, 16.0, 2.0], [4.0, 16.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7535 finished with score 1496.0, result : lose board : [[16.0, 32.0, 128.0, 2.0], [8.0, 16.0, 32.0, 64.0], [2.0, 4.0, 16.0, 8.0], [4, 2, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7540 finished with score 1392.0, result : lose board : [[ 32.   8.   4.  16.]\n",
            " [  4.  32.   2.   8.]\n",
            " [  2. 128.  64.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 202, Loss : 0.16061729192733765\n",
            "Mini-Batch - 1 Back-Prop : 202, Loss : 0.1820635348558426\n",
            "Mini-Batch - 2 Back-Prop : 202, Loss : 0.16741563379764557\n",
            "Mini-Batch - 3 Back-Prop : 202, Loss : 0.20014408230781555\n",
            "Mini-Batch - 4 Back-Prop : 202, Loss : 0.17492513358592987\n",
            "Mini-Batch - 5 Back-Prop : 202, Loss : 0.17461951076984406\n",
            "Mini-Batch - 6 Back-Prop : 202, Loss : 0.16145917773246765\n",
            "Mini-Batch - 7 Back-Prop : 202, Loss : 0.15858577191829681\n",
            "Mini-Batch - 8 Back-Prop : 202, Loss : 0.18729561567306519\n",
            "Episode 7545 finished with score 1168.0, result : lose board : [[8.0, 32.0, 2.0, 128.0], [4.0, 16.0, 32.0, 2.0], [2.0, 4.0, 16.0, 4.0], [4, 2, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7550 finished with score 3248.0, result : lose board : [[  2.   4. 256.  16.]\n",
            " [ 32. 128.  32.   2.]\n",
            " [ 16.   8.  16.  64.]\n",
            " [  4.   2.   4.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7555 finished with score 1836.0, result : lose board : [[  2.  32.  64. 128.]\n",
            " [  8.   4.  32.  64.]\n",
            " [  4.  32.  16.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7560 finished with score 1360.0, result : lose board : [[  8.  16.  32. 128.]\n",
            " [  2.   8.  16.  64.]\n",
            " [  4.   2.   8.   4.]\n",
            " [  2.   8.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7565 finished with score 1180.0, result : lose board : [[16.0, 32.0, 4.0, 32.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 32.0, 64.0], [2, 4, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 203, Loss : 0.1283397525548935\n",
            "Mini-Batch - 1 Back-Prop : 203, Loss : 0.15545551478862762\n",
            "Mini-Batch - 2 Back-Prop : 203, Loss : 0.17888502776622772\n",
            "Mini-Batch - 3 Back-Prop : 203, Loss : 0.1618739366531372\n",
            "Mini-Batch - 4 Back-Prop : 203, Loss : 0.15463867783546448\n",
            "Mini-Batch - 5 Back-Prop : 203, Loss : 0.1576680988073349\n",
            "Mini-Batch - 6 Back-Prop : 203, Loss : 0.18458250164985657\n",
            "Mini-Batch - 7 Back-Prop : 203, Loss : 0.2023642361164093\n",
            "Mini-Batch - 8 Back-Prop : 203, Loss : 0.17437028884887695\n",
            "Episode 7570 finished with score 3084.0, result : lose board : [[  4.  16. 256.  32.]\n",
            " [ 16. 128.  32.   8.]\n",
            " [  4.  32.  16.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7575 finished with score 2816.0, result : lose board : [[8.0, 2.0, 256.0, 16.0], [16.0, 128.0, 8.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7580 finished with score 3352.0, result : lose board : [[  2.   4.   8.   4.]\n",
            " [  8. 128. 256.   8.]\n",
            " [  4.   8. 128.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7585 finished with score 448.0, result : lose board : [[8.0, 32.0, 2.0, 32.0], [4.0, 2.0, 32.0, 2.0], [2.0, 4.0, 16.0, 8.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7590 finished with score 1572.0, result : lose board : [[  4.  64.   4.   8.]\n",
            " [  2.   4. 128.  64.]\n",
            " [  8.   2.  32.   4.]\n",
            " [  2.   8.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7595 finished with score 1068.0, result : lose board : [[ 2. 16. 32.  4.]\n",
            " [ 8. 64. 16. 64.]\n",
            " [ 4.  8. 32. 16.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 204, Loss : 0.17633572220802307\n",
            "Mini-Batch - 1 Back-Prop : 204, Loss : 0.1453101485967636\n",
            "Mini-Batch - 2 Back-Prop : 204, Loss : 0.1712692528963089\n",
            "Mini-Batch - 3 Back-Prop : 204, Loss : 0.22901108860969543\n",
            "Mini-Batch - 4 Back-Prop : 204, Loss : 0.2150947004556656\n",
            "Mini-Batch - 5 Back-Prop : 204, Loss : 0.19968244433403015\n",
            "Mini-Batch - 6 Back-Prop : 204, Loss : 0.20221897959709167\n",
            "Mini-Batch - 7 Back-Prop : 204, Loss : 0.19318325817584991\n",
            "Mini-Batch - 8 Back-Prop : 204, Loss : 0.2292737066745758\n",
            "Episode 7600 finished with score 1624.0, result : lose board : [[16.0, 64.0, 2.0, 4.0], [8.0, 16.0, 64.0, 128.0], [2.0, 4.0, 32.0, 8.0], [4.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7605 finished with score 1340.0, result : lose board : [[  2.  32. 128.   2.]\n",
            " [ 16.   4.  64.   4.]\n",
            " [  4.  16.   8.   2.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7610 finished with score 1496.0, result : lose board : [[  2.  32. 128.   2.]\n",
            " [ 16.   4.  16.  64.]\n",
            " [  8.  16.   8.  32.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7615 finished with score 1484.0, result : lose board : [[ 16. 128.  64.   2.]\n",
            " [  8.  16.  32.   4.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7620 finished with score 3028.0, result : lose board : [[  4. 128. 256.   8.]\n",
            " [ 32.  16.  64.   4.]\n",
            " [  4.   2.   8.  16.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7625 finished with score 588.0, result : lose board : [[4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 32.0], [4, 2, 4, 16.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 205, Loss : 0.20559166371822357\n",
            "Mini-Batch - 1 Back-Prop : 205, Loss : 0.19711901247501373\n",
            "Mini-Batch - 2 Back-Prop : 205, Loss : 0.1643979549407959\n",
            "Mini-Batch - 3 Back-Prop : 205, Loss : 0.2083931416273117\n",
            "Mini-Batch - 4 Back-Prop : 205, Loss : 0.1816205084323883\n",
            "Mini-Batch - 5 Back-Prop : 205, Loss : 0.16622412204742432\n",
            "Mini-Batch - 6 Back-Prop : 205, Loss : 0.18910729885101318\n",
            "Mini-Batch - 7 Back-Prop : 205, Loss : 0.18334272503852844\n",
            "Mini-Batch - 8 Back-Prop : 205, Loss : 0.16983647644519806\n",
            "Episode 7630 finished with score 2384.0, result : lose board : [[  2.   4.   8. 256.]\n",
            " [  4.  16.  64.   4.]\n",
            " [ 16.  32.   8.   2.]\n",
            " [  4.  16.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7635 finished with score 1568.0, result : lose board : [[  2.  32. 128.   8.]\n",
            " [  8.  16.  64.   2.]\n",
            " [  4.   2.   8.  64.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7640 finished with score 2264.0, result : lose board : [[  2.  32. 256.  16.]\n",
            " [  8.  16.  32.   4.]\n",
            " [  4.   2.  16.  32.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7645 finished with score 2808.0, result : lose board : [[4.0, 128.0, 4.0, 128.0], [2.0, 32.0, 64.0, 4.0], [8.0, 16.0, 128.0, 2], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7650 finished with score 1132.0, result : lose board : [[2.0, 16.0, 32.0, 128.0], [4.0, 8.0, 16.0, 4.0], [2, 32.0, 2.0, 8.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7655 finished with score 604.0, result : lose board : [[2.0, 8.0, 16.0, 2.0], [16.0, 2.0, 4.0, 64.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 32.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7660 finished with score 2632.0, result : lose board : [[ 16.  32.  64. 256.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 206, Loss : 0.17593222856521606\n",
            "Mini-Batch - 1 Back-Prop : 206, Loss : 0.19479307532310486\n",
            "Mini-Batch - 2 Back-Prop : 206, Loss : 0.1686883270740509\n",
            "Mini-Batch - 3 Back-Prop : 206, Loss : 0.18635006248950958\n",
            "Mini-Batch - 4 Back-Prop : 206, Loss : 0.19396156072616577\n",
            "Mini-Batch - 5 Back-Prop : 206, Loss : 0.22768165171146393\n",
            "Mini-Batch - 6 Back-Prop : 206, Loss : 0.20004084706306458\n",
            "Mini-Batch - 7 Back-Prop : 206, Loss : 0.17973893880844116\n",
            "Mini-Batch - 8 Back-Prop : 206, Loss : 0.16809310019016266\n",
            "Episode 7665 finished with score 1428.0, result : lose board : [[16.0, 32.0, 2.0, 16.0], [4.0, 16.0, 128.0, 2.0], [16.0, 8.0, 64.0, 16.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7670 finished with score 1304.0, result : lose board : [[  8.  32.   4.   8.]\n",
            " [  2.   8.   2. 128.]\n",
            " [  4.  64.  16.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7675 finished with score 1120.0, result : lose board : [[16.0, 2.0, 4.0, 2.0], [8.0, 32.0, 2.0, 128.0], [2.0, 8.0, 32.0, 8.0], [4, 2, 4.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7680 finished with score 1244.0, result : lose board : [[ 2. 64. 32. 64.]\n",
            " [ 4. 32.  4.  2.]\n",
            " [ 2.  4. 16. 64.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7685 finished with score 1504.0, result : lose board : [[  2.  32.  64.  16.]\n",
            " [ 16.   2.  16. 128.]\n",
            " [  4.  32.   8.   2.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7690 finished with score 1552.0, result : lose board : [[  2.   8. 128.   4.]\n",
            " [  8.  32.  16.  32.]\n",
            " [  4.  16.  64.   2.]\n",
            " [  2.   4.   8.  32.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 207, Loss : 0.2118597775697708\n",
            "Mini-Batch - 1 Back-Prop : 207, Loss : 0.19561998546123505\n",
            "Mini-Batch - 2 Back-Prop : 207, Loss : 0.17404130101203918\n",
            "Mini-Batch - 3 Back-Prop : 207, Loss : 0.21710148453712463\n",
            "Mini-Batch - 4 Back-Prop : 207, Loss : 0.15911129117012024\n",
            "Mini-Batch - 5 Back-Prop : 207, Loss : 0.16099193692207336\n",
            "Mini-Batch - 6 Back-Prop : 207, Loss : 0.14781557023525238\n",
            "Mini-Batch - 7 Back-Prop : 207, Loss : 0.1715351939201355\n",
            "Mini-Batch - 8 Back-Prop : 207, Loss : 0.20607464015483856\n",
            "Episode 7695 finished with score 4980.0, result : lose board : [[4.0, 16.0, 128.0, 512.0], [2.0, 8.0, 16.0, 4.0], [4, 16.0, 4, 2], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7700 finished with score 1028.0, result : lose board : [[  2.  16.  32. 128.]\n",
            " [ 16.   4.   8.   2.]\n",
            " [  4.   2.   4.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7705 finished with score 1468.0, result : lose board : [[2.0, 16.0, 64.0, 4.0], [32.0, 8.0, 16.0, 128.0], [2.0, 4.0, 32.0, 4.0], [4.0, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7710 finished with score 1480.0, result : lose board : [[ 64.   4.  16.   2.]\n",
            " [  8.  32.   2. 128.]\n",
            " [  2.  16.  32.   8.]\n",
            " [  8.   2.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7715 finished with score 2304.0, result : lose board : [[16.0, 32.0, 4.0, 256.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7720 finished with score 1460.0, result : lose board : [[4, 2, 8, 16.0], [2.0, 32.0, 128.0, 32.0], [8.0, 16.0, 64.0, 2.0], [2.0, 8.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 208, Loss : 0.20772312581539154\n",
            "Mini-Batch - 1 Back-Prop : 208, Loss : 0.21178443729877472\n",
            "Mini-Batch - 2 Back-Prop : 208, Loss : 0.19473686814308167\n",
            "Mini-Batch - 3 Back-Prop : 208, Loss : 0.2068021446466446\n",
            "Mini-Batch - 4 Back-Prop : 208, Loss : 0.16618075966835022\n",
            "Mini-Batch - 5 Back-Prop : 208, Loss : 0.16829927265644073\n",
            "Mini-Batch - 6 Back-Prop : 208, Loss : 0.1783357560634613\n",
            "Mini-Batch - 7 Back-Prop : 208, Loss : 0.23694901168346405\n",
            "Mini-Batch - 8 Back-Prop : 208, Loss : 0.212630033493042\n",
            "Episode 7725 finished with score 1500.0, result : lose board : [[16.0, 4.0, 128.0, 32.0], [8.0, 32.0, 64.0, 2.0], [4.0, 16.0, 8.0, 16.0], [2, 8.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7730 finished with score 1548.0, result : lose board : [[8.0, 32.0, 64.0, 128.0], [4.0, 8.0, 4.0, 64.0], [2.0, 4.0, 8.0, 2.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7735 finished with score 2228.0, result : lose board : [[4.0, 16.0, 4.0, 256.0], [2.0, 4.0, 64.0, 8.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7740 finished with score 576.0, result : lose board : [[ 2.  8. 32.  4.]\n",
            " [ 8.  4. 16. 64.]\n",
            " [ 4.  2.  8. 16.]\n",
            " [ 2.  4.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7745 finished with score 292.0, result : lose board : [[4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0], [4, 8.0, 4, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7750 finished with score 2340.0, result : lose board : [[ 16.   2. 256.   8.]\n",
            " [  8.  64.  16.   4.]\n",
            " [  4.   8.   4.  32.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 209, Loss : 0.19642269611358643\n",
            "Mini-Batch - 1 Back-Prop : 209, Loss : 0.17993572354316711\n",
            "Mini-Batch - 2 Back-Prop : 209, Loss : 0.19728177785873413\n",
            "Mini-Batch - 3 Back-Prop : 209, Loss : 0.20181016623973846\n",
            "Mini-Batch - 4 Back-Prop : 209, Loss : 0.1910528540611267\n",
            "Mini-Batch - 5 Back-Prop : 209, Loss : 0.20625996589660645\n",
            "Mini-Batch - 6 Back-Prop : 209, Loss : 0.16151195764541626\n",
            "Mini-Batch - 7 Back-Prop : 209, Loss : 0.163053497672081\n",
            "Mini-Batch - 8 Back-Prop : 209, Loss : 0.16877195239067078\n",
            "Episode 7755 finished with score 1332.0, result : lose board : [[2.0, 4.0, 8.0, 64.0], [32.0, 64.0, 2.0, 32.0], [2, 32.0, 64.0, 2.0], [4.0, 2.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7760 finished with score 1284.0, result : lose board : [[  2.  32. 128.  32.]\n",
            " [ 16.   2.   4.  16.]\n",
            " [  4.  32.  16.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7765 finished with score 3356.0, result : lose board : [[  8.   4.  64. 256.]\n",
            " [  2.  64.  32. 128.]\n",
            " [  4.   8.  16.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7770 finished with score 2380.0, result : lose board : [[  2.  32.   2.   4.]\n",
            " [  8.   2.  64. 256.]\n",
            " [  2.   8.  32.   2.]\n",
            " [  8.   2.   4.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7775 finished with score 1184.0, result : lose board : [[  4.   2.   4.   8.]\n",
            " [  8.  16. 128.  32.]\n",
            " [  4.  32.   8.  16.]\n",
            " [  2.   4.  16.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7780 finished with score 2824.0, result : lose board : [[16.0, 2.0, 4.0, 2.0], [4.0, 32.0, 256.0, 8.0], [2, 4.0, 128.0, 32.0], [4.0, 2.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7785 finished with score 2148.0, result : lose board : [[16.0, 32.0, 128.0, 4.0], [8.0, 16.0, 64.0, 128.0], [4.0, 2.0, 16.0, 8.0], [16.0, 8.0, 2.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 210, Loss : 0.1642383337020874\n",
            "Mini-Batch - 1 Back-Prop : 210, Loss : 0.19131900370121002\n",
            "Mini-Batch - 2 Back-Prop : 210, Loss : 0.199550598859787\n",
            "Mini-Batch - 3 Back-Prop : 210, Loss : 0.19664430618286133\n",
            "Mini-Batch - 4 Back-Prop : 210, Loss : 0.1772412210702896\n",
            "Mini-Batch - 5 Back-Prop : 210, Loss : 0.16719233989715576\n",
            "Mini-Batch - 6 Back-Prop : 210, Loss : 0.2532655596733093\n",
            "Mini-Batch - 7 Back-Prop : 210, Loss : 0.24153351783752441\n",
            "Mini-Batch - 8 Back-Prop : 210, Loss : 0.17717188596725464\n",
            "Episode 7790 finished with score 1972.0, result : lose board : [[2.0, 4.0, 64.0, 8.0], [32.0, 64.0, 4.0, 128.0], [4.0, 8.0, 32.0, 64.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7795 finished with score 2904.0, result : lose board : [[16.0, 32.0, 256.0, 4.0], [2.0, 8.0, 128.0, 8.0], [4, 2.0, 8.0, 32.0], [2, 4.0, 16.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7800 finished with score 1644.0, result : lose board : [[16.0, 2.0, 8.0, 64.0], [2, 8.0, 128.0, 8.0], [4.0, 32.0, 16.0, 64.0], [2.0, 8.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7805 finished with score 896.0, result : lose board : [[16.0, 64.0, 2.0, 64.0], [2.0, 32.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2.0], [2, 16.0, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7810 finished with score 1456.0, result : lose board : [[  4.   8.  16. 128.]\n",
            " [  2.  32.  64.   8.]\n",
            " [  8.  16.  32.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7815 finished with score 668.0, result : lose board : [[16. 64. 16.  8.]\n",
            " [ 4. 16.  4.  2.]\n",
            " [ 2.  4.  8. 32.]\n",
            " [ 4.  2. 16.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 211, Loss : 0.14355140924453735\n",
            "Mini-Batch - 1 Back-Prop : 211, Loss : 0.20012685656547546\n",
            "Mini-Batch - 2 Back-Prop : 211, Loss : 0.22373126447200775\n",
            "Mini-Batch - 3 Back-Prop : 211, Loss : 0.19947129487991333\n",
            "Mini-Batch - 4 Back-Prop : 211, Loss : 0.2060341238975525\n",
            "Mini-Batch - 5 Back-Prop : 211, Loss : 0.19171082973480225\n",
            "Mini-Batch - 6 Back-Prop : 211, Loss : 0.1759839951992035\n",
            "Mini-Batch - 7 Back-Prop : 211, Loss : 0.18518422544002533\n",
            "Mini-Batch - 8 Back-Prop : 211, Loss : 0.2077852487564087\n",
            "Episode 7820 finished with score 2232.0, result : lose board : [[ 16.   8. 256.  64.]\n",
            " [  8.   4.   8.  16.]\n",
            " [  4.   2.   4.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7825 finished with score 372.0, result : lose board : [[2.0, 32.0, 4.0, 16.0], [8.0, 16.0, 2.0, 8.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7830 finished with score 884.0, result : lose board : [[32.0, 4.0, 64.0, 16.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7835 finished with score 1664.0, result : lose board : [[2, 4.0, 16.0, 64.0], [8.0, 64.0, 128.0, 8.0], [4.0, 16.0, 32.0, 16.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7840 finished with score 788.0, result : lose board : [[4.0, 32.0, 64.0, 8.0], [16.0, 8.0, 32.0, 2.0], [2, 4.0, 8.0, 32.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7845 finished with score 1108.0, result : lose board : [[8.0, 16.0, 2.0, 16.0], [16.0, 32.0, 128.0, 4.0], [4.0, 8.0, 16.0, 8.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 212, Loss : 0.17563743889331818\n",
            "Mini-Batch - 1 Back-Prop : 212, Loss : 0.16169659793376923\n",
            "Mini-Batch - 2 Back-Prop : 212, Loss : 0.17949751019477844\n",
            "Mini-Batch - 3 Back-Prop : 212, Loss : 0.19382888078689575\n",
            "Mini-Batch - 4 Back-Prop : 212, Loss : 0.1558520495891571\n",
            "Mini-Batch - 5 Back-Prop : 212, Loss : 0.1938297152519226\n",
            "Mini-Batch - 6 Back-Prop : 212, Loss : 0.2001691311597824\n",
            "Mini-Batch - 7 Back-Prop : 212, Loss : 0.15663737058639526\n",
            "Mini-Batch - 8 Back-Prop : 212, Loss : 0.18848352134227753\n",
            "Episode 7850 finished with score 1584.0, result : lose board : [[ 16.   2.   4.  32.]\n",
            " [  4.  32.  16.   2.]\n",
            " [  2.  16. 128.  64.]\n",
            " [  4.   8.  32.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7855 finished with score 2484.0, result : lose board : [[16.0, 32.0, 256.0, 4.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 2.0, 32.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7860 finished with score 1808.0, result : lose board : [[ 16.  32. 128.   8.]\n",
            " [  8.  16.   2. 128.]\n",
            " [  4.   8.  16.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7865 finished with score 5128.0, result : lose board : [[ 16.  64.   2. 512.]\n",
            " [  8.  32.  64.  32.]\n",
            " [  2.   8.  32.   4.]\n",
            " [  4.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7870 finished with score 1400.0, result : lose board : [[4.0, 32.0, 128.0, 64.0], [2.0, 8.0, 32.0, 4.0], [4, 16.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7875 finished with score 1212.0, result : lose board : [[  2.  64.   2.   8.]\n",
            " [  4.   8. 128.  16.]\n",
            " [  2.   4.  16.   4.]\n",
            " [  8.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7880 finished with score 996.0, result : lose board : [[ 8. 32.  4. 64.]\n",
            " [ 2.  4. 32. 16.]\n",
            " [64. 16.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 213, Loss : 0.15310223400592804\n",
            "Mini-Batch - 1 Back-Prop : 213, Loss : 0.18135297298431396\n",
            "Mini-Batch - 2 Back-Prop : 213, Loss : 0.17995378375053406\n",
            "Mini-Batch - 3 Back-Prop : 213, Loss : 0.19066783785820007\n",
            "Mini-Batch - 4 Back-Prop : 213, Loss : 0.18061469495296478\n",
            "Mini-Batch - 5 Back-Prop : 213, Loss : 0.22296038269996643\n",
            "Mini-Batch - 6 Back-Prop : 213, Loss : 0.19881388545036316\n",
            "Mini-Batch - 7 Back-Prop : 213, Loss : 0.17235511541366577\n",
            "Mini-Batch - 8 Back-Prop : 213, Loss : 0.16341587901115417\n",
            "Episode 7885 finished with score 1248.0, result : lose board : [[4.0, 128.0, 32.0, 2.0], [2.0, 4.0, 8.0, 4.0], [16.0, 32.0, 4.0, 32.0], [4, 8.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7890 finished with score 1016.0, result : lose board : [[ 8. 16.  2. 64.]\n",
            " [32.  8. 16.  2.]\n",
            " [ 4. 64. 32.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7895 finished with score 2784.0, result : lose board : [[16.0, 64.0, 256.0, 32.0], [8.0, 16.0, 64.0, 16.0], [2.0, 4.0, 32.0, 8.0], [8.0, 2, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7900 finished with score 1704.0, result : lose board : [[32.0, 64.0, 2.0, 16.0], [8.0, 16.0, 128.0, 8.0], [4.0, 8.0, 64.0, 2.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7905 finished with score 3488.0, result : lose board : [[2.0, 4.0, 16.0, 2.0], [8.0, 32.0, 128.0, 256.0], [2, 8.0, 16.0, 128.0], [4.0, 2.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7910 finished with score 1748.0, result : lose board : [[  8.  32.  64. 128.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.   2.   4.]\n",
            " [  4.   2.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 214, Loss : 0.1622026413679123\n",
            "Mini-Batch - 1 Back-Prop : 214, Loss : 0.21585217118263245\n",
            "Mini-Batch - 2 Back-Prop : 214, Loss : 0.16299204528331757\n",
            "Mini-Batch - 3 Back-Prop : 214, Loss : 0.22093209624290466\n",
            "Mini-Batch - 4 Back-Prop : 214, Loss : 0.2366735190153122\n",
            "Mini-Batch - 5 Back-Prop : 214, Loss : 0.16779781877994537\n",
            "Mini-Batch - 6 Back-Prop : 214, Loss : 0.16980093717575073\n",
            "Mini-Batch - 7 Back-Prop : 214, Loss : 0.20279428362846375\n",
            "Mini-Batch - 8 Back-Prop : 214, Loss : 0.1829550415277481\n",
            "Episode 7915 finished with score 3508.0, result : lose board : [[32.0, 2.0, 128.0, 2.0], [8.0, 16.0, 4.0, 256.0], [4.0, 8.0, 128.0, 4.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7920 finished with score 552.0, result : lose board : [[2.0, 16.0, 32.0, 4.0], [4.0, 2.0, 16.0, 64.0], [2.0, 4.0, 8.0, 4.0], [4, 2, 4, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7925 finished with score 1632.0, result : lose board : [[  2.   4.   8.  64.]\n",
            " [ 16.   8. 128.  32.]\n",
            " [  4.  64.   2.  16.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7930 finished with score 936.0, result : lose board : [[16.0, 64.0, 4.0, 2.0], [2.0, 16.0, 32.0, 64.0], [4.0, 8.0, 16.0, 4.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7935 finished with score 620.0, result : lose board : [[ 2. 32.  2. 32.]\n",
            " [ 4. 16. 32. 16.]\n",
            " [ 2. 32.  8.  4.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7940 finished with score 2820.0, result : lose board : [[16.0, 2.0, 128.0, 256.0], [2.0, 16.0, 2.0, 32.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 215, Loss : 0.17936964333057404\n",
            "Mini-Batch - 1 Back-Prop : 215, Loss : 0.17662623524665833\n",
            "Mini-Batch - 2 Back-Prop : 215, Loss : 0.15088459849357605\n",
            "Mini-Batch - 3 Back-Prop : 215, Loss : 0.18749399483203888\n",
            "Mini-Batch - 4 Back-Prop : 215, Loss : 0.1832471787929535\n",
            "Mini-Batch - 5 Back-Prop : 215, Loss : 0.1493806391954422\n",
            "Mini-Batch - 6 Back-Prop : 215, Loss : 0.15904253721237183\n",
            "Mini-Batch - 7 Back-Prop : 215, Loss : 0.16490454971790314\n",
            "Mini-Batch - 8 Back-Prop : 215, Loss : 0.1839478313922882\n",
            "Episode 7945 finished with score 1772.0, result : lose board : [[16.0, 64.0, 128.0, 32.0], [4.0, 32.0, 64.0, 16.0], [8.0, 4.0, 8.0, 2.0], [4, 2, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7950 finished with score 2036.0, result : lose board : [[2, 4.0, 32.0, 128.0], [4.0, 16.0, 128.0, 8.0], [2.0, 4.0, 8.0, 64.0], [4.0, 2.0, 4.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7955 finished with score 1740.0, result : lose board : [[2.0, 4.0, 2.0, 128.0], [16.0, 128.0, 8.0, 2.0], [8.0, 2.0, 4.0, 16.0], [2, 4, 32.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7960 finished with score 696.0, result : lose board : [[2.0, 4.0, 32.0, 2.0], [8.0, 32.0, 4.0, 64.0], [4.0, 8.0, 16.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7965 finished with score 1496.0, result : lose board : [[16.0, 64.0, 128.0, 8.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7970 finished with score 1628.0, result : lose board : [[32. 64.  4. 64.]\n",
            " [ 8. 32. 64.  4.]\n",
            " [ 4.  8. 16. 64.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 216, Loss : 0.14956539869308472\n",
            "Mini-Batch - 1 Back-Prop : 216, Loss : 0.15858595073223114\n",
            "Mini-Batch - 2 Back-Prop : 216, Loss : 0.18061983585357666\n",
            "Mini-Batch - 3 Back-Prop : 216, Loss : 0.1782549023628235\n",
            "Mini-Batch - 4 Back-Prop : 216, Loss : 0.18438012897968292\n",
            "Mini-Batch - 5 Back-Prop : 216, Loss : 0.18758271634578705\n",
            "Mini-Batch - 6 Back-Prop : 216, Loss : 0.18478651344776154\n",
            "Mini-Batch - 7 Back-Prop : 216, Loss : 0.17612318694591522\n",
            "Mini-Batch - 8 Back-Prop : 216, Loss : 0.17062225937843323\n",
            "Episode 7975 finished with score 816.0, result : lose board : [[16.0, 32.0, 2.0, 32.0], [4.0, 16.0, 64.0, 2.0], [2.0, 4.0, 32.0, 8.0], [4, 16.0, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7980 finished with score 2452.0, result : lose board : [[ 16.  64. 256.   8.]\n",
            " [  8.  32.   8.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7985 finished with score 3180.0, result : lose board : [[ 16.  32.   4. 256.]\n",
            " [  8.  16. 128.   4.]\n",
            " [  4.  64.  32.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7990 finished with score 3428.0, result : lose board : [[ 16.   4. 128.   4.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 7995 finished with score 2500.0, result : lose board : [[16.0, 32.0, 64.0, 256.0], [4.0, 16.0, 32.0, 4.0], [8.0, 2.0, 8.0, 2], [2.0, 4.0, 16.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 217, Loss : 0.19283419847488403\n",
            "Mini-Batch - 1 Back-Prop : 217, Loss : 0.1659361571073532\n",
            "Mini-Batch - 2 Back-Prop : 217, Loss : 0.15286587178707123\n",
            "Mini-Batch - 3 Back-Prop : 217, Loss : 0.2389206737279892\n",
            "Mini-Batch - 4 Back-Prop : 217, Loss : 0.18414461612701416\n",
            "Mini-Batch - 5 Back-Prop : 217, Loss : 0.1796003133058548\n",
            "Mini-Batch - 6 Back-Prop : 217, Loss : 0.16427834331989288\n",
            "Mini-Batch - 7 Back-Prop : 217, Loss : 0.22474898397922516\n",
            "Mini-Batch - 8 Back-Prop : 217, Loss : 0.21273086965084076\n",
            "Maximum Score : 6356.0 ,Episode : 5768\n",
            "Loss : 0.1906733363866806\n",
            "\n",
            "Episode 8000 finished with score 1440.0, result : lose board : [[32.0, 2.0, 8.0, 128.0], [8.0, 16.0, 64.0, 2.0], [2.0, 4.0, 16.0, 32.0], [8.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8005 finished with score 1780.0, result : lose board : [[ 32.  64.   2. 128.]\n",
            " [  8.  16.  64.  16.]\n",
            " [  4.   8.  32.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8010 finished with score 1416.0, result : lose board : [[32.0, 4.0, 32.0, 4.0], [8.0, 64.0, 16.0, 128.0], [4.0, 16.0, 4.0, 2.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8015 finished with score 508.0, result : lose board : [[32.0, 2.0, 8.0, 32.0], [2.0, 16.0, 2.0, 4.0], [4.0, 8.0, 32.0, 2], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8020 finished with score 764.0, result : lose board : [[16.0, 32.0, 4.0, 64.0], [8.0, 16.0, 32.0, 16.0], [2.0, 4.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8025 finished with score 2216.0, result : lose board : [[ 16.  32.   2. 128.]\n",
            " [  8.  16. 128.   4.]\n",
            " [  4.   8.  64.  32.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8030 finished with score 460.0, result : lose board : [[16.0, 32.0, 16.0, 4.0], [4.0, 8.0, 32.0, 8.0], [2, 4.0, 16.0, 2], [4, 2, 4, 16.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 218, Loss : 0.18522629141807556\n",
            "Mini-Batch - 1 Back-Prop : 218, Loss : 0.1991780549287796\n",
            "Mini-Batch - 2 Back-Prop : 218, Loss : 0.15866664052009583\n",
            "Mini-Batch - 3 Back-Prop : 218, Loss : 0.16263934969902039\n",
            "Mini-Batch - 4 Back-Prop : 218, Loss : 0.1765223890542984\n",
            "Mini-Batch - 5 Back-Prop : 218, Loss : 0.15147900581359863\n",
            "Mini-Batch - 6 Back-Prop : 218, Loss : 0.17214451730251312\n",
            "Mini-Batch - 7 Back-Prop : 218, Loss : 0.1765211522579193\n",
            "Mini-Batch - 8 Back-Prop : 218, Loss : 0.1600223034620285\n",
            "Episode 8035 finished with score 1156.0, result : lose board : [[  2.   8.  32.   4.]\n",
            " [  8.  16. 128.   8.]\n",
            " [  4.  32.   2.  16.]\n",
            " [  2.   8.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8040 finished with score 3076.0, result : lose board : [[  8.  16. 256.   4.]\n",
            " [ 64.   2.   8.   2.]\n",
            " [  8.  16. 128.  32.]\n",
            " [  4.   2.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8045 finished with score 840.0, result : lose board : [[4.0, 16.0, 2.0, 64.0], [8.0, 4.0, 16.0, 2.0], [2.0, 16.0, 64.0, 16.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8050 finished with score 2448.0, result : lose board : [[ 32.   2.   8.  64.]\n",
            " [  8.  16.   2.   4.]\n",
            " [  4.   8. 256.  32.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8055 finished with score 528.0, result : lose board : [[8.0, 32.0, 4.0, 32.0], [2.0, 16.0, 32.0, 8.0], [4.0, 8.0, 16.0, 2.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8060 finished with score 1528.0, result : lose board : [[2.0, 8.0, 16.0, 128.0], [16.0, 64.0, 2.0, 32.0], [8.0, 16.0, 32.0, 8.0], [2.0, 8.0, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 219, Loss : 0.15803095698356628\n",
            "Mini-Batch - 1 Back-Prop : 219, Loss : 0.17710354924201965\n",
            "Mini-Batch - 2 Back-Prop : 219, Loss : 0.24541661143302917\n",
            "Mini-Batch - 3 Back-Prop : 219, Loss : 0.1891433149576187\n",
            "Mini-Batch - 4 Back-Prop : 219, Loss : 0.15094277262687683\n",
            "Mini-Batch - 5 Back-Prop : 219, Loss : 0.15634490549564362\n",
            "Mini-Batch - 6 Back-Prop : 219, Loss : 0.1887034922838211\n",
            "Mini-Batch - 7 Back-Prop : 219, Loss : 0.19562186300754547\n",
            "Mini-Batch - 8 Back-Prop : 219, Loss : 0.19348114728927612\n",
            "Episode 8065 finished with score 2456.0, result : lose board : [[  2.  32.   2.   8.]\n",
            " [  8.  16. 256.  64.]\n",
            " [  4.   8.  32.  16.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8070 finished with score 796.0, result : lose board : [[2.0, 32.0, 4.0, 64.0], [16.0, 2.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8075 finished with score 2456.0, result : lose board : [[  2.   8. 128.   2.]\n",
            " [  4.  32.  64.   4.]\n",
            " [ 16. 128.  32.  64.]\n",
            " [  4.   2.   4.  16.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8080 finished with score 2608.0, result : lose board : [[16.0, 64.0, 256.0, 32.0], [4.0, 16.0, 32.0, 8.0], [2.0, 32.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8085 finished with score 1092.0, result : lose board : [[4.0, 32.0, 16.0, 128.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4.0, 2.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8090 finished with score 1092.0, result : lose board : [[8.0, 16.0, 4.0, 64.0], [4.0, 32.0, 64.0, 8.0], [2.0, 8.0, 4.0, 32.0], [4, 2.0, 32.0, 4]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 220, Loss : 0.15911443531513214\n",
            "Mini-Batch - 1 Back-Prop : 220, Loss : 0.1869041919708252\n",
            "Mini-Batch - 2 Back-Prop : 220, Loss : 0.17886187136173248\n",
            "Mini-Batch - 3 Back-Prop : 220, Loss : 0.1398462951183319\n",
            "Mini-Batch - 4 Back-Prop : 220, Loss : 0.17341956496238708\n",
            "Mini-Batch - 5 Back-Prop : 220, Loss : 0.17257893085479736\n",
            "Mini-Batch - 6 Back-Prop : 220, Loss : 0.15302728116512299\n",
            "Mini-Batch - 7 Back-Prop : 220, Loss : 0.15717782080173492\n",
            "Mini-Batch - 8 Back-Prop : 220, Loss : 0.14139054715633392\n",
            "Episode 8095 finished with score 1796.0, result : lose board : [[2, 4.0, 8.0, 2.0], [8.0, 64.0, 128.0, 4.0], [4.0, 16.0, 64.0, 8.0], [2.0, 4.0, 8.0, 64.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8100 finished with score 412.0, result : lose board : [[ 2.  8. 32.  2.]\n",
            " [32.  4.  8. 16.]\n",
            " [ 8. 16.  4.  2.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8105 finished with score 732.0, result : lose board : [[ 4. 16. 64. 32.]\n",
            " [ 2.  8. 16.  8.]\n",
            " [ 4.  2. 32.  4.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8110 finished with score 1344.0, result : lose board : [[ 16.  32. 128.   4.]\n",
            " [  8.   2.  16.  64.]\n",
            " [  2.   8.   4.   8.]\n",
            " [  8.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8115 finished with score 3024.0, result : lose board : [[  2.  64.   4.   2.]\n",
            " [ 16.  32.  64. 256.]\n",
            " [  2.  16.  32.   2.]\n",
            " [  8.   4.   2.  64.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8120 finished with score 1808.0, result : lose board : [[16.0, 64.0, 4.0, 128.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 4.0, 64.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 221, Loss : 0.1558724045753479\n",
            "Mini-Batch - 1 Back-Prop : 221, Loss : 0.18036170303821564\n",
            "Mini-Batch - 2 Back-Prop : 221, Loss : 0.17654910683631897\n",
            "Mini-Batch - 3 Back-Prop : 221, Loss : 0.18502812087535858\n",
            "Mini-Batch - 4 Back-Prop : 221, Loss : 0.1539122462272644\n",
            "Mini-Batch - 5 Back-Prop : 221, Loss : 0.19847452640533447\n",
            "Mini-Batch - 6 Back-Prop : 221, Loss : 0.18061916530132294\n",
            "Mini-Batch - 7 Back-Prop : 221, Loss : 0.1608615517616272\n",
            "Mini-Batch - 8 Back-Prop : 221, Loss : 0.18513871729373932\n",
            "Episode 8125 finished with score 504.0, result : lose board : [[ 8. 16.  4.  8.]\n",
            " [ 2.  4. 16. 64.]\n",
            " [ 4.  2.  8.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8130 finished with score 2776.0, result : lose board : [[ 16.   2.  64. 256.]\n",
            " [  8.  16.  32.  64.]\n",
            " [  2.   4.  16.  32.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8135 finished with score 1212.0, result : lose board : [[16.0, 32.0, 128.0, 8.0], [8.0, 2.0, 8.0, 4.0], [2.0, 16.0, 32.0, 8.0], [16.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8140 finished with score 1704.0, result : lose board : [[  2.   4. 128.   2.]\n",
            " [ 16.  64.  32.  64.]\n",
            " [  8.  16.   8.  16.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8145 finished with score 1724.0, result : lose board : [[  4.  32.  64. 128.]\n",
            " [  8.   4.  32.   8.]\n",
            " [  4.  64.   8.   4.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Episode 8150 finished with score 3044.0, result : lose board : [[ 16.  32. 128. 256.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.0004500000213738531 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 222, Loss : 0.16957338154315948\n",
            "Mini-Batch - 1 Back-Prop : 222, Loss : 0.16576561331748962\n",
            "Mini-Batch - 2 Back-Prop : 222, Loss : 0.1703442931175232\n",
            "Mini-Batch - 3 Back-Prop : 222, Loss : 0.19973136484622955\n",
            "Mini-Batch - 4 Back-Prop : 222, Loss : 0.17080706357955933\n",
            "Mini-Batch - 5 Back-Prop : 222, Loss : 0.1520821750164032\n",
            "Mini-Batch - 6 Back-Prop : 222, Loss : 0.18410606682300568\n",
            "Mini-Batch - 7 Back-Prop : 222, Loss : 0.16493721306324005\n",
            "Mini-Batch - 8 Back-Prop : 222, Loss : 0.15667280554771423\n",
            "Episode 8155 finished with score 1868.0, result : lose board : [[32.0, 4.0, 64.0, 128.0], [8.0, 32.0, 2.0, 64.0], [2.0, 8.0, 32.0, 16.0], [4.0, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8160 finished with score 1512.0, result : lose board : [[  2.   4.   8. 128.]\n",
            " [ 16.  64.   4.   2.]\n",
            " [  4.   8.  64.  16.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8165 finished with score 1312.0, result : lose board : [[4.0, 128.0, 4.0, 2], [16.0, 64.0, 8.0, 16.0], [4.0, 32.0, 2.0, 4.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode : 8170, Score : 5908.0, Iters : 400, Finish : Game not over\n",
            "Episode 8170 finished with score 6168.0, result : lose board : [[16.0, 32.0, 128.0, 512.0], [4.0, 8.0, 64.0, 128.0], [8.0, 32.0, 16.0, 8.0], [2.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8175 finished with score 916.0, result : lose board : [[8.0, 16.0, 64.0, 2.0], [2.0, 8.0, 16.0, 64.0], [4, 2.0, 8.0, 32.0], [2, 4.0, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 223, Loss : 0.17971384525299072\n",
            "Mini-Batch - 1 Back-Prop : 223, Loss : 0.19240395724773407\n",
            "Mini-Batch - 2 Back-Prop : 223, Loss : 0.15449613332748413\n",
            "Mini-Batch - 3 Back-Prop : 223, Loss : 0.15926899015903473\n",
            "Mini-Batch - 4 Back-Prop : 223, Loss : 0.228651762008667\n",
            "Mini-Batch - 5 Back-Prop : 223, Loss : 0.17749209702014923\n",
            "Mini-Batch - 6 Back-Prop : 223, Loss : 0.19545117020606995\n",
            "Mini-Batch - 7 Back-Prop : 223, Loss : 0.18916483223438263\n",
            "Mini-Batch - 8 Back-Prop : 223, Loss : 0.21402034163475037\n",
            "Episode 8180 finished with score 1240.0, result : lose board : [[8.0, 16.0, 4.0, 8.0], [4.0, 8.0, 64.0, 128.0], [2, 4.0, 8.0, 16.0], [4.0, 8.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8185 finished with score 1460.0, result : lose board : [[2, 4.0, 8.0, 64.0], [4.0, 16.0, 128.0, 2.0], [32.0, 8.0, 32.0, 16.0], [4.0, 2.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8190 finished with score 1756.0, result : lose board : [[ 16.  64.   4. 128.]\n",
            " [  4.  32.  64.   8.]\n",
            " [  2.  16.  32.   2.]\n",
            " [  8.   2.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8195 finished with score 1020.0, result : lose board : [[  4.   8.  32. 128.]\n",
            " [ 16.   4.   8.   2.]\n",
            " [  8.   2.   4.  16.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8200 finished with score 2284.0, result : lose board : [[ 16.  32.   4. 256.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 224, Loss : 0.19370347261428833\n",
            "Mini-Batch - 1 Back-Prop : 224, Loss : 0.17677682638168335\n",
            "Mini-Batch - 2 Back-Prop : 224, Loss : 0.1782178431749344\n",
            "Mini-Batch - 3 Back-Prop : 224, Loss : 0.18774358928203583\n",
            "Mini-Batch - 4 Back-Prop : 224, Loss : 0.19588042795658112\n",
            "Mini-Batch - 5 Back-Prop : 224, Loss : 0.2171597182750702\n",
            "Mini-Batch - 6 Back-Prop : 224, Loss : 0.19221007823944092\n",
            "Mini-Batch - 7 Back-Prop : 224, Loss : 0.21078917384147644\n",
            "Mini-Batch - 8 Back-Prop : 224, Loss : 0.1821865439414978\n",
            "Episode 8205 finished with score 1468.0, result : lose board : [[16.0, 32.0, 2.0, 128.0], [8.0, 16.0, 64.0, 2.0], [2.0, 4.0, 16.0, 32.0], [4.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8210 finished with score 800.0, result : lose board : [[8.0, 32.0, 64.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2.0, 32.0, 4.0, 2.0], [4, 2, 16.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8215 finished with score 2616.0, result : lose board : [[16.0, 64.0, 4.0, 2.0], [4.0, 32.0, 256.0, 16.0], [2, 4.0, 64.0, 4.0], [4, 2, 4, 8]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8220 finished with score 860.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 64. 16.]\n",
            " [ 4.  2.  4. 32.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8225 finished with score 3344.0, result : lose board : [[  4.   2. 128.   8.]\n",
            " [  2.   8.  64. 256.]\n",
            " [  4.  32.  16.  64.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8230 finished with score 1052.0, result : lose board : [[16.  2. 64.  4.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8235 finished with score 1044.0, result : lose board : [[2.0, 16.0, 4.0, 16.0], [16.0, 64.0, 32.0, 64.0], [8.0, 32.0, 4.0, 8.0], [4, 2.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 225, Loss : 0.2206360399723053\n",
            "Mini-Batch - 1 Back-Prop : 225, Loss : 0.1764802485704422\n",
            "Mini-Batch - 2 Back-Prop : 225, Loss : 0.13967706263065338\n",
            "Mini-Batch - 3 Back-Prop : 225, Loss : 0.16045543551445007\n",
            "Mini-Batch - 4 Back-Prop : 225, Loss : 0.184963658452034\n",
            "Mini-Batch - 5 Back-Prop : 225, Loss : 0.17712202668190002\n",
            "Mini-Batch - 6 Back-Prop : 225, Loss : 0.17503608763217926\n",
            "Mini-Batch - 7 Back-Prop : 225, Loss : 0.13878804445266724\n",
            "Mini-Batch - 8 Back-Prop : 225, Loss : 0.16696402430534363\n",
            "Episode 8240 finished with score 908.0, result : lose board : [[16. 32.  4. 16.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8245 finished with score 5204.0, result : lose board : [[8.0, 32.0, 4.0, 8.0], [2.0, 16.0, 32.0, 512.0], [4.0, 128.0, 4.0, 2], [2, 4.0, 8.0, 32.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8250 finished with score 792.0, result : lose board : [[4.0, 16.0, 4.0, 2.0], [16.0, 2.0, 32.0, 64.0], [8.0, 16.0, 4.0, 32.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8255 finished with score 936.0, result : lose board : [[32.  8. 32. 64.]\n",
            " [ 8. 32.  8.  4.]\n",
            " [ 4. 16. 32.  8.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8260 finished with score 880.0, result : lose board : [[16. 32.  2. 64.]\n",
            " [ 8. 16. 32.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8265 finished with score 3356.0, result : lose board : [[ 16.  32. 256.  32.]\n",
            " [  8.  16.  32. 128.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 226, Loss : 0.1924435943365097\n",
            "Mini-Batch - 1 Back-Prop : 226, Loss : 0.15822702646255493\n",
            "Mini-Batch - 2 Back-Prop : 226, Loss : 0.18006925284862518\n",
            "Mini-Batch - 3 Back-Prop : 226, Loss : 0.2031521052122116\n",
            "Mini-Batch - 4 Back-Prop : 226, Loss : 0.16391049325466156\n",
            "Mini-Batch - 5 Back-Prop : 226, Loss : 0.15172991156578064\n",
            "Mini-Batch - 6 Back-Prop : 226, Loss : 0.1963385045528412\n",
            "Mini-Batch - 7 Back-Prop : 226, Loss : 0.20519502460956573\n",
            "Mini-Batch - 8 Back-Prop : 226, Loss : 0.22517965734004974\n",
            "Episode 8270 finished with score 1768.0, result : lose board : [[ 16.  32.  64.   4.]\n",
            " [  4.  16.  32. 128.]\n",
            " [ 16.  64.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8275 finished with score 1776.0, result : lose board : [[  2.  32.   4.  16.]\n",
            " [ 16. 128.  64.   4.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8280 finished with score 1424.0, result : lose board : [[8.0, 32.0, 64.0, 128.0], [4.0, 16.0, 8.0, 32.0], [2.0, 8.0, 2.0, 8.0], [4, 2.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8285 finished with score 732.0, result : lose board : [[ 2. 16. 32. 64.]\n",
            " [ 4.  2.  4. 16.]\n",
            " [ 2. 32.  8.  4.]\n",
            " [ 4. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8290 finished with score 1320.0, result : lose board : [[  2.  32.   4. 128.]\n",
            " [ 16.   8.  64.   8.]\n",
            " [  2.  16.   4.   2.]\n",
            " [  4.   2.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8295 finished with score 1736.0, result : lose board : [[64.0, 128.0, 4.0, 2], [2.0, 32.0, 64.0, 8.0], [16.0, 8.0, 32.0, 2.0], [8.0, 2.0, 4.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 227, Loss : 0.18636450171470642\n",
            "Mini-Batch - 1 Back-Prop : 227, Loss : 0.18011265993118286\n",
            "Mini-Batch - 2 Back-Prop : 227, Loss : 0.15064875781536102\n",
            "Mini-Batch - 3 Back-Prop : 227, Loss : 0.1627752184867859\n",
            "Mini-Batch - 4 Back-Prop : 227, Loss : 0.18681733310222626\n",
            "Mini-Batch - 5 Back-Prop : 227, Loss : 0.1580081731081009\n",
            "Mini-Batch - 6 Back-Prop : 227, Loss : 0.1526927947998047\n",
            "Mini-Batch - 7 Back-Prop : 227, Loss : 0.16380149126052856\n",
            "Mini-Batch - 8 Back-Prop : 227, Loss : 0.19543877243995667\n",
            "Episode 8300 finished with score 1200.0, result : lose board : [[  2.   8. 128.   8.]\n",
            " [  8.   4.  16.  64.]\n",
            " [  4.   2.   8.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8305 finished with score 1360.0, result : lose board : [[  8.  16.   4. 128.]\n",
            " [  4.  32.  64.   8.]\n",
            " [  2.   4.  16.   4.]\n",
            " [ 16.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8310 finished with score 2496.0, result : lose board : [[16.0, 64.0, 4.0, 8.0], [8.0, 16.0, 32.0, 256.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8315 finished with score 1096.0, result : lose board : [[32.0, 64.0, 4.0, 32.0], [8.0, 16.0, 64.0, 2.0], [2, 4.0, 16.0, 32.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8320 finished with score 500.0, result : lose board : [[ 2.  8. 16. 64.]\n",
            " [ 8. 16.  8.  4.]\n",
            " [ 2.  4. 16.  2.]\n",
            " [ 4.  2.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8325 finished with score 1404.0, result : lose board : [[16.0, 32.0, 128.0, 16.0], [4.0, 16.0, 64.0, 8.0], [2.0, 4.0, 16.0, 4.0], [4, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 228, Loss : 0.1875355988740921\n",
            "Mini-Batch - 1 Back-Prop : 228, Loss : 0.15731793642044067\n",
            "Mini-Batch - 2 Back-Prop : 228, Loss : 0.19725069403648376\n",
            "Mini-Batch - 3 Back-Prop : 228, Loss : 0.13691215217113495\n",
            "Mini-Batch - 4 Back-Prop : 228, Loss : 0.2001488208770752\n",
            "Mini-Batch - 5 Back-Prop : 228, Loss : 0.12556245923042297\n",
            "Mini-Batch - 6 Back-Prop : 228, Loss : 0.18072772026062012\n",
            "Mini-Batch - 7 Back-Prop : 228, Loss : 0.19252869486808777\n",
            "Mini-Batch - 8 Back-Prop : 228, Loss : 0.19013582170009613\n",
            "Episode 8330 finished with score 1444.0, result : lose board : [[ 16.  32.  64.   2.]\n",
            " [  8.  16. 128.   4.]\n",
            " [  4.   2.  16.  32.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8335 finished with score 1428.0, result : lose board : [[32.0, 4.0, 128.0, 4.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 4.0, 32.0], [2, 4.0, 16.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8340 finished with score 872.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 64.  4.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8345 finished with score 1048.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [8.0, 16.0, 32.0, 64.0], [4.0, 8.0, 16.0, 8.0], [8.0, 4, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8350 finished with score 372.0, result : lose board : [[ 2.  8. 16. 32.]\n",
            " [ 8.  2.  4. 16.]\n",
            " [ 4.  8. 16.  2.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8355 finished with score 772.0, result : lose board : [[16.  2.  4.  8.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 229, Loss : 0.19097718596458435\n",
            "Mini-Batch - 1 Back-Prop : 229, Loss : 0.25393182039260864\n",
            "Mini-Batch - 2 Back-Prop : 229, Loss : 0.18015837669372559\n",
            "Mini-Batch - 3 Back-Prop : 229, Loss : 0.18823422491550446\n",
            "Mini-Batch - 4 Back-Prop : 229, Loss : 0.1682615429162979\n",
            "Mini-Batch - 5 Back-Prop : 229, Loss : 0.21526113152503967\n",
            "Mini-Batch - 6 Back-Prop : 229, Loss : 0.181870698928833\n",
            "Mini-Batch - 7 Back-Prop : 229, Loss : 0.1574321687221527\n",
            "Mini-Batch - 8 Back-Prop : 229, Loss : 0.16300755739212036\n",
            "Episode 8360 finished with score 1460.0, result : lose board : [[16.0, 64.0, 2.0, 4.0], [4.0, 8.0, 128.0, 2.0], [2.0, 4.0, 64.0, 8.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8365 finished with score 1372.0, result : lose board : [[2, 4.0, 8.0, 128.0], [4.0, 8.0, 64.0, 4.0], [16.0, 32.0, 2.0, 32.0], [4.0, 2.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8370 finished with score 3116.0, result : lose board : [[ 16.  64. 256.   8.]\n",
            " [  8.  32. 128.  16.]\n",
            " [  4.   8.  16.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8375 finished with score 1792.0, result : lose board : [[  4.  32.  64.  16.]\n",
            " [ 16.   2. 128.   8.]\n",
            " [  2.  16.  32.  64.]\n",
            " [  4.   2.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8380 finished with score 3076.0, result : lose board : [[ 16.  32. 128. 256.]\n",
            " [  8.  64.  16.   8.]\n",
            " [  2.   4.   8.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8385 finished with score 1012.0, result : lose board : [[16.  4.  8. 64.]\n",
            " [ 8. 32. 64. 32.]\n",
            " [ 4.  8. 16.  2.]\n",
            " [ 2.  4.  2.  8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 230, Loss : 0.1677563488483429\n",
            "Mini-Batch - 1 Back-Prop : 230, Loss : 0.18949759006500244\n",
            "Mini-Batch - 2 Back-Prop : 230, Loss : 0.18227678537368774\n",
            "Mini-Batch - 3 Back-Prop : 230, Loss : 0.195041686296463\n",
            "Mini-Batch - 4 Back-Prop : 230, Loss : 0.12732478976249695\n",
            "Mini-Batch - 5 Back-Prop : 230, Loss : 0.19916245341300964\n",
            "Mini-Batch - 6 Back-Prop : 230, Loss : 0.1657058298587799\n",
            "Mini-Batch - 7 Back-Prop : 230, Loss : 0.205624520778656\n",
            "Mini-Batch - 8 Back-Prop : 230, Loss : 0.22977907955646515\n",
            "Episode 8390 finished with score 640.0, result : lose board : [[ 2. 16. 32. 64.]\n",
            " [ 4.  8. 16.  8.]\n",
            " [ 8.  2.  4. 16.]\n",
            " [ 4.  8.  2.  8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8395 finished with score 724.0, result : lose board : [[2.0, 8.0, 16.0, 32.0], [8.0, 2.0, 64.0, 16.0], [4.0, 8.0, 32.0, 8.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8400 finished with score 1412.0, result : lose board : [[8.0, 32.0, 2.0, 32.0], [4.0, 64.0, 128.0, 4.0], [2.0, 4.0, 16.0, 2.0], [4, 2.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8405 finished with score 2944.0, result : lose board : [[ 16.  32. 128. 256.]\n",
            " [  8.  16.   2.   8.]\n",
            " [  4.  32.  16.   4.]\n",
            " [  2.   4.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8410 finished with score 868.0, result : lose board : [[16.0, 64.0, 2.0, 32.0], [8.0, 2.0, 64.0, 4.0], [2, 4.0, 8.0, 16.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8415 finished with score 1432.0, result : lose board : [[4.0, 128.0, 32.0, 2], [2, 8.0, 16.0, 4.0], [4.0, 64.0, 4.0, 16.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 231, Loss : 0.13085326552391052\n",
            "Mini-Batch - 1 Back-Prop : 231, Loss : 0.16924865543842316\n",
            "Mini-Batch - 2 Back-Prop : 231, Loss : 0.15438619256019592\n",
            "Mini-Batch - 3 Back-Prop : 231, Loss : 0.20193591713905334\n",
            "Mini-Batch - 4 Back-Prop : 231, Loss : 0.1765626072883606\n",
            "Mini-Batch - 5 Back-Prop : 231, Loss : 0.19082403182983398\n",
            "Mini-Batch - 6 Back-Prop : 231, Loss : 0.1779184192419052\n",
            "Mini-Batch - 7 Back-Prop : 231, Loss : 0.1878783106803894\n",
            "Mini-Batch - 8 Back-Prop : 231, Loss : 0.15189231932163239\n",
            "Episode 8420 finished with score 1444.0, result : lose board : [[16.0, 32.0, 4.0, 128.0], [4.0, 16.0, 64.0, 8.0], [2.0, 4.0, 8.0, 32.0], [8.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8425 finished with score 3124.0, result : lose board : [[2, 4.0, 128.0, 2.0], [16.0, 32.0, 64.0, 256.0], [8.0, 16.0, 4.0, 16.0], [4.0, 8.0, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8430 finished with score 876.0, result : lose board : [[16.0, 32.0, 2.0, 64.0], [8.0, 16.0, 32.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8435 finished with score 1016.0, result : lose board : [[16.0, 64.0, 4.0, 8.0], [8.0, 16.0, 32.0, 64.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8440 finished with score 3152.0, result : lose board : [[2.0, 4.0, 128.0, 2.0], [8.0, 64.0, 32.0, 256.0], [4.0, 8.0, 16.0, 32.0], [2.0, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8445 finished with score 3420.0, result : lose board : [[ 16.   2.  32.   2.]\n",
            " [  8.  64. 256.  64.]\n",
            " [  4.   8. 128.  16.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 232, Loss : 0.17534507811069489\n",
            "Mini-Batch - 1 Back-Prop : 232, Loss : 0.17033323645591736\n",
            "Mini-Batch - 2 Back-Prop : 232, Loss : 0.15385858714580536\n",
            "Mini-Batch - 3 Back-Prop : 232, Loss : 0.16254834830760956\n",
            "Mini-Batch - 4 Back-Prop : 232, Loss : 0.18570926785469055\n",
            "Mini-Batch - 5 Back-Prop : 232, Loss : 0.1504611223936081\n",
            "Mini-Batch - 6 Back-Prop : 232, Loss : 0.18172171711921692\n",
            "Mini-Batch - 7 Back-Prop : 232, Loss : 0.19424763321876526\n",
            "Mini-Batch - 8 Back-Prop : 232, Loss : 0.18932142853736877\n",
            "Episode 8450 finished with score 1404.0, result : lose board : [[  2.   4.  64.   2.]\n",
            " [ 32.  16.  32. 128.]\n",
            " [  8.   2.   4.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8455 finished with score 1300.0, result : lose board : [[ 16.  64. 128.  16.]\n",
            " [  8.  32.   2.   8.]\n",
            " [  4.   8.   4.   2.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8460 finished with score 1236.0, result : lose board : [[  2.  16.   2. 128.]\n",
            " [ 32.   4.  32.   8.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8465 finished with score 3176.0, result : lose board : [[2.0, 32.0, 256.0, 4.0], [8.0, 16.0, 32.0, 128.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8470 finished with score 1696.0, result : lose board : [[32.0, 64.0, 128.0, 4.0], [2, 4, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2.0, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8475 finished with score 796.0, result : lose board : [[64.0, 4.0, 32.0, 2.0], [4.0, 32.0, 2.0, 16.0], [2.0, 16.0, 32.0, 8.0], [4, 8.0, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8480 finished with score 1164.0, result : lose board : [[4.0, 32.0, 64.0, 2.0], [2.0, 16.0, 32.0, 64.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 233, Loss : 0.18546655774116516\n",
            "Mini-Batch - 1 Back-Prop : 233, Loss : 0.1738416850566864\n",
            "Mini-Batch - 2 Back-Prop : 233, Loss : 0.21607229113578796\n",
            "Mini-Batch - 3 Back-Prop : 233, Loss : 0.14637231826782227\n",
            "Mini-Batch - 4 Back-Prop : 233, Loss : 0.15649312734603882\n",
            "Mini-Batch - 5 Back-Prop : 233, Loss : 0.18418574333190918\n",
            "Mini-Batch - 6 Back-Prop : 233, Loss : 0.2006872594356537\n",
            "Mini-Batch - 7 Back-Prop : 233, Loss : 0.20089294016361237\n",
            "Mini-Batch - 8 Back-Prop : 233, Loss : 0.1646784245967865\n",
            "Episode 8485 finished with score 1284.0, result : lose board : [[ 2. 64. 32.  2.]\n",
            " [ 8. 32.  8. 64.]\n",
            " [ 4.  8. 64.  8.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8490 finished with score 984.0, result : lose board : [[  2.   4.  16. 128.]\n",
            " [  4.   8.   2.   8.]\n",
            " [  2.  32.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8495 finished with score 1272.0, result : lose board : [[  2.  32. 128.   2.]\n",
            " [  8.   4.  64.   4.]\n",
            " [  2.   8.  16.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8500 finished with score 1484.0, result : lose board : [[32.0, 64.0, 128.0, 4.0], [8.0, 16.0, 2.0, 16.0], [2.0, 8.0, 32.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8505 finished with score 1356.0, result : lose board : [[2.0, 16.0, 4.0, 128.0], [16.0, 2.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8510 finished with score 1596.0, result : lose board : [[16.0, 32.0, 4.0, 128.0], [8.0, 16.0, 32.0, 64.0], [4.0, 8.0, 2.0, 32.0], [2, 4.0, 16.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 234, Loss : 0.19033731520175934\n",
            "Mini-Batch - 1 Back-Prop : 234, Loss : 0.16388536989688873\n",
            "Mini-Batch - 2 Back-Prop : 234, Loss : 0.16606728732585907\n",
            "Mini-Batch - 3 Back-Prop : 234, Loss : 0.15942393243312836\n",
            "Mini-Batch - 4 Back-Prop : 234, Loss : 0.1724221557378769\n",
            "Mini-Batch - 5 Back-Prop : 234, Loss : 0.14405885338783264\n",
            "Mini-Batch - 6 Back-Prop : 234, Loss : 0.15219691395759583\n",
            "Mini-Batch - 7 Back-Prop : 234, Loss : 0.1624438613653183\n",
            "Mini-Batch - 8 Back-Prop : 234, Loss : 0.1438474804162979\n",
            "Episode 8515 finished with score 2780.0, result : lose board : [[  2.  16. 128. 256.]\n",
            " [ 16.   4.   8.   4.]\n",
            " [  4.  16.  32.   2.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8520 finished with score 1668.0, result : lose board : [[4, 2.0, 64.0, 8.0], [8.0, 128.0, 16.0, 4.0], [16.0, 32.0, 64.0, 8.0], [8.0, 16.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8525 finished with score 1076.0, result : lose board : [[32. 64.  2. 64.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 16.  8.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8530 finished with score 3012.0, result : lose board : [[  2.  64. 128. 256.]\n",
            " [ 16.   2.   8.   4.]\n",
            " [  4.   8.   4.  32.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8535 finished with score 772.0, result : lose board : [[16. 32. 64.  4.]\n",
            " [ 8. 16.  2.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8540 finished with score 692.0, result : lose board : [[16.0, 32.0, 16.0, 2.0], [4.0, 16.0, 64.0, 16.0], [2, 8.0, 16.0, 2.0], [8.0, 4.0, 2.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 235, Loss : 0.18661722540855408\n",
            "Mini-Batch - 1 Back-Prop : 235, Loss : 0.154121533036232\n",
            "Mini-Batch - 2 Back-Prop : 235, Loss : 0.18597173690795898\n",
            "Mini-Batch - 3 Back-Prop : 235, Loss : 0.1847093254327774\n",
            "Mini-Batch - 4 Back-Prop : 235, Loss : 0.15879614651203156\n",
            "Mini-Batch - 5 Back-Prop : 235, Loss : 0.16923992335796356\n",
            "Mini-Batch - 6 Back-Prop : 235, Loss : 0.17261989414691925\n",
            "Mini-Batch - 7 Back-Prop : 235, Loss : 0.1786692589521408\n",
            "Mini-Batch - 8 Back-Prop : 235, Loss : 0.1787773072719574\n",
            "Episode 8545 finished with score 1308.0, result : lose board : [[2.0, 8.0, 128.0, 8.0], [8.0, 16.0, 64.0, 2.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8550 finished with score 1696.0, result : lose board : [[ 16.   4. 128.   4.]\n",
            " [  8.  64.  32.  64.]\n",
            " [  4.  16.   4.  32.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8555 finished with score 1332.0, result : lose board : [[16. 64.  4. 64.]\n",
            " [ 8. 32. 64.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8560 finished with score 1004.0, result : lose board : [[ 2. 32. 64.  2.]\n",
            " [ 8.  2. 32. 64.]\n",
            " [ 4. 16.  2. 16.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8565 finished with score 2300.0, result : lose board : [[  4.  32.  64. 256.]\n",
            " [  2.   4.  32.   2.]\n",
            " [  4.   8.   2.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8570 finished with score 1084.0, result : lose board : [[ 8. 32. 16. 64.]\n",
            " [ 4. 16. 64. 16.]\n",
            " [ 2. 32. 16.  4.]\n",
            " [ 4.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8575 finished with score 2756.0, result : lose board : [[  2.  64.   4. 256.]\n",
            " [ 16.  32.  64.   4.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 236, Loss : 0.21674585342407227\n",
            "Mini-Batch - 1 Back-Prop : 236, Loss : 0.1780843734741211\n",
            "Mini-Batch - 2 Back-Prop : 236, Loss : 0.15000616014003754\n",
            "Mini-Batch - 3 Back-Prop : 236, Loss : 0.18131527304649353\n",
            "Mini-Batch - 4 Back-Prop : 236, Loss : 0.17004497349262238\n",
            "Mini-Batch - 5 Back-Prop : 236, Loss : 0.16699787974357605\n",
            "Mini-Batch - 6 Back-Prop : 236, Loss : 0.1637660712003708\n",
            "Mini-Batch - 7 Back-Prop : 236, Loss : 0.16443750262260437\n",
            "Mini-Batch - 8 Back-Prop : 236, Loss : 0.13532906770706177\n",
            "Episode 8580 finished with score 1228.0, result : lose board : [[16. 64.  2. 64.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 16. 64.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8585 finished with score 792.0, result : lose board : [[32.0, 8.0, 32.0, 64.0], [8.0, 2.0, 8.0, 2.0], [4.0, 16.0, 32.0, 8.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8590 finished with score 596.0, result : lose board : [[ 8.  2. 16. 32.]\n",
            " [ 4.  8. 64.  8.]\n",
            " [ 2.  4. 16.  4.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8595 finished with score 1148.0, result : lose board : [[16.0, 32.0, 2.0, 8.0], [2.0, 8.0, 32.0, 128.0], [4.0, 16.0, 4.0, 2], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8600 finished with score 1116.0, result : lose board : [[32.0, 2.0, 16.0, 2.0], [8.0, 32.0, 64.0, 4.0], [4.0, 64.0, 8.0, 32.0], [2, 4, 16, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8605 finished with score 3356.0, result : lose board : [[2.0, 16.0, 32.0, 256.0], [32.0, 64.0, 128.0, 2], [16.0, 8.0, 32.0, 4.0], [4.0, 16.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 237, Loss : 0.20682880282402039\n",
            "Mini-Batch - 1 Back-Prop : 237, Loss : 0.17243702709674835\n",
            "Mini-Batch - 2 Back-Prop : 237, Loss : 0.18722139298915863\n",
            "Mini-Batch - 3 Back-Prop : 237, Loss : 0.20338666439056396\n",
            "Mini-Batch - 4 Back-Prop : 237, Loss : 0.23559387028217316\n",
            "Mini-Batch - 5 Back-Prop : 237, Loss : 0.19137050211429596\n",
            "Mini-Batch - 6 Back-Prop : 237, Loss : 0.18072113394737244\n",
            "Mini-Batch - 7 Back-Prop : 237, Loss : 0.18970923125743866\n",
            "Mini-Batch - 8 Back-Prop : 237, Loss : 0.1770084798336029\n",
            "Episode 8610 finished with score 3196.0, result : lose board : [[2.0, 16.0, 8.0, 256.0], [4.0, 32.0, 128.0, 32.0], [8.0, 2.0, 64.0, 16.0], [2, 4, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8615 finished with score 564.0, result : lose board : [[16.0, 2.0, 4.0, 32.0], [8.0, 16.0, 32.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8620 finished with score 296.0, result : lose board : [[16.  8. 32.  4.]\n",
            " [ 8.  4.  8.  2.]\n",
            " [ 4.  8.  2. 16.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8625 finished with score 2644.0, result : lose board : [[16.0, 256.0, 2.0, 32.0], [8.0, 16.0, 64.0, 16.0], [2.0, 4.0, 8.0, 64.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8630 finished with score 860.0, result : lose board : [[16.0, 32.0, 2.0, 32.0], [2.0, 4.0, 64.0, 16.0], [8.0, 32.0, 16.0, 8.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8635 finished with score 1464.0, result : lose board : [[  2.   4.  64.   8.]\n",
            " [  8.  64.   8.   2.]\n",
            " [  4. 128.   2.  16.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8640 finished with score 3464.0, result : lose board : [[2, 16.0, 128.0, 4.0], [4.0, 2.0, 32.0, 128.0], [2.0, 4.0, 16.0, 256.0], [8.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 238, Loss : 0.17035016417503357\n",
            "Mini-Batch - 1 Back-Prop : 238, Loss : 0.1662997007369995\n",
            "Mini-Batch - 2 Back-Prop : 238, Loss : 0.16847528517246246\n",
            "Mini-Batch - 3 Back-Prop : 238, Loss : 0.22208400070667267\n",
            "Mini-Batch - 4 Back-Prop : 238, Loss : 0.13289859890937805\n",
            "Mini-Batch - 5 Back-Prop : 238, Loss : 0.16549421846866608\n",
            "Mini-Batch - 6 Back-Prop : 238, Loss : 0.1934552788734436\n",
            "Mini-Batch - 7 Back-Prop : 238, Loss : 0.20517230033874512\n",
            "Mini-Batch - 8 Back-Prop : 238, Loss : 0.18856732547283173\n",
            "Episode 8645 finished with score 1560.0, result : lose board : [[  8.  32. 128.   8.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.  16.  32.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8650 finished with score 1284.0, result : lose board : [[  2.  16.  64. 128.]\n",
            " [ 16.  32.   8.   2.]\n",
            " [  2.   4.   2.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8655 finished with score 840.0, result : lose board : [[8.0, 32.0, 2.0, 32.0], [4.0, 16.0, 64.0, 8.0], [2, 4.0, 8.0, 32.0], [4, 2, 4, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8660 finished with score 3304.0, result : lose board : [[  2.   8. 128.   2.]\n",
            " [  8.   4.  64. 256.]\n",
            " [  4.  32.   8.  64.]\n",
            " [  2.   8.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8665 finished with score 1584.0, result : lose board : [[32.0, 4.0, 128.0, 64.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2.0, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 239, Loss : 0.18178199231624603\n",
            "Mini-Batch - 1 Back-Prop : 239, Loss : 0.16824965178966522\n",
            "Mini-Batch - 2 Back-Prop : 239, Loss : 0.17532415688037872\n",
            "Mini-Batch - 3 Back-Prop : 239, Loss : 0.17934902012348175\n",
            "Mini-Batch - 4 Back-Prop : 239, Loss : 0.15673886239528656\n",
            "Mini-Batch - 5 Back-Prop : 239, Loss : 0.18587557971477509\n",
            "Mini-Batch - 6 Back-Prop : 239, Loss : 0.20069260895252228\n",
            "Mini-Batch - 7 Back-Prop : 239, Loss : 0.16765911877155304\n",
            "Mini-Batch - 8 Back-Prop : 239, Loss : 0.1765432506799698\n",
            "Episode 8670 finished with score 3624.0, result : lose board : [[  4.  32. 128.   4.]\n",
            " [128. 256.   4.   8.]\n",
            " [  4.  16.  32.   4.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8675 finished with score 3572.0, result : lose board : [[2.0, 64.0, 128.0, 256.0], [8.0, 16.0, 2.0, 64.0], [4.0, 8.0, 64.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8680 finished with score 1000.0, result : lose board : [[16. 32. 64.  4.]\n",
            " [ 8.  2.  8. 64.]\n",
            " [ 4. 16.  4. 32.]\n",
            " [ 2.  8.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8685 finished with score 1912.0, result : lose board : [[16.0, 32.0, 64.0, 128.0], [8.0, 16.0, 32.0, 64.0], [2.0, 4.0, 16.0, 32.0], [4, 2.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8690 finished with score 1968.0, result : lose board : [[2, 4.0, 64.0, 8.0], [64.0, 128.0, 16.0, 32.0], [8.0, 16.0, 64.0, 16.0], [4.0, 2.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8695 finished with score 1048.0, result : lose board : [[  4.   8.  16. 128.]\n",
            " [  2.   4.   8.   4.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 240, Loss : 0.16862648725509644\n",
            "Mini-Batch - 1 Back-Prop : 240, Loss : 0.17365258932113647\n",
            "Mini-Batch - 2 Back-Prop : 240, Loss : 0.1723358929157257\n",
            "Mini-Batch - 3 Back-Prop : 240, Loss : 0.16599765419960022\n",
            "Mini-Batch - 4 Back-Prop : 240, Loss : 0.1944834440946579\n",
            "Mini-Batch - 5 Back-Prop : 240, Loss : 0.16263891756534576\n",
            "Mini-Batch - 6 Back-Prop : 240, Loss : 0.17002800107002258\n",
            "Mini-Batch - 7 Back-Prop : 240, Loss : 0.18405766785144806\n",
            "Mini-Batch - 8 Back-Prop : 240, Loss : 0.15474607050418854\n",
            "Episode 8700 finished with score 572.0, result : lose board : [[2, 4, 8.0, 32.0], [16.0, 64.0, 4.0, 2.0], [8.0, 2.0, 8.0, 4.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8705 finished with score 1412.0, result : lose board : [[  2.  16. 128.   8.]\n",
            " [ 32.  64.   4.   2.]\n",
            " [  4.   2.  16.   4.]\n",
            " [  2.  32.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8710 finished with score 1716.0, result : lose board : [[2, 4.0, 128.0, 2.0], [32.0, 2.0, 16.0, 64.0], [8.0, 64.0, 8.0, 32.0], [2.0, 4.0, 2.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8715 finished with score 1624.0, result : lose board : [[2, 4, 16.0, 64.0], [16.0, 64.0, 4.0, 2.0], [4.0, 32.0, 128.0, 16.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8720 finished with score 920.0, result : lose board : [[16. 32.  2. 64.]\n",
            " [ 8. 16. 32.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8725 finished with score 1288.0, result : lose board : [[8.0, 32.0, 64.0, 128.0], [4.0, 8.0, 16.0, 4.0], [2.0, 4.0, 8.0, 16.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8730 finished with score 836.0, result : lose board : [[ 2.  4. 16.  2.]\n",
            " [16. 64.  2.  4.]\n",
            " [ 4. 16. 64.  8.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 241, Loss : 0.19735558331012726\n",
            "Mini-Batch - 1 Back-Prop : 241, Loss : 0.16377075016498566\n",
            "Mini-Batch - 2 Back-Prop : 241, Loss : 0.16299015283584595\n",
            "Mini-Batch - 3 Back-Prop : 241, Loss : 0.17045466601848602\n",
            "Mini-Batch - 4 Back-Prop : 241, Loss : 0.16179342567920685\n",
            "Mini-Batch - 5 Back-Prop : 241, Loss : 0.1536690890789032\n",
            "Mini-Batch - 6 Back-Prop : 241, Loss : 0.16030220687389374\n",
            "Mini-Batch - 7 Back-Prop : 241, Loss : 0.18326877057552338\n",
            "Mini-Batch - 8 Back-Prop : 241, Loss : 0.15579161047935486\n",
            "Episode 8735 finished with score 964.0, result : lose board : [[2, 8.0, 4, 2], [32.0, 64.0, 2.0, 64.0], [16.0, 32.0, 8.0, 4.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8740 finished with score 1228.0, result : lose board : [[16.0, 32.0, 4.0, 128.0], [4.0, 16.0, 32.0, 16.0], [2.0, 4.0, 16.0, 8.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8745 finished with score 776.0, result : lose board : [[2, 4.0, 16.0, 64.0], [16.0, 2.0, 8.0, 32.0], [4.0, 16.0, 32.0, 16.0], [2.0, 8.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8750 finished with score 1020.0, result : lose board : [[  4.  16.   2. 128.]\n",
            " [  2.   4.  16.   8.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8755 finished with score 1232.0, result : lose board : [[16.0, 2.0, 128.0, 4.0], [4.0, 8.0, 64.0, 2.0], [2.0, 16.0, 8.0, 16.0], [4.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8760 finished with score 1208.0, result : lose board : [[2.0, 4.0, 32.0, 4.0], [8.0, 32.0, 2.0, 128.0], [4.0, 16.0, 32.0, 8.0], [2.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 242, Loss : 0.19763517379760742\n",
            "Mini-Batch - 1 Back-Prop : 242, Loss : 0.17296800017356873\n",
            "Mini-Batch - 2 Back-Prop : 242, Loss : 0.17702938616275787\n",
            "Mini-Batch - 3 Back-Prop : 242, Loss : 0.16227054595947266\n",
            "Mini-Batch - 4 Back-Prop : 242, Loss : 0.19805486500263214\n",
            "Mini-Batch - 5 Back-Prop : 242, Loss : 0.20623619854450226\n",
            "Mini-Batch - 6 Back-Prop : 242, Loss : 0.16997447609901428\n",
            "Mini-Batch - 7 Back-Prop : 242, Loss : 0.15346886217594147\n",
            "Mini-Batch - 8 Back-Prop : 242, Loss : 0.1951965093612671\n",
            "Episode 8765 finished with score 2616.0, result : lose board : [[16.0, 64.0, 2.0, 256.0], [8.0, 2.0, 64.0, 2], [16.0, 32.0, 2.0, 8.0], [2, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8770 finished with score 2780.0, result : lose board : [[  4.   8.  32.   2.]\n",
            " [ 16.   4. 128. 256.]\n",
            " [  4.   8.  16.   4.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8775 finished with score 972.0, result : lose board : [[8.0, 16.0, 128.0, 16.0], [2.0, 4.0, 2.0, 8.0], [8.0, 2.0, 8.0, 4.0], [2, 4, 16.0, 8]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8780 finished with score 576.0, result : lose board : [[ 8.  2.  4. 64.]\n",
            " [ 2.  8.  2. 16.]\n",
            " [ 8. 32.  8.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8785 finished with score 1596.0, result : lose board : [[2.0, 64.0, 4.0, 64.0], [16.0, 32.0, 64.0, 32.0], [4.0, 8.0, 16.0, 64.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8790 finished with score 2844.0, result : lose board : [[16.0, 32.0, 128.0, 256.0], [8.0, 2.0, 8.0, 16.0], [2.0, 16.0, 4.0, 2.0], [16, 8, 2, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 243, Loss : 0.20971335470676422\n",
            "Mini-Batch - 1 Back-Prop : 243, Loss : 0.18600022792816162\n",
            "Mini-Batch - 2 Back-Prop : 243, Loss : 0.17026960849761963\n",
            "Mini-Batch - 3 Back-Prop : 243, Loss : 0.19064860045909882\n",
            "Mini-Batch - 4 Back-Prop : 243, Loss : 0.14615769684314728\n",
            "Mini-Batch - 5 Back-Prop : 243, Loss : 0.16136041283607483\n",
            "Mini-Batch - 6 Back-Prop : 243, Loss : 0.15978045761585236\n",
            "Mini-Batch - 7 Back-Prop : 243, Loss : 0.15450114011764526\n",
            "Mini-Batch - 8 Back-Prop : 243, Loss : 0.13514041900634766\n",
            "Episode 8795 finished with score 840.0, result : lose board : [[16.0, 2.0, 16.0, 32.0], [8.0, 16.0, 64.0, 16.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8800 finished with score 2352.0, result : lose board : [[ 16.   4.   8. 256.]\n",
            " [  8.  16.  64.   8.]\n",
            " [  2.   4.  16.  32.]\n",
            " [  4.   2.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8805 finished with score 2412.0, result : lose board : [[32.0, 4.0, 2.0, 64.0], [4.0, 8.0, 256.0, 16.0], [2.0, 16.0, 32.0, 4.0], [4.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8810 finished with score 1388.0, result : lose board : [[8.0, 32.0, 128.0, 32.0], [2, 4.0, 8.0, 64.0], [4, 16.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8815 finished with score 552.0, result : lose board : [[ 2.  4. 64.  8.]\n",
            " [ 8.  2. 16. 32.]\n",
            " [ 4.  8.  4.  8.]\n",
            " [ 2.  4.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8820 finished with score 2836.0, result : lose board : [[32.0, 64.0, 256.0, 64.0], [2.0, 4.0, 32.0, 8.0], [8.0, 32.0, 8.0, 4.0], [4, 2, 4, 16]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 244, Loss : 0.1501019448041916\n",
            "Mini-Batch - 1 Back-Prop : 244, Loss : 0.16715669631958008\n",
            "Mini-Batch - 2 Back-Prop : 244, Loss : 0.13243919610977173\n",
            "Mini-Batch - 3 Back-Prop : 244, Loss : 0.14369560778141022\n",
            "Mini-Batch - 4 Back-Prop : 244, Loss : 0.15687230229377747\n",
            "Mini-Batch - 5 Back-Prop : 244, Loss : 0.16615116596221924\n",
            "Mini-Batch - 6 Back-Prop : 244, Loss : 0.1845725178718567\n",
            "Mini-Batch - 7 Back-Prop : 244, Loss : 0.20199082791805267\n",
            "Mini-Batch - 8 Back-Prop : 244, Loss : 0.18103040754795074\n",
            "Episode 8825 finished with score 1620.0, result : lose board : [[ 16.  32.  64. 128.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8830 finished with score 1476.0, result : lose board : [[4.0, 16.0, 64.0, 128.0], [2.0, 4.0, 2.0, 32.0], [8.0, 32.0, 16.0, 2.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8835 finished with score 1768.0, result : lose board : [[  2.   8.  64.   4.]\n",
            " [ 16.  32. 128.   2.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8840 finished with score 996.0, result : lose board : [[  2.  32. 128.  16.]\n",
            " [  8.   4.   8.   4.]\n",
            " [  4.   8.   2.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8845 finished with score 1408.0, result : lose board : [[ 32. 128.   4.  64.]\n",
            " [  2.   4.  16.   8.]\n",
            " [  8.   2.  32.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8850 finished with score 496.0, result : lose board : [[ 4.  8. 16. 64.]\n",
            " [ 2.  4.  8. 16.]\n",
            " [ 4.  2.  4.  2.]\n",
            " [ 2.  4. 16.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8855 finished with score 1972.0, result : lose board : [[ 32. 128.   4. 128.]\n",
            " [  8.  32.   2.  16.]\n",
            " [  4.  16.  32.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 245, Loss : 0.18202580511569977\n",
            "Mini-Batch - 1 Back-Prop : 245, Loss : 0.1770920306444168\n",
            "Mini-Batch - 2 Back-Prop : 245, Loss : 0.19244441390037537\n",
            "Mini-Batch - 3 Back-Prop : 245, Loss : 0.15361548960208893\n",
            "Mini-Batch - 4 Back-Prop : 245, Loss : 0.18717215955257416\n",
            "Mini-Batch - 5 Back-Prop : 245, Loss : 0.14246928691864014\n",
            "Mini-Batch - 6 Back-Prop : 245, Loss : 0.18107619881629944\n",
            "Mini-Batch - 7 Back-Prop : 245, Loss : 0.17429356276988983\n",
            "Mini-Batch - 8 Back-Prop : 245, Loss : 0.1933450698852539\n",
            "Episode 8860 finished with score 3204.0, result : lose board : [[2.0, 4.0, 128.0, 256.0], [16.0, 32.0, 64.0, 4.0], [2, 16.0, 32.0, 16.0], [4.0, 2.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8865 finished with score 3764.0, result : lose board : [[ 16.  32. 128.   8.]\n",
            " [  8.  16.  32. 256.]\n",
            " [  4.   8. 128.  32.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8870 finished with score 1132.0, result : lose board : [[4.0, 128.0, 2.0, 16.0], [2.0, 4.0, 32.0, 8.0], [8.0, 32.0, 2.0, 4.0], [4, 2.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8875 finished with score 1636.0, result : lose board : [[32.0, 2.0, 32.0, 16.0], [2.0, 32.0, 128.0, 2.0], [4.0, 16.0, 32.0, 64.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8880 finished with score 2344.0, result : lose board : [[  2.  32.   2.   8.]\n",
            " [  8.  16.  64. 256.]\n",
            " [  4.   8.   4.  16.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8885 finished with score 1796.0, result : lose board : [[  2.  16.   2.  64.]\n",
            " [ 32. 128.  64.  16.]\n",
            " [  4.  32.  16.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 246, Loss : 0.16917148232460022\n",
            "Mini-Batch - 1 Back-Prop : 246, Loss : 0.1854497194290161\n",
            "Mini-Batch - 2 Back-Prop : 246, Loss : 0.22406356036663055\n",
            "Mini-Batch - 3 Back-Prop : 246, Loss : 0.18604040145874023\n",
            "Mini-Batch - 4 Back-Prop : 246, Loss : 0.18746629357337952\n",
            "Mini-Batch - 5 Back-Prop : 246, Loss : 0.19886919856071472\n",
            "Mini-Batch - 6 Back-Prop : 246, Loss : 0.1418527513742447\n",
            "Mini-Batch - 7 Back-Prop : 246, Loss : 0.15500205755233765\n",
            "Mini-Batch - 8 Back-Prop : 246, Loss : 0.19269271194934845\n",
            "Episode 8890 finished with score 612.0, result : lose board : [[16. 32. 64.  2.]\n",
            " [ 2.  4.  8. 16.]\n",
            " [ 4.  2. 16.  4.]\n",
            " [ 2.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8895 finished with score 1072.0, result : lose board : [[16 32  2 64]\n",
            " [ 8 16 32  8]\n",
            " [ 4  8 64 16]\n",
            " [ 2  4  8  2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8900 finished with score 1232.0, result : lose board : [[  8.  16.   2. 128.]\n",
            " [  4.   8.  64.  16.]\n",
            " [  2.   4.  16.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8905 finished with score 2112.0, result : lose board : [[2.0, 4.0, 64.0, 4.0], [32.0, 128.0, 4.0, 128.0], [2, 4.0, 32.0, 2], [4, 2, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8910 finished with score 2756.0, result : lose board : [[  4. 128. 256.   2.]\n",
            " [  2.   8.  32.   8.]\n",
            " [  4.  16.   8.   2.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 247, Loss : 0.17714911699295044\n",
            "Mini-Batch - 1 Back-Prop : 247, Loss : 0.16374477744102478\n",
            "Mini-Batch - 2 Back-Prop : 247, Loss : 0.16558082401752472\n",
            "Mini-Batch - 3 Back-Prop : 247, Loss : 0.17302517592906952\n",
            "Mini-Batch - 4 Back-Prop : 247, Loss : 0.17530953884124756\n",
            "Mini-Batch - 5 Back-Prop : 247, Loss : 0.20903821289539337\n",
            "Mini-Batch - 6 Back-Prop : 247, Loss : 0.18548820912837982\n",
            "Mini-Batch - 7 Back-Prop : 247, Loss : 0.1513993740081787\n",
            "Mini-Batch - 8 Back-Prop : 247, Loss : 0.1671711951494217\n",
            "Episode 8915 finished with score 1932.0, result : lose board : [[2.0, 8.0, 64.0, 128.0], [4.0, 64.0, 32.0, 2.0], [2, 16.0, 2.0, 64.0], [4.0, 8.0, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8920 finished with score 1344.0, result : lose board : [[8.0, 32.0, 2.0, 128.0], [2.0, 8.0, 64.0, 4.0], [4.0, 2.0, 32.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8925 finished with score 2572.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [16.0, 64.0, 2.0, 256.0], [2, 16.0, 64.0, 2.0], [4.0, 2.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8930 finished with score 2712.0, result : lose board : [[  2.  64.  32.   8.]\n",
            " [ 16.   4. 256.  64.]\n",
            " [  4.   2.  32.   8.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8935 finished with score 2252.0, result : lose board : [[ 16.   2.  64. 128.]\n",
            " [  8.  32. 128.  32.]\n",
            " [  4.  16.   8.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8940 finished with score 648.0, result : lose board : [[32.  2.  8. 32.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 248, Loss : 0.1751890927553177\n",
            "Mini-Batch - 1 Back-Prop : 248, Loss : 0.20276980102062225\n",
            "Mini-Batch - 2 Back-Prop : 248, Loss : 0.1887461096048355\n",
            "Mini-Batch - 3 Back-Prop : 248, Loss : 0.1699841022491455\n",
            "Mini-Batch - 4 Back-Prop : 248, Loss : 0.19526052474975586\n",
            "Mini-Batch - 5 Back-Prop : 248, Loss : 0.2170390784740448\n",
            "Mini-Batch - 6 Back-Prop : 248, Loss : 0.18617363274097443\n",
            "Mini-Batch - 7 Back-Prop : 248, Loss : 0.15296348929405212\n",
            "Mini-Batch - 8 Back-Prop : 248, Loss : 0.15077154338359833\n",
            "Episode 8945 finished with score 2892.0, result : lose board : [[4.0, 8.0, 32.0, 2.0], [2.0, 32.0, 128.0, 8.0], [4.0, 16.0, 256.0, 2.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8950 finished with score 304.0, result : lose board : [[ 2.  8. 16. 32.]\n",
            " [ 8.  2.  8. 16.]\n",
            " [ 4.  8.  2.  8.]\n",
            " [ 2.  4.  8.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8955 finished with score 644.0, result : lose board : [[16.  2. 64.  4.]\n",
            " [ 8. 32. 16.  8.]\n",
            " [ 4.  8.  4.  2.]\n",
            " [ 2.  4.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8960 finished with score 856.0, result : lose board : [[32.0, 2.0, 32.0, 4.0], [8.0, 16.0, 64.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8965 finished with score 1564.0, result : lose board : [[2, 4.0, 16.0, 64.0], [8.0, 16.0, 128.0, 8.0], [4.0, 8.0, 64.0, 2.0], [2.0, 16.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8970 finished with score 1040.0, result : lose board : [[16. 32. 64.  8.]\n",
            " [ 2.  8. 32. 64.]\n",
            " [ 4.  2. 16.  4.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8975 finished with score 864.0, result : lose board : [[4.0, 2.0, 64.0, 2.0], [2.0, 8.0, 2.0, 32.0], [4.0, 16.0, 64.0, 2], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 249, Loss : 0.19945794343948364\n",
            "Mini-Batch - 1 Back-Prop : 249, Loss : 0.14646217226982117\n",
            "Mini-Batch - 2 Back-Prop : 249, Loss : 0.1754685789346695\n",
            "Mini-Batch - 3 Back-Prop : 249, Loss : 0.1459062397480011\n",
            "Mini-Batch - 4 Back-Prop : 249, Loss : 0.1598924696445465\n",
            "Mini-Batch - 5 Back-Prop : 249, Loss : 0.1550167351961136\n",
            "Mini-Batch - 6 Back-Prop : 249, Loss : 0.15179982781410217\n",
            "Mini-Batch - 7 Back-Prop : 249, Loss : 0.17942140996456146\n",
            "Mini-Batch - 8 Back-Prop : 249, Loss : 0.15715837478637695\n",
            "Episode 8980 finished with score 476.0, result : lose board : [[ 2.  4. 16. 32.]\n",
            " [ 8.  2.  8. 16.]\n",
            " [ 4. 16. 32.  4.]\n",
            " [16.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8985 finished with score 1584.0, result : lose board : [[2, 4.0, 128.0, 2.0], [4.0, 8.0, 64.0, 4.0], [16.0, 32.0, 16.0, 64.0], [2.0, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8990 finished with score 1120.0, result : lose board : [[2, 8.0, 32.0, 64.0], [4.0, 32.0, 64.0, 32.0], [2.0, 4.0, 8.0, 16.0], [16.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 8995 finished with score 2472.0, result : lose board : [[  4.   2. 256.   4.]\n",
            " [  8.  64.   4.   2.]\n",
            " [  4.   8.  64.   8.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Maximum Score : 6356.0 ,Episode : 5768\n",
            "Loss : 0.16339819464418623\n",
            "\n",
            "Episode 9000 finished with score 1432.0, result : lose board : [[ 16.  32.  64. 128.]\n",
            " [  8.   2.   4.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9005 finished with score 580.0, result : lose board : [[2.0, 4.0, 32.0, 2.0], [8.0, 32.0, 4.0, 32.0], [4, 8.0, 32.0, 2.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 250, Loss : 0.22467410564422607\n",
            "Mini-Batch - 1 Back-Prop : 250, Loss : 0.1985572874546051\n",
            "Mini-Batch - 2 Back-Prop : 250, Loss : 0.20619016885757446\n",
            "Mini-Batch - 3 Back-Prop : 250, Loss : 0.1833212971687317\n",
            "Mini-Batch - 4 Back-Prop : 250, Loss : 0.17405790090560913\n",
            "Mini-Batch - 5 Back-Prop : 250, Loss : 0.14257816970348358\n",
            "Mini-Batch - 6 Back-Prop : 250, Loss : 0.1681523621082306\n",
            "Mini-Batch - 7 Back-Prop : 250, Loss : 0.17424164712429047\n",
            "Mini-Batch - 8 Back-Prop : 250, Loss : 0.22056718170642853\n",
            "Episode 9010 finished with score 1620.0, result : lose board : [[16.0, 64.0, 4.0, 16.0], [4.0, 32.0, 128.0, 32.0], [2, 8.0, 32.0, 16.0], [4.0, 16.0, 2.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9015 finished with score 1568.0, result : lose board : [[8.0, 32.0, 2.0, 32.0], [4.0, 128.0, 64.0, 16.0], [2.0, 8.0, 32.0, 8.0], [8, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9020 finished with score 2428.0, result : lose board : [[  2.  16.   8.  16.]\n",
            " [  4.   8. 256.  32.]\n",
            " [  2.  64.  32.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9025 finished with score 3872.0, result : lose board : [[64.0, 32.0, 128.0, 4.0], [8.0, 16.0, 256.0, 2.0], [4.0, 8.0, 128.0, 16.0], [2, 4.0, 16.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9030 finished with score 1140.0, result : lose board : [[16.0, 32.0, 64.0, 2.0], [4.0, 16.0, 32.0, 64.0], [2.0, 4.0, 16.0, 32.0], [4, 2.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9035 finished with score 1228.0, result : lose board : [[8.0, 4.0, 128.0, 4.0], [4.0, 8.0, 16.0, 64.0], [2.0, 4.0, 8.0, 16.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 251, Loss : 0.18649792671203613\n",
            "Mini-Batch - 1 Back-Prop : 251, Loss : 0.1798989474773407\n",
            "Mini-Batch - 2 Back-Prop : 251, Loss : 0.1883249580860138\n",
            "Mini-Batch - 3 Back-Prop : 251, Loss : 0.17879429459571838\n",
            "Mini-Batch - 4 Back-Prop : 251, Loss : 0.1435985267162323\n",
            "Mini-Batch - 5 Back-Prop : 251, Loss : 0.18316666781902313\n",
            "Mini-Batch - 6 Back-Prop : 251, Loss : 0.17073971033096313\n",
            "Mini-Batch - 7 Back-Prop : 251, Loss : 0.1565648466348648\n",
            "Mini-Batch - 8 Back-Prop : 251, Loss : 0.18193480372428894\n",
            "Episode 9040 finished with score 1440.0, result : lose board : [[  2.  16.   4. 128.]\n",
            " [ 16.  32.  64.   2.]\n",
            " [  4.  16.   2.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9045 finished with score 960.0, result : lose board : [[ 2. 16. 64. 16.]\n",
            " [ 8. 64. 16.  4.]\n",
            " [ 4.  8. 32.  2.]\n",
            " [ 2.  4. 16.  8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9050 finished with score 1288.0, result : lose board : [[4.0, 32.0, 64.0, 128.0], [2.0, 8.0, 2.0, 8.0], [4.0, 16.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9055 finished with score 836.0, result : lose board : [[16.  2.  4. 32.]\n",
            " [ 8. 32. 64.  8.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9060 finished with score 804.0, result : lose board : [[4.0, 32.0, 64.0, 2.0], [2.0, 4.0, 2.0, 64.0], [4.0, 2.0, 16.0, 2.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9065 finished with score 2368.0, result : lose board : [[  2.   4.  32. 256.]\n",
            " [ 16.   2.  16.  64.]\n",
            " [  4.  16.   4.   2.]\n",
            " [  2.   8.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9070 finished with score 320.0, result : lose board : [[2, 16.0, 2.0, 4.0], [4.0, 8.0, 16.0, 32.0], [8.0, 16.0, 2.0, 8.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 252, Loss : 0.18057313561439514\n",
            "Mini-Batch - 1 Back-Prop : 252, Loss : 0.18467170000076294\n",
            "Mini-Batch - 2 Back-Prop : 252, Loss : 0.17156729102134705\n",
            "Mini-Batch - 3 Back-Prop : 252, Loss : 0.16351893544197083\n",
            "Mini-Batch - 4 Back-Prop : 252, Loss : 0.18131393194198608\n",
            "Mini-Batch - 5 Back-Prop : 252, Loss : 0.16835235059261322\n",
            "Mini-Batch - 6 Back-Prop : 252, Loss : 0.19808973371982574\n",
            "Mini-Batch - 7 Back-Prop : 252, Loss : 0.16970914602279663\n",
            "Mini-Batch - 8 Back-Prop : 252, Loss : 0.17042575776576996\n",
            "Episode 9075 finished with score 4700.0, result : lose board : [[16.0, 2.0, 512.0, 16.0], [8.0, 16.0, 64.0, 2.0], [4, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9080 finished with score 1300.0, result : lose board : [[  2.  32. 128.   2.]\n",
            " [ 16.   8.  32.  16.]\n",
            " [  4.  32.  16.   8.]\n",
            " [  8.   2.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9085 finished with score 2412.0, result : lose board : [[  4.  16.   4.   2.]\n",
            " [  2.  32. 256.   4.]\n",
            " [  8.  64.  32.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9090 finished with score 2972.0, result : lose board : [[  8.  32. 256.  32.]\n",
            " [  4.  16.   4. 128.]\n",
            " [  2.   8.  32.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9095 finished with score 1464.0, result : lose board : [[16.0, 4.0, 128.0, 8.0], [8.0, 32.0, 64.0, 4.0], [4.0, 8.0, 32.0, 2.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9100 finished with score 1216.0, result : lose board : [[ 16.   2.  32.   2.]\n",
            " [  8.  32. 128.   4.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 253, Loss : 0.1699252724647522\n",
            "Mini-Batch - 1 Back-Prop : 253, Loss : 0.1968684047460556\n",
            "Mini-Batch - 2 Back-Prop : 253, Loss : 0.1764916479587555\n",
            "Mini-Batch - 3 Back-Prop : 253, Loss : 0.20241977274417877\n",
            "Mini-Batch - 4 Back-Prop : 253, Loss : 0.17652462422847748\n",
            "Mini-Batch - 5 Back-Prop : 253, Loss : 0.1713775098323822\n",
            "Mini-Batch - 6 Back-Prop : 253, Loss : 0.19679750502109528\n",
            "Mini-Batch - 7 Back-Prop : 253, Loss : 0.16789841651916504\n",
            "Mini-Batch - 8 Back-Prop : 253, Loss : 0.16446176171302795\n",
            "Episode 9105 finished with score 2424.0, result : lose board : [[8.0, 32.0, 2.0, 4.0], [4.0, 16.0, 256.0, 64.0], [2, 4.0, 8.0, 32.0], [16.0, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9110 finished with score 624.0, result : lose board : [[ 8. 16. 32. 64.]\n",
            " [ 2.  4. 16.  4.]\n",
            " [ 4.  2.  8.  2.]\n",
            " [ 2.  4.  2. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9115 finished with score 1660.0, result : lose board : [[2.0, 16.0, 64.0, 128.0], [16.0, 8.0, 32.0, 64.0], [4.0, 2.0, 16.0, 8.0], [2.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9120 finished with score 352.0, result : lose board : [[16.0, 2.0, 4.0, 16.0], [8.0, 16.0, 2.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9125 finished with score 1400.0, result : lose board : [[32. 64.  2. 32.]\n",
            " [ 8. 32. 64. 16.]\n",
            " [ 4. 64.  8.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 254, Loss : 0.20458252727985382\n",
            "Mini-Batch - 1 Back-Prop : 254, Loss : 0.1705869436264038\n",
            "Mini-Batch - 2 Back-Prop : 254, Loss : 0.16813921928405762\n",
            "Mini-Batch - 3 Back-Prop : 254, Loss : 0.15724697709083557\n",
            "Mini-Batch - 4 Back-Prop : 254, Loss : 0.1914132535457611\n",
            "Mini-Batch - 5 Back-Prop : 254, Loss : 0.1609600931406021\n",
            "Mini-Batch - 6 Back-Prop : 254, Loss : 0.18997913599014282\n",
            "Mini-Batch - 7 Back-Prop : 254, Loss : 0.16155408322811127\n",
            "Mini-Batch - 8 Back-Prop : 254, Loss : 0.18739163875579834\n",
            "Episode 9130 finished with score 3076.0, result : lose board : [[16.0, 2.0, 256.0, 8.0], [2.0, 128.0, 8.0, 64.0], [8.0, 16.0, 2.0, 32.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9135 finished with score 1652.0, result : lose board : [[ 2. 64.  4. 64.]\n",
            " [16. 32. 64. 16.]\n",
            " [ 8. 64. 32.  8.]\n",
            " [ 2. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9140 finished with score 1392.0, result : lose board : [[4.0, 32.0, 64.0, 128.0], [2.0, 8.0, 32.0, 4.0], [4, 16.0, 4, 2], [2, 4, 8, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9145 finished with score 1352.0, result : lose board : [[  4.  16.  64. 128.]\n",
            " [  2.   8.  16.   4.]\n",
            " [  8.   2.  32.  16.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9150 finished with score 2288.0, result : lose board : [[2, 4.0, 8.0, 32.0], [8.0, 16.0, 64.0, 2.0], [4.0, 2.0, 4.0, 256.0], [2.0, 4.0, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9155 finished with score 2372.0, result : lose board : [[128.0, 64.0, 2.0, 8.0], [8.0, 16.0, 32.0, 128.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9160 finished with score 820.0, result : lose board : [[ 2.  4. 32. 64.]\n",
            " [ 8.  2.  8.  4.]\n",
            " [ 2. 16. 64.  8.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 255, Loss : 0.1930500566959381\n",
            "Mini-Batch - 1 Back-Prop : 255, Loss : 0.16822108626365662\n",
            "Mini-Batch - 2 Back-Prop : 255, Loss : 0.16331572830677032\n",
            "Mini-Batch - 3 Back-Prop : 255, Loss : 0.2035885751247406\n",
            "Mini-Batch - 4 Back-Prop : 255, Loss : 0.15273557603359222\n",
            "Mini-Batch - 5 Back-Prop : 255, Loss : 0.16139459609985352\n",
            "Mini-Batch - 6 Back-Prop : 255, Loss : 0.16429471969604492\n",
            "Mini-Batch - 7 Back-Prop : 255, Loss : 0.15368004143238068\n",
            "Mini-Batch - 8 Back-Prop : 255, Loss : 0.15860876441001892\n",
            "Episode 9165 finished with score 1624.0, result : lose board : [[ 16.  32.  64.   8.]\n",
            " [  8.  16.   2. 128.]\n",
            " [  4.   8.  64.   2.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9170 finished with score 452.0, result : lose board : [[ 4. 16.  4.  2.]\n",
            " [ 8.  4.  2. 32.]\n",
            " [16.  8. 32.  8.]\n",
            " [ 2. 16.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9175 finished with score 636.0, result : lose board : [[ 8. 16.  2. 64.]\n",
            " [ 4.  8. 32.  8.]\n",
            " [ 8. 16.  8.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9180 finished with score 1380.0, result : lose board : [[32.0, 64.0, 4.0, 2.0], [2.0, 8.0, 128.0, 16.0], [4.0, 2.0, 32.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9185 finished with score 1428.0, result : lose board : [[2.0, 32.0, 2.0, 4.0], [8.0, 4.0, 64.0, 128.0], [2.0, 16.0, 32.0, 16.0], [4.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9190 finished with score 2416.0, result : lose board : [[  2.   8.  16.   2.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  2.  16.  32.   4.]\n",
            " [  4.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 256, Loss : 0.1865164190530777\n",
            "Mini-Batch - 1 Back-Prop : 256, Loss : 0.1803717464208603\n",
            "Mini-Batch - 2 Back-Prop : 256, Loss : 0.18431593477725983\n",
            "Mini-Batch - 3 Back-Prop : 256, Loss : 0.18264541029930115\n",
            "Mini-Batch - 4 Back-Prop : 256, Loss : 0.14124935865402222\n",
            "Mini-Batch - 5 Back-Prop : 256, Loss : 0.1935301125049591\n",
            "Mini-Batch - 6 Back-Prop : 256, Loss : 0.1562618464231491\n",
            "Mini-Batch - 7 Back-Prop : 256, Loss : 0.14600062370300293\n",
            "Mini-Batch - 8 Back-Prop : 256, Loss : 0.1850791573524475\n",
            "Episode 9195 finished with score 768.0, result : lose board : [[4.0, 64.0, 2.0, 16.0], [16.0, 2.0, 64.0, 4.0], [2.0, 4.0, 2.0, 16.0], [4, 2.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9200 finished with score 3088.0, result : lose board : [[8.0, 16.0, 2.0, 256.0], [2.0, 8.0, 128.0, 8.0], [4.0, 64.0, 16.0, 2], [2, 4.0, 8.0, 32.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9205 finished with score 600.0, result : lose board : [[16.0, 32.0, 2.0, 16.0], [4.0, 16.0, 32.0, 8.0], [2.0, 8.0, 16.0, 32.0], [4.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9210 finished with score 1504.0, result : lose board : [[16.0, 32.0, 2.0, 128.0], [8.0, 16.0, 64.0, 16.0], [2, 4.0, 32.0, 8.0], [16.0, 8, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9215 finished with score 1948.0, result : lose board : [[ 16.  64.   4. 128.]\n",
            " [  8.  32.  64.   8.]\n",
            " [  2.   8.  16.  64.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9220 finished with score 1712.0, result : lose board : [[  4.   2. 128.   4.]\n",
            " [  8.  16.  32. 128.]\n",
            " [  4.   2.   4.   8.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9225 finished with score 740.0, result : lose board : [[8.0, 32.0, 64.0, 2.0], [2, 8.0, 16.0, 32.0], [4, 2, 4, 16], [2, 8, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 257, Loss : 0.15238884091377258\n",
            "Mini-Batch - 1 Back-Prop : 257, Loss : 0.14749379456043243\n",
            "Mini-Batch - 2 Back-Prop : 257, Loss : 0.1658601611852646\n",
            "Mini-Batch - 3 Back-Prop : 257, Loss : 0.16803041100502014\n",
            "Mini-Batch - 4 Back-Prop : 257, Loss : 0.15184445679187775\n",
            "Mini-Batch - 5 Back-Prop : 257, Loss : 0.1758601814508438\n",
            "Mini-Batch - 6 Back-Prop : 257, Loss : 0.1568591147661209\n",
            "Mini-Batch - 7 Back-Prop : 257, Loss : 0.19684940576553345\n",
            "Mini-Batch - 8 Back-Prop : 257, Loss : 0.17790718376636505\n",
            "Episode 9230 finished with score 692.0, result : lose board : [[ 2. 32.  8.  2.]\n",
            " [16.  4. 64.  4.]\n",
            " [ 2. 16. 32.  2.]\n",
            " [ 8.  4.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9235 finished with score 2536.0, result : lose board : [[ 16.   2.  64.   4.]\n",
            " [  8.  16.   2. 256.]\n",
            " [  4.   8.  64.   8.]\n",
            " [  2.  16.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9240 finished with score 2068.0, result : lose board : [[2, 4.0, 128.0, 2.0], [16.0, 32.0, 64.0, 128.0], [8.0, 16.0, 2.0, 8.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9245 finished with score 524.0, result : lose board : [[ 4. 32.  2. 32.]\n",
            " [ 2.  4. 32.  8.]\n",
            " [ 8. 16.  8.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9250 finished with score 900.0, result : lose board : [[16.0, 32.0, 2.0, 64.0], [2.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9255 finished with score 1412.0, result : lose board : [[4.0, 128.0, 2.0, 32.0], [2, 4.0, 64.0, 16.0], [8.0, 32.0, 8.0, 2.0], [2.0, 4.0, 2.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 258, Loss : 0.19140560925006866\n",
            "Mini-Batch - 1 Back-Prop : 258, Loss : 0.16470235586166382\n",
            "Mini-Batch - 2 Back-Prop : 258, Loss : 0.17394471168518066\n",
            "Mini-Batch - 3 Back-Prop : 258, Loss : 0.19960924983024597\n",
            "Mini-Batch - 4 Back-Prop : 258, Loss : 0.13956475257873535\n",
            "Mini-Batch - 5 Back-Prop : 258, Loss : 0.1532093584537506\n",
            "Mini-Batch - 6 Back-Prop : 258, Loss : 0.1671871542930603\n",
            "Mini-Batch - 7 Back-Prop : 258, Loss : 0.2088412344455719\n",
            "Mini-Batch - 8 Back-Prop : 258, Loss : 0.16499368846416473\n",
            "Episode 9260 finished with score 1064.0, result : lose board : [[4.0, 32.0, 128.0, 2.0], [2.0, 4.0, 2.0, 4.0], [4.0, 2.0, 16.0, 32.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9265 finished with score 2336.0, result : lose board : [[ 16.   2. 256.   2.]\n",
            " [  8.  32.   4.   8.]\n",
            " [  2.   8.  64.  16.]\n",
            " [  4.   2.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9270 finished with score 892.0, result : lose board : [[16.0, 32.0, 16.0, 64.0], [4.0, 16.0, 2.0, 32.0], [32.0, 8.0, 4.0, 2], [2, 4.0, 16.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9275 finished with score 1516.0, result : lose board : [[2.0, 4.0, 32.0, 64.0], [8.0, 32.0, 128.0, 8.0], [4.0, 8.0, 32.0, 4.0], [2, 4.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9280 finished with score 1376.0, result : lose board : [[ 32.   4.   8. 128.]\n",
            " [  8.  32.   2.  32.]\n",
            " [  4.   8.  32.  16.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9285 finished with score 1464.0, result : lose board : [[16.0, 2.0, 4.0, 8.0], [8.0, 32.0, 128.0, 4.0], [4.0, 8.0, 64.0, 32.0], [2, 4, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 259, Loss : 0.1771601289510727\n",
            "Mini-Batch - 1 Back-Prop : 259, Loss : 0.1507605016231537\n",
            "Mini-Batch - 2 Back-Prop : 259, Loss : 0.1669662743806839\n",
            "Mini-Batch - 3 Back-Prop : 259, Loss : 0.15883493423461914\n",
            "Mini-Batch - 4 Back-Prop : 259, Loss : 0.15413449704647064\n",
            "Mini-Batch - 5 Back-Prop : 259, Loss : 0.18195679783821106\n",
            "Mini-Batch - 6 Back-Prop : 259, Loss : 0.13648787140846252\n",
            "Mini-Batch - 7 Back-Prop : 259, Loss : 0.16632869839668274\n",
            "Mini-Batch - 8 Back-Prop : 259, Loss : 0.15983662009239197\n",
            "Episode 9290 finished with score 760.0, result : lose board : [[4.0, 8.0, 32.0, 64.0], [2.0, 4.0, 8.0, 32.0], [8.0, 32.0, 2.0, 8.0], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9295 finished with score 1384.0, result : lose board : [[32.0, 4.0, 2.0, 16.0], [16.0, 2.0, 128.0, 8.0], [4.0, 16.0, 64.0, 2.0], [2, 4.0, 16.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9300 finished with score 1036.0, result : lose board : [[4, 2, 8, 16.0], [2.0, 32.0, 128.0, 2.0], [8.0, 4.0, 8.0, 16.0], [16.0, 2.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9305 finished with score 1012.0, result : lose board : [[ 2.  8.  4. 64.]\n",
            " [ 4. 32. 64.  8.]\n",
            " [ 8. 16. 32.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9310 finished with score 1180.0, result : lose board : [[ 16.  32. 128.  16.]\n",
            " [  8.  16.   8.   2.]\n",
            " [  4.   2.   4.  32.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9315 finished with score 516.0, result : lose board : [[ 2. 16. 64.  2.]\n",
            " [ 8.  4. 16.  8.]\n",
            " [ 4.  2.  8.  2.]\n",
            " [ 2.  8.  2. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 260, Loss : 0.16209691762924194\n",
            "Mini-Batch - 1 Back-Prop : 260, Loss : 0.1667708456516266\n",
            "Mini-Batch - 2 Back-Prop : 260, Loss : 0.20425178110599518\n",
            "Mini-Batch - 3 Back-Prop : 260, Loss : 0.1905132383108139\n",
            "Mini-Batch - 4 Back-Prop : 260, Loss : 0.19747766852378845\n",
            "Mini-Batch - 5 Back-Prop : 260, Loss : 0.2050304114818573\n",
            "Mini-Batch - 6 Back-Prop : 260, Loss : 0.19739176332950592\n",
            "Mini-Batch - 7 Back-Prop : 260, Loss : 0.1858871877193451\n",
            "Mini-Batch - 8 Back-Prop : 260, Loss : 0.19382700324058533\n",
            "Episode 9320 finished with score 2716.0, result : lose board : [[16.0, 32.0, 4.0, 2.0], [2.0, 8.0, 64.0, 256.0], [4.0, 64.0, 32.0, 8.0], [2, 4, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9325 finished with score 1472.0, result : lose board : [[ 16.   2.  16.   8.]\n",
            " [  8.  16.  64. 128.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9330 finished with score 1584.0, result : lose board : [[ 16.  64.   2. 128.]\n",
            " [  8.   2.  16.   8.]\n",
            " [ 16.  64.   8.   4.]\n",
            " [  2.   4.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9335 finished with score 1392.0, result : lose board : [[ 16.   2.  64.   4.]\n",
            " [  8.  16.   4. 128.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9340 finished with score 2640.0, result : lose board : [[16.0, 64.0, 4.0, 256.0], [8.0, 16.0, 64.0, 16.0], [4.0, 8.0, 16.0, 8.0], [2.0, 16.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9345 finished with score 844.0, result : lose board : [[32.  2.  4.  8.]\n",
            " [ 8. 16. 32. 64.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 261, Loss : 0.2161235809326172\n",
            "Mini-Batch - 1 Back-Prop : 261, Loss : 0.1650824099779129\n",
            "Mini-Batch - 2 Back-Prop : 261, Loss : 0.16231301426887512\n",
            "Mini-Batch - 3 Back-Prop : 261, Loss : 0.18700791895389557\n",
            "Mini-Batch - 4 Back-Prop : 261, Loss : 0.19062121212482452\n",
            "Mini-Batch - 5 Back-Prop : 261, Loss : 0.15458105504512787\n",
            "Mini-Batch - 6 Back-Prop : 261, Loss : 0.17053787410259247\n",
            "Mini-Batch - 7 Back-Prop : 261, Loss : 0.14153027534484863\n",
            "Mini-Batch - 8 Back-Prop : 261, Loss : 0.18399973213672638\n",
            "Episode 9350 finished with score 1080.0, result : lose board : [[4.0, 16.0, 32.0, 128.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4.0, 8.0], [2.0, 4.0, 2.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9355 finished with score 1896.0, result : lose board : [[64.0, 128.0, 4.0, 2.0], [16.0, 64.0, 2.0, 64.0], [4.0, 8.0, 16.0, 4.0], [2, 4.0, 32.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9360 finished with score 796.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 64. 16.]\n",
            " [ 2.  4. 16.  4.]\n",
            " [ 4. 16.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9365 finished with score 892.0, result : lose board : [[ 8.  2. 64.  8.]\n",
            " [ 2.  4. 16. 64.]\n",
            " [16.  8. 32.  4.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9370 finished with score 2464.0, result : lose board : [[8.0, 32.0, 64.0, 256.0], [2, 8.0, 16.0, 32.0], [8.0, 16.0, 2.0, 4], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9375 finished with score 4460.0, result : lose board : [[  4. 256.   8. 256.]\n",
            " [ 16.  32.  64.   8.]\n",
            " [  4.   8.   2.  64.]\n",
            " [  2.   4.   8.  32.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 262, Loss : 0.1747853308916092\n",
            "Mini-Batch - 1 Back-Prop : 262, Loss : 0.1818762570619583\n",
            "Mini-Batch - 2 Back-Prop : 262, Loss : 0.17718815803527832\n",
            "Mini-Batch - 3 Back-Prop : 262, Loss : 0.1759892702102661\n",
            "Mini-Batch - 4 Back-Prop : 262, Loss : 0.2073134332895279\n",
            "Mini-Batch - 5 Back-Prop : 262, Loss : 0.1733519434928894\n",
            "Mini-Batch - 6 Back-Prop : 262, Loss : 0.21572120487689972\n",
            "Mini-Batch - 7 Back-Prop : 262, Loss : 0.17362822592258453\n",
            "Mini-Batch - 8 Back-Prop : 262, Loss : 0.1545705944299698\n",
            "Episode 9380 finished with score 716.0, result : lose board : [[16. 32.  2.  8.]\n",
            " [ 8. 16. 32.  2.]\n",
            " [ 4.  8. 64.  4.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9385 finished with score 856.0, result : lose board : [[16.0, 32.0, 64.0, 4.0], [8.0, 16.0, 32.0, 2.0], [2.0, 4.0, 16.0, 32.0], [4, 2.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9390 finished with score 748.0, result : lose board : [[16.  4. 32. 64.]\n",
            " [ 8. 16.  4.  2.]\n",
            " [ 4.  8. 16. 32.]\n",
            " [ 2.  4.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9395 finished with score 2604.0, result : lose board : [[  4.   2.  64.   2.]\n",
            " [  8.  16.  32. 256.]\n",
            " [  4.   8.  64.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9400 finished with score 1508.0, result : lose board : [[2.0, 16.0, 32.0, 16.0], [8.0, 4.0, 128.0, 64.0], [2.0, 16.0, 32.0, 4.0], [16.0, 8, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9405 finished with score 1556.0, result : lose board : [[  4. 128.   2. 128.]\n",
            " [  8.   4.  16.   2.]\n",
            " [  4.   2.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 263, Loss : 0.14715439081192017\n",
            "Mini-Batch - 1 Back-Prop : 263, Loss : 0.16756880283355713\n",
            "Mini-Batch - 2 Back-Prop : 263, Loss : 0.1753983348608017\n",
            "Mini-Batch - 3 Back-Prop : 263, Loss : 0.21245607733726501\n",
            "Mini-Batch - 4 Back-Prop : 263, Loss : 0.15517674386501312\n",
            "Mini-Batch - 5 Back-Prop : 263, Loss : 0.2042860984802246\n",
            "Mini-Batch - 6 Back-Prop : 263, Loss : 0.16593407094478607\n",
            "Mini-Batch - 7 Back-Prop : 263, Loss : 0.20931489765644073\n",
            "Mini-Batch - 8 Back-Prop : 263, Loss : 0.1740695685148239\n",
            "Episode 9410 finished with score 1652.0, result : lose board : [[ 32.   2. 128.   4.]\n",
            " [  8.  64.   4.  64.]\n",
            " [  4.   2.  32.   8.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9415 finished with score 1552.0, result : lose board : [[16.0, 64.0, 128.0, 2.0], [4.0, 16.0, 64.0, 16.0], [2.0, 4.0, 16.0, 2.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9420 finished with score 636.0, result : lose board : [[ 2. 32. 16.  4.]\n",
            " [ 8.  4.  8. 64.]\n",
            " [ 4. 32.  4.  2.]\n",
            " [ 2.  4.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9425 finished with score 528.0, result : lose board : [[ 2.  4.  8. 32.]\n",
            " [ 8. 16. 32.  8.]\n",
            " [ 4. 32.  8. 16.]\n",
            " [ 2.  8.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9430 finished with score 1500.0, result : lose board : [[16.0, 4.0, 128.0, 2.0], [8.0, 16.0, 32.0, 4.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 32.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9435 finished with score 740.0, result : lose board : [[ 4.  2. 32.  2.]\n",
            " [ 2.  4. 16. 64.]\n",
            " [ 8. 16.  2.  8.]\n",
            " [ 4. 32.  4. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 264, Loss : 0.19306877255439758\n",
            "Mini-Batch - 1 Back-Prop : 264, Loss : 0.15456125140190125\n",
            "Mini-Batch - 2 Back-Prop : 264, Loss : 0.15396204590797424\n",
            "Mini-Batch - 3 Back-Prop : 264, Loss : 0.20271211862564087\n",
            "Mini-Batch - 4 Back-Prop : 264, Loss : 0.1667296141386032\n",
            "Mini-Batch - 5 Back-Prop : 264, Loss : 0.17558814585208893\n",
            "Mini-Batch - 6 Back-Prop : 264, Loss : 0.18141233921051025\n",
            "Mini-Batch - 7 Back-Prop : 264, Loss : 0.16786658763885498\n",
            "Mini-Batch - 8 Back-Prop : 264, Loss : 0.18912243843078613\n",
            "Episode 9440 finished with score 1640.0, result : lose board : [[  2.   4.   8.  16.]\n",
            " [ 32.   8. 128.  64.]\n",
            " [  8.  16.  64.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9445 finished with score 2796.0, result : lose board : [[  2.  16.  32.   2.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9450 finished with score 492.0, result : lose board : [[ 8. 16. 32.  4.]\n",
            " [ 2.  8. 16. 32.]\n",
            " [ 8. 16.  8.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9455 finished with score 1428.0, result : lose board : [[  2.  64. 128.   4.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9460 finished with score 1464.0, result : lose board : [[  4.  16. 128.   8.]\n",
            " [ 16.  32.   2.   4.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9465 finished with score 3816.0, result : lose board : [[16.0, 128.0, 4.0, 2.0], [4.0, 64.0, 256.0, 128.0], [2.0, 8.0, 32.0, 16.0], [4.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 265, Loss : 0.13525831699371338\n",
            "Mini-Batch - 1 Back-Prop : 265, Loss : 0.18665100634098053\n",
            "Mini-Batch - 2 Back-Prop : 265, Loss : 0.18239152431488037\n",
            "Mini-Batch - 3 Back-Prop : 265, Loss : 0.20563407242298126\n",
            "Mini-Batch - 4 Back-Prop : 265, Loss : 0.16356343030929565\n",
            "Mini-Batch - 5 Back-Prop : 265, Loss : 0.18038803339004517\n",
            "Mini-Batch - 6 Back-Prop : 265, Loss : 0.19449231028556824\n",
            "Mini-Batch - 7 Back-Prop : 265, Loss : 0.19652840495109558\n",
            "Mini-Batch - 8 Back-Prop : 265, Loss : 0.14051443338394165\n",
            "Episode 9470 finished with score 1348.0, result : lose board : [[16.0, 64.0, 4.0, 2.0], [8.0, 4.0, 128.0, 16.0], [4.0, 8.0, 32.0, 2], [2, 16.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9475 finished with score 1708.0, result : lose board : [[2.0, 4.0, 2.0, 64.0], [32.0, 128.0, 32.0, 2.0], [4.0, 16.0, 64.0, 16.0], [2, 4, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9480 finished with score 3048.0, result : lose board : [[ 16.   4.   2. 256.]\n",
            " [  2.   8. 128.   8.]\n",
            " [  4.  64.  32.   4.]\n",
            " [  8.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9485 finished with score 1320.0, result : lose board : [[16.0, 2.0, 4.0, 128.0], [2.0, 64.0, 16.0, 8.0], [4.0, 8.0, 32.0, 4.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9490 finished with score 736.0, result : lose board : [[16.  2. 32.  2.]\n",
            " [ 4. 16.  2. 64.]\n",
            " [ 2.  8. 32. 16.]\n",
            " [ 8.  4.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9495 finished with score 3492.0, result : lose board : [[  2.   8. 256.  32.]\n",
            " [  8.  32.  64.   8.]\n",
            " [  4. 128.  16.  64.]\n",
            " [  2.   8.   2.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 266, Loss : 0.1499234437942505\n",
            "Mini-Batch - 1 Back-Prop : 266, Loss : 0.14680884778499603\n",
            "Mini-Batch - 2 Back-Prop : 266, Loss : 0.16755056381225586\n",
            "Mini-Batch - 3 Back-Prop : 266, Loss : 0.16471104323863983\n",
            "Mini-Batch - 4 Back-Prop : 266, Loss : 0.19866839051246643\n",
            "Mini-Batch - 5 Back-Prop : 266, Loss : 0.18256832659244537\n",
            "Mini-Batch - 6 Back-Prop : 266, Loss : 0.185979425907135\n",
            "Mini-Batch - 7 Back-Prop : 266, Loss : 0.17383712530136108\n",
            "Mini-Batch - 8 Back-Prop : 266, Loss : 0.1687609851360321\n",
            "Episode 9500 finished with score 2424.0, result : lose board : [[8.0, 16.0, 4.0, 256.0], [4.0, 8.0, 32.0, 64.0], [2.0, 4.0, 8.0, 32.0], [4, 2, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9505 finished with score 680.0, result : lose board : [[16.0, 2.0, 16.0, 64.0], [8.0, 16.0, 4.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9510 finished with score 2248.0, result : lose board : [[ 64. 128.   2.   4.]\n",
            " [  8.  16.  32. 128.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9515 finished with score 2380.0, result : lose board : [[16.0, 64.0, 4.0, 128.0], [8.0, 32.0, 128.0, 4.0], [2, 8.0, 16.0, 64.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9520 finished with score 1412.0, result : lose board : [[  8.  32.  64. 128.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.  16.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9525 finished with score 1092.0, result : lose board : [[2.0, 16.0, 128.0, 2.0], [16.0, 4.0, 2.0, 16.0], [8.0, 32.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 267, Loss : 0.18965724110603333\n",
            "Mini-Batch - 1 Back-Prop : 267, Loss : 0.1371912658214569\n",
            "Mini-Batch - 2 Back-Prop : 267, Loss : 0.20602954924106598\n",
            "Mini-Batch - 3 Back-Prop : 267, Loss : 0.16160760819911957\n",
            "Mini-Batch - 4 Back-Prop : 267, Loss : 0.14274370670318604\n",
            "Mini-Batch - 5 Back-Prop : 267, Loss : 0.1810193657875061\n",
            "Mini-Batch - 6 Back-Prop : 267, Loss : 0.16651226580142975\n",
            "Mini-Batch - 7 Back-Prop : 267, Loss : 0.1552640050649643\n",
            "Mini-Batch - 8 Back-Prop : 267, Loss : 0.14687496423721313\n",
            "Episode 9530 finished with score 1140.0, result : lose board : [[16.0, 32.0, 64.0, 4.0], [8.0, 16.0, 32.0, 64.0], [2.0, 32.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9535 finished with score 1312.0, result : lose board : [[16.0, 2.0, 4.0, 128.0], [4.0, 8.0, 64.0, 2.0], [2.0, 4.0, 2.0, 32.0], [8.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9540 finished with score 988.0, result : lose board : [[4.0, 16.0, 2.0, 128.0], [2.0, 8.0, 16.0, 4.0], [4.0, 32.0, 4, 2], [2, 4, 2.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9545 finished with score 1248.0, result : lose board : [[  4.   2.   4.  16.]\n",
            " [  2.   8. 128.   8.]\n",
            " [  4.  16.  64.   4.]\n",
            " [  2.   8.  16.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9550 finished with score 2076.0, result : lose board : [[16.0, 4.0, 128.0, 2.0], [2.0, 32.0, 2.0, 64.0], [4.0, 16.0, 128.0, 16.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9555 finished with score 700.0, result : lose board : [[2, 4, 2, 64.0], [4, 8.0, 64.0, 2], [2.0, 4.0, 8.0, 16.0], [4.0, 2.0, 4.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 268, Loss : 0.16228364408016205\n",
            "Mini-Batch - 1 Back-Prop : 268, Loss : 0.16435465216636658\n",
            "Mini-Batch - 2 Back-Prop : 268, Loss : 0.1356247514486313\n",
            "Mini-Batch - 3 Back-Prop : 268, Loss : 0.16305845975875854\n",
            "Mini-Batch - 4 Back-Prop : 268, Loss : 0.16641730070114136\n",
            "Mini-Batch - 5 Back-Prop : 268, Loss : 0.1464305967092514\n",
            "Mini-Batch - 6 Back-Prop : 268, Loss : 0.15251310169696808\n",
            "Mini-Batch - 7 Back-Prop : 268, Loss : 0.17151302099227905\n",
            "Mini-Batch - 8 Back-Prop : 268, Loss : 0.21329450607299805\n",
            "Episode 9560 finished with score 1860.0, result : lose board : [[8.0, 16.0, 128.0, 8.0], [4.0, 8.0, 32.0, 128.0], [2, 4.0, 16.0, 32.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9565 finished with score 1640.0, result : lose board : [[4.0, 8.0, 64.0, 8.0], [32.0, 16.0, 128.0, 4.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9570 finished with score 992.0, result : lose board : [[8.0, 2.0, 4.0, 128.0], [2.0, 8.0, 2.0, 16.0], [8.0, 32.0, 8.0, 4], [2.0, 8.0, 4.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9575 finished with score 1216.0, result : lose board : [[ 16.   4.  16.  32.]\n",
            " [  8.  16. 128.  16.]\n",
            " [  4.   8.  32.   4.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9580 finished with score 2736.0, result : lose board : [[16.0, 64.0, 256.0, 32.0], [8.0, 16.0, 64.0, 8.0], [4.0, 8.0, 16.0, 4.0], [2, 16.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9585 finished with score 1196.0, result : lose board : [[ 16.   4. 128.   4.]\n",
            " [  8.  16.  32.   2.]\n",
            " [  4.   8.  16.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9590 finished with score 2732.0, result : lose board : [[  2.  64.   8.   2.]\n",
            " [  8.  32. 256.   8.]\n",
            " [  4.   8.  32.  64.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 269, Loss : 0.18069010972976685\n",
            "Mini-Batch - 1 Back-Prop : 269, Loss : 0.1529056578874588\n",
            "Mini-Batch - 2 Back-Prop : 269, Loss : 0.19406436383724213\n",
            "Mini-Batch - 3 Back-Prop : 269, Loss : 0.16208916902542114\n",
            "Mini-Batch - 4 Back-Prop : 269, Loss : 0.1804896593093872\n",
            "Mini-Batch - 5 Back-Prop : 269, Loss : 0.15987582504749298\n",
            "Mini-Batch - 6 Back-Prop : 269, Loss : 0.16240498423576355\n",
            "Mini-Batch - 7 Back-Prop : 269, Loss : 0.1894027441740036\n",
            "Mini-Batch - 8 Back-Prop : 269, Loss : 0.15518267452716827\n",
            "Episode 9595 finished with score 3292.0, result : lose board : [[16.0, 4.0, 256.0, 2], [8.0, 64.0, 128.0, 16.0], [2.0, 16.0, 64.0, 4.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9600 finished with score 1476.0, result : lose board : [[2.0, 8.0, 16.0, 4.0], [4.0, 32.0, 128.0, 64.0], [8.0, 16.0, 32.0, 16.0], [2, 4.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9605 finished with score 3196.0, result : lose board : [[ 16.   2. 128.   8.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  4.  16.   8.  32.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9610 finished with score 1220.0, result : lose board : [[  2.  32.  16.   2.]\n",
            " [  4.   2. 128.   8.]\n",
            " [  8.  32.   4.   2.]\n",
            " [  2.   4.   8.  32.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9615 finished with score 1496.0, result : lose board : [[ 16.  32.   2.   8.]\n",
            " [  8.  16.  32. 128.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9620 finished with score 1196.0, result : lose board : [[2.0, 4.0, 16.0, 32.0], [8.0, 16.0, 32.0, 8.0], [4.0, 8.0, 128.0, 4.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 270, Loss : 0.14953814446926117\n",
            "Mini-Batch - 1 Back-Prop : 270, Loss : 0.1449970155954361\n",
            "Mini-Batch - 2 Back-Prop : 270, Loss : 0.13654443621635437\n",
            "Mini-Batch - 3 Back-Prop : 270, Loss : 0.16974054276943207\n",
            "Mini-Batch - 4 Back-Prop : 270, Loss : 0.16934512555599213\n",
            "Mini-Batch - 5 Back-Prop : 270, Loss : 0.17185191810131073\n",
            "Mini-Batch - 6 Back-Prop : 270, Loss : 0.23047205805778503\n",
            "Mini-Batch - 7 Back-Prop : 270, Loss : 0.14205582439899445\n",
            "Mini-Batch - 8 Back-Prop : 270, Loss : 0.1602359116077423\n",
            "Episode 9625 finished with score 2004.0, result : lose board : [[4.0, 8.0, 128.0, 2.0], [8.0, 128.0, 64.0, 8.0], [4.0, 8.0, 32.0, 4.0], [2, 4, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9630 finished with score 2772.0, result : lose board : [[ 16.   2. 256.   2.]\n",
            " [  8.  16.  32.   4.]\n",
            " [  4.   8. 128.   8.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9635 finished with score 2956.0, result : lose board : [[16.0, 64.0, 256.0, 4.0], [8.0, 32.0, 2.0, 64.0], [4.0, 64.0, 16.0, 4.0], [16.0, 8.0, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9640 finished with score 520.0, result : lose board : [[ 2.  4. 16. 32.]\n",
            " [ 8.  2. 32.  2.]\n",
            " [ 4.  8. 16.  8.]\n",
            " [ 2.  4. 32.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9645 finished with score 732.0, result : lose board : [[16. 32.  2. 16.]\n",
            " [ 8. 16. 32.  8.]\n",
            " [ 2.  4. 64.  4.]\n",
            " [ 4.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9650 finished with score 1464.0, result : lose board : [[8.0, 16.0, 64.0, 128.0], [2, 8, 32.0, 2], [4.0, 16.0, 2.0, 32.0], [2, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 271, Loss : 0.1715061515569687\n",
            "Mini-Batch - 1 Back-Prop : 271, Loss : 0.21849143505096436\n",
            "Mini-Batch - 2 Back-Prop : 271, Loss : 0.14895106852054596\n",
            "Mini-Batch - 3 Back-Prop : 271, Loss : 0.16561385989189148\n",
            "Mini-Batch - 4 Back-Prop : 271, Loss : 0.1813657283782959\n",
            "Mini-Batch - 5 Back-Prop : 271, Loss : 0.16073155403137207\n",
            "Mini-Batch - 6 Back-Prop : 271, Loss : 0.15449723601341248\n",
            "Mini-Batch - 7 Back-Prop : 271, Loss : 0.14509780704975128\n",
            "Mini-Batch - 8 Back-Prop : 271, Loss : 0.14651378989219666\n",
            "Episode 9655 finished with score 1680.0, result : lose board : [[2.0, 8.0, 128.0, 32.0], [8.0, 64.0, 16.0, 2.0], [4.0, 16.0, 64.0, 8.0], [2, 8.0, 16.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9660 finished with score 1496.0, result : lose board : [[  2. 128.   4.  16.]\n",
            " [ 32.   8.  32.   2.]\n",
            " [ 16.   4.  64.  16.]\n",
            " [  8.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9665 finished with score 776.0, result : lose board : [[16.0, 4.0, 8.0, 16.0], [8.0, 32.0, 64.0, 4.0], [2, 8.0, 16.0, 32.0], [4, 2, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9670 finished with score 944.0, result : lose board : [[2.0, 16.0, 2.0, 128.0], [4.0, 2.0, 8.0, 2.0], [2.0, 4.0, 2.0, 32.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9675 finished with score 1576.0, result : lose board : [[ 16.  32. 128.   8.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   8.  16.  32.]\n",
            " [  4.   2.   4.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9680 finished with score 3084.0, result : lose board : [[ 32.  64.   4.   2.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  4.   8.  32.   8.]\n",
            " [  2.   4.  64.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 272, Loss : 0.1768917590379715\n",
            "Mini-Batch - 1 Back-Prop : 272, Loss : 0.17357812821865082\n",
            "Mini-Batch - 2 Back-Prop : 272, Loss : 0.1492753028869629\n",
            "Mini-Batch - 3 Back-Prop : 272, Loss : 0.1880931556224823\n",
            "Mini-Batch - 4 Back-Prop : 272, Loss : 0.195034459233284\n",
            "Mini-Batch - 5 Back-Prop : 272, Loss : 0.15967462956905365\n",
            "Mini-Batch - 6 Back-Prop : 272, Loss : 0.18131738901138306\n",
            "Mini-Batch - 7 Back-Prop : 272, Loss : 0.173871710896492\n",
            "Mini-Batch - 8 Back-Prop : 272, Loss : 0.14504176378250122\n",
            "Episode 9685 finished with score 688.0, result : lose board : [[16. 64.  2. 32.]\n",
            " [ 8.  2. 32.  8.]\n",
            " [ 2.  8. 16.  4.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9690 finished with score 244.0, result : lose board : [[ 2.  8. 16. 32.]\n",
            " [ 8.  2.  4.  8.]\n",
            " [ 2.  8.  2.  4.]\n",
            " [ 4.  2.  8.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9695 finished with score 1964.0, result : lose board : [[2.0, 8.0, 16.0, 128.0], [16.0, 32.0, 128.0, 8.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9700 finished with score 3604.0, result : lose board : [[2.0, 4.0, 64.0, 2.0], [16.0, 64.0, 128.0, 256.0], [4.0, 8.0, 16.0, 64.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9705 finished with score 3380.0, result : lose board : [[  2.   8. 128.   2.]\n",
            " [  8.  32.  64. 256.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9710 finished with score 1752.0, result : lose board : [[32.0, 64.0, 4.0, 128.0], [4.0, 16.0, 64.0, 8.0], [2.0, 4.0, 16.0, 32.0], [4, 2.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 273, Loss : 0.1572452038526535\n",
            "Mini-Batch - 1 Back-Prop : 273, Loss : 0.2112252414226532\n",
            "Mini-Batch - 2 Back-Prop : 273, Loss : 0.17855069041252136\n",
            "Mini-Batch - 3 Back-Prop : 273, Loss : 0.14986658096313477\n",
            "Mini-Batch - 4 Back-Prop : 273, Loss : 0.16795660555362701\n",
            "Mini-Batch - 5 Back-Prop : 273, Loss : 0.1801120638847351\n",
            "Mini-Batch - 6 Back-Prop : 273, Loss : 0.1513148844242096\n",
            "Mini-Batch - 7 Back-Prop : 273, Loss : 0.15471749007701874\n",
            "Mini-Batch - 8 Back-Prop : 273, Loss : 0.17281147837638855\n",
            "Episode 9715 finished with score 1632.0, result : lose board : [[ 16.  64. 128.   4.]\n",
            " [  4.   8.  64.  32.]\n",
            " [  2.  16.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9720 finished with score 3416.0, result : lose board : [[32.0, 128.0, 256.0, 64.0], [4.0, 8.0, 64.0, 4.0], [2, 4.0, 8.0, 32.0], [4, 2, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9725 finished with score 660.0, result : lose board : [[ 2.  4. 32. 64.]\n",
            " [ 8. 32.  8.  2.]\n",
            " [ 4.  2.  4. 16.]\n",
            " [ 2.  8.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9730 finished with score 1764.0, result : lose board : [[ 16.  32.   2.  64.]\n",
            " [  8.  16.  64.   4.]\n",
            " [  4.   8.  32. 128.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9735 finished with score 1504.0, result : lose board : [[ 16.  32.  64. 128.]\n",
            " [  8.   4.  32.   2.]\n",
            " [  4.   2.   4.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9740 finished with score 3220.0, result : lose board : [[ 16.   2.  64. 256.]\n",
            " [  8.  32. 128.  32.]\n",
            " [  4.   8.  16.   8.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 274, Loss : 0.16690875589847565\n",
            "Mini-Batch - 1 Back-Prop : 274, Loss : 0.16136911511421204\n",
            "Mini-Batch - 2 Back-Prop : 274, Loss : 0.17761960625648499\n",
            "Mini-Batch - 3 Back-Prop : 274, Loss : 0.17587602138519287\n",
            "Mini-Batch - 4 Back-Prop : 274, Loss : 0.19237589836120605\n",
            "Mini-Batch - 5 Back-Prop : 274, Loss : 0.16457290947437286\n",
            "Mini-Batch - 6 Back-Prop : 274, Loss : 0.20222395658493042\n",
            "Mini-Batch - 7 Back-Prop : 274, Loss : 0.15590080618858337\n",
            "Mini-Batch - 8 Back-Prop : 274, Loss : 0.1829593926668167\n",
            "Episode 9745 finished with score 864.0, result : lose board : [[16. 32.  4. 64.]\n",
            " [ 4. 16. 64.  8.]\n",
            " [ 2.  4.  2.  4.]\n",
            " [ 4.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9750 finished with score 2204.0, result : lose board : [[2, 4.0, 64.0, 2.0], [4.0, 32.0, 8.0, 128.0], [32.0, 16.0, 128.0, 16.0], [4.0, 2.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9755 finished with score 636.0, result : lose board : [[8.0, 32.0, 2.0, 32.0], [2, 64.0, 8.0, 4.0], [4.0, 8.0, 4.0, 2], [2, 4, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9760 finished with score 1280.0, result : lose board : [[16.0, 32.0, 4.0, 32.0], [4.0, 16.0, 128.0, 16.0], [2.0, 32.0, 8.0, 4.0], [8.0, 2, 4, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9765 finished with score 2316.0, result : lose board : [[  8.  16.   2. 256.]\n",
            " [  2.   8.  64.   8.]\n",
            " [  4.  32.  16.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9770 finished with score 1624.0, result : lose board : [[16.0, 32.0, 128.0, 8.0], [8.0, 16.0, 32.0, 64.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 4.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9775 finished with score 3376.0, result : lose board : [[  4.  16.   8. 128.]\n",
            " [  8.   4. 256.   8.]\n",
            " [  4.   2. 128.  16.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 275, Loss : 0.15007632970809937\n",
            "Mini-Batch - 1 Back-Prop : 275, Loss : 0.17624208331108093\n",
            "Mini-Batch - 2 Back-Prop : 275, Loss : 0.15039050579071045\n",
            "Mini-Batch - 3 Back-Prop : 275, Loss : 0.15916265547275543\n",
            "Mini-Batch - 4 Back-Prop : 275, Loss : 0.12730816006660461\n",
            "Mini-Batch - 5 Back-Prop : 275, Loss : 0.1617475152015686\n",
            "Mini-Batch - 6 Back-Prop : 275, Loss : 0.15026839077472687\n",
            "Mini-Batch - 7 Back-Prop : 275, Loss : 0.1711718738079071\n",
            "Mini-Batch - 8 Back-Prop : 275, Loss : 0.14958561956882477\n",
            "Episode 9780 finished with score 556.0, result : lose board : [[ 8. 16.  2. 64.]\n",
            " [ 2.  8. 32.  8.]\n",
            " [ 8.  2.  8.  4.]\n",
            " [ 4.  8.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9785 finished with score 656.0, result : lose board : [[32. 16.  2. 16.]\n",
            " [ 2.  8. 64.  2.]\n",
            " [ 4.  2.  4. 32.]\n",
            " [ 2.  4.  2.  8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9790 finished with score 400.0, result : lose board : [[ 2.  4. 32.  4.]\n",
            " [ 8. 16.  8. 32.]\n",
            " [ 2.  8.  4.  2.]\n",
            " [ 4.  2.  8. 16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9795 finished with score 1024.0, result : lose board : [[8.0, 16.0, 2.0, 4.0], [4.0, 8.0, 4.0, 128.0], [2.0, 4.0, 32.0, 16.0], [4, 2.0, 8.0, 2.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9800 finished with score 3028.0, result : lose board : [[ 16.  32.   2. 256.]\n",
            " [  8.  16.  32.   8.]\n",
            " [  4.   8. 128.  32.]\n",
            " [  2.   4.   8.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9805 finished with score 576.0, result : lose board : [[8.0, 32.0, 2.0, 32.0], [2.0, 4.0, 32.0, 4.0], [8.0, 32.0, 4.0, 2], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 276, Loss : 0.158532977104187\n",
            "Mini-Batch - 1 Back-Prop : 276, Loss : 0.13882508873939514\n",
            "Mini-Batch - 2 Back-Prop : 276, Loss : 0.1909468024969101\n",
            "Mini-Batch - 3 Back-Prop : 276, Loss : 0.15850546956062317\n",
            "Mini-Batch - 4 Back-Prop : 276, Loss : 0.1821497231721878\n",
            "Mini-Batch - 5 Back-Prop : 276, Loss : 0.22465072572231293\n",
            "Mini-Batch - 6 Back-Prop : 276, Loss : 0.15504874289035797\n",
            "Mini-Batch - 7 Back-Prop : 276, Loss : 0.15109498798847198\n",
            "Mini-Batch - 8 Back-Prop : 276, Loss : 0.11707363277673721\n",
            "Episode 9810 finished with score 5712.0, result : lose board : [[ 32. 128.   4. 512.]\n",
            " [  2.   8. 128.  16.]\n",
            " [  8.   4.   8.   4.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9815 finished with score 1600.0, result : lose board : [[  8.  32.   4. 128.]\n",
            " [  4.  16.  32.  64.]\n",
            " [  2.   4.  16.  32.]\n",
            " [  4.   2.   4.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9820 finished with score 2220.0, result : lose board : [[16.0, 64.0, 4.0, 128.0], [2.0, 32.0, 128.0, 16.0], [4.0, 8.0, 16.0, 32.0], [2, 4.0, 8.0, 4]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9825 finished with score 896.0, result : lose board : [[ 16.   2.   8. 128.]\n",
            " [  8.   4.  16.   8.]\n",
            " [  4.   2.   4.   2.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9830 finished with score 3160.0, result : lose board : [[ 32.   2. 256.   4.]\n",
            " [ 16.   4. 128.   2.]\n",
            " [  4.  32.  16.  64.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9835 finished with score 764.0, result : lose board : [[ 2. 16. 64.  2.]\n",
            " [16.  2. 16. 32.]\n",
            " [ 4. 16. 32.  8.]\n",
            " [ 2.  8.  2.  4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9840 finished with score 3008.0, result : lose board : [[  2.  16.   2.   4.]\n",
            " [  8.  64. 128. 256.]\n",
            " [  4.  32.   8.   4.]\n",
            " [  2.   8.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 277, Loss : 0.17547664046287537\n",
            "Mini-Batch - 1 Back-Prop : 277, Loss : 0.17345485091209412\n",
            "Mini-Batch - 2 Back-Prop : 277, Loss : 0.17573581635951996\n",
            "Mini-Batch - 3 Back-Prop : 277, Loss : 0.16845552623271942\n",
            "Mini-Batch - 4 Back-Prop : 277, Loss : 0.19041435420513153\n",
            "Mini-Batch - 5 Back-Prop : 277, Loss : 0.15666161477565765\n",
            "Mini-Batch - 6 Back-Prop : 277, Loss : 0.13787265121936798\n",
            "Mini-Batch - 7 Back-Prop : 277, Loss : 0.1474493145942688\n",
            "Mini-Batch - 8 Back-Prop : 277, Loss : 0.13950636982917786\n",
            "Episode 9845 finished with score 3136.0, result : lose board : [[ 32. 128.   2.   4.]\n",
            " [ 16.   4. 256.  32.]\n",
            " [  4.  64.   4.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9850 finished with score 2140.0, result : lose board : [[  2.  32. 128.   2.]\n",
            " [  8.   4.  64. 128.]\n",
            " [  4.  16.  32.   2.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9855 finished with score 1020.0, result : lose board : [[  2.  16.  32. 128.]\n",
            " [  8.   4.  16.   2.]\n",
            " [  4.   2.   4.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9860 finished with score 604.0, result : lose board : [[ 8. 16. 64. 16.]\n",
            " [ 4.  8.  2.  8.]\n",
            " [ 2.  4. 16. 32.]\n",
            " [ 4.  2.  4.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9865 finished with score 836.0, result : lose board : [[16. 32.  2. 32.]\n",
            " [ 8. 16. 64.  8.]\n",
            " [ 4.  2. 32.  4.]\n",
            " [ 2.  4. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9870 finished with score 292.0, result : lose board : [[4.0, 2.0, 16.0, 32.0], [2.0, 4.0, 2.0, 16.0], [8.0, 2.0, 16.0, 4.0], [2, 4.0, 8.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 278, Loss : 0.22010797262191772\n",
            "Mini-Batch - 1 Back-Prop : 278, Loss : 0.19747886061668396\n",
            "Mini-Batch - 2 Back-Prop : 278, Loss : 0.2079479694366455\n",
            "Mini-Batch - 3 Back-Prop : 278, Loss : 0.24757695198059082\n",
            "Mini-Batch - 4 Back-Prop : 278, Loss : 0.21147693693637848\n",
            "Mini-Batch - 5 Back-Prop : 278, Loss : 0.19435258209705353\n",
            "Mini-Batch - 6 Back-Prop : 278, Loss : 0.16885462403297424\n",
            "Mini-Batch - 7 Back-Prop : 278, Loss : 0.14250586926937103\n",
            "Mini-Batch - 8 Back-Prop : 278, Loss : 0.1792055070400238\n",
            "Episode 9875 finished with score 1552.0, result : lose board : [[16.0, 2.0, 64.0, 128.0], [8.0, 16.0, 32.0, 2.0], [4.0, 8.0, 16.0, 32.0], [2, 4, 8, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9880 finished with score 3916.0, result : lose board : [[ 32.   4. 128. 256.]\n",
            " [ 16. 128.  32.   4.]\n",
            " [  4.   8.  16.  64.]\n",
            " [  2.   4.   2.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9885 finished with score 1420.0, result : lose board : [[  2.   8.  32.   8.]\n",
            " [  8.  64. 128.   4.]\n",
            " [  4.  16.   4.  32.]\n",
            " [  2.   4.  16.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9890 finished with score 3316.0, result : lose board : [[ 16.  64. 256.   8.]\n",
            " [  8.  16.  64. 128.]\n",
            " [  2.   8.  16.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9895 finished with score 1416.0, result : lose board : [[32.0, 16.0, 128.0, 4.0], [4.0, 8.0, 16.0, 64.0], [2, 4.0, 8.0, 32.0], [4, 2.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9900 finished with score 892.0, result : lose board : [[4.0, 8.0, 16.0, 32.0], [2.0, 64.0, 2.0, 8.0], [4.0, 2.0, 64.0, 2.0], [2, 4, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 279, Loss : 0.17238059639930725\n",
            "Mini-Batch - 1 Back-Prop : 279, Loss : 0.15031956136226654\n",
            "Mini-Batch - 2 Back-Prop : 279, Loss : 0.15096846222877502\n",
            "Mini-Batch - 3 Back-Prop : 279, Loss : 0.15131883323192596\n",
            "Mini-Batch - 4 Back-Prop : 279, Loss : 0.15488669276237488\n",
            "Mini-Batch - 5 Back-Prop : 279, Loss : 0.15398328006267548\n",
            "Mini-Batch - 6 Back-Prop : 279, Loss : 0.1674366444349289\n",
            "Mini-Batch - 7 Back-Prop : 279, Loss : 0.17402160167694092\n",
            "Mini-Batch - 8 Back-Prop : 279, Loss : 0.1958746463060379\n",
            "Episode 9905 finished with score 1180.0, result : lose board : [[16. 32. 16. 64.]\n",
            " [ 4. 16. 64. 32.]\n",
            " [ 2.  8. 32.  4.]\n",
            " [ 4.  2. 16.  2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9910 finished with score 1100.0, result : lose board : [[  4.  16.   4.  16.]\n",
            " [ 16.   2. 128.   8.]\n",
            " [  4.  32.  16.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9915 finished with score 2044.0, result : lose board : [[32.0, 64.0, 128.0, 32.0], [16.0, 32.0, 64.0, 16.0], [4.0, 16.0, 32.0, 8.0], [2, 4, 16, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9920 finished with score 1356.0, result : lose board : [[ 16.   4.  16.   8.]\n",
            " [  8.  64. 128.   4.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9925 finished with score 1408.0, result : lose board : [[8.0, 2.0, 4.0, 128.0], [2.0, 8.0, 64.0, 8.0], [4.0, 16.0, 32.0, 2.0], [2, 4, 8, 32.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9930 finished with score 1572.0, result : lose board : [[  2.   4.  64. 128.]\n",
            " [  8.  64.   8.   2.]\n",
            " [  4.   2.   4.  32.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 280, Loss : 0.16643933951854706\n",
            "Mini-Batch - 1 Back-Prop : 280, Loss : 0.15229672193527222\n",
            "Mini-Batch - 2 Back-Prop : 280, Loss : 0.13722838461399078\n",
            "Mini-Batch - 3 Back-Prop : 280, Loss : 0.16394315659999847\n",
            "Mini-Batch - 4 Back-Prop : 280, Loss : 0.18523360788822174\n",
            "Mini-Batch - 5 Back-Prop : 280, Loss : 0.16588720679283142\n",
            "Mini-Batch - 6 Back-Prop : 280, Loss : 0.21395808458328247\n",
            "Mini-Batch - 7 Back-Prop : 280, Loss : 0.18778415024280548\n",
            "Mini-Batch - 8 Back-Prop : 280, Loss : 0.21132323145866394\n",
            "Episode 9935 finished with score 1836.0, result : lose board : [[  2.   8.  16. 128.]\n",
            " [ 16.   2. 128.   8.]\n",
            " [  4.   8.  32.   2.]\n",
            " [  2.   4.   8.  16.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9940 finished with score 3396.0, result : lose board : [[ 32. 128. 256.   8.]\n",
            " [  8.  32.  64.  32.]\n",
            " [  2.  16.  32.   8.]\n",
            " [  4.   2.   4.   2.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9945 finished with score 1528.0, result : lose board : [[ 16.   2. 128.   8.]\n",
            " [  8.  64.   8.  64.]\n",
            " [  4.   8.   4.  16.]\n",
            " [  2.   4.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9950 finished with score 1604.0, result : lose board : [[2, 4.0, 128.0, 2], [8.0, 32.0, 64.0, 4.0], [4.0, 16.0, 4.0, 64.0], [2.0, 4.0, 8.0, 16.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9955 finished with score 336.0, result : lose board : [[4.0, 16.0, 4.0, 32.0], [2.0, 4.0, 16.0, 8.0], [4.0, 16.0, 2.0, 4.0], [2, 4, 16.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9960 finished with score 2160.0, result : lose board : [[ 32.   2. 128.   8.]\n",
            " [  8.  64.   8. 128.]\n",
            " [  4.  16.  32.   8.]\n",
            " [  2.   8.   2.   4.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 281, Loss : 0.17071162164211273\n",
            "Mini-Batch - 1 Back-Prop : 281, Loss : 0.16458843648433685\n",
            "Mini-Batch - 2 Back-Prop : 281, Loss : 0.20545031130313873\n",
            "Mini-Batch - 3 Back-Prop : 281, Loss : 0.18617939949035645\n",
            "Mini-Batch - 4 Back-Prop : 281, Loss : 0.1340092420578003\n",
            "Mini-Batch - 5 Back-Prop : 281, Loss : 0.19045144319534302\n",
            "Mini-Batch - 6 Back-Prop : 281, Loss : 0.1575918346643448\n",
            "Mini-Batch - 7 Back-Prop : 281, Loss : 0.1565048098564148\n",
            "Mini-Batch - 8 Back-Prop : 281, Loss : 0.15732695162296295\n",
            "Episode 9965 finished with score 5100.0, result : lose board : [[2.0, 16.0, 4.0, 8.0], [32.0, 4.0, 128.0, 512.0], [2.0, 32.0, 8.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9970 finished with score 1008.0, result : lose board : [[16. 32.  2. 64.]\n",
            " [ 8. 16. 64.  8.]\n",
            " [ 4.  8. 32.  2.]\n",
            " [ 2.  4.  2.  8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9975 finished with score 2164.0, result : lose board : [[ 16.  32.   4.  16.]\n",
            " [  8. 256.  16.   2.]\n",
            " [  4.  16.   2.  16.]\n",
            " [  2.   4.  16.   8.]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9980 finished with score 2724.0, result : lose board : [[2.0, 4.0, 2.0, 4.0], [8.0, 32.0, 256.0, 8.0], [4.0, 16.0, 128.0, 4.0], [2, 8.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9985 finished with score 420.0, result : lose board : [[8.0, 16.0, 2.0, 32.0], [16.0, 32.0, 4.0, 2], [4.0, 16.0, 8.0, 4.0], [2, 4, 2.0, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Episode 9990 finished with score 2576.0, result : lose board : [[2.0, 4.0, 2.0, 32.0], [8.0, 64.0, 256.0, 2.0], [4.0, 8.0, 64.0, 8.0], [2.0, 16.0, 4.0, 2]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Mini-Batch - 0 Back-Prop : 282, Loss : 0.1531834453344345\n",
            "Mini-Batch - 1 Back-Prop : 282, Loss : 0.13990697264671326\n",
            "Mini-Batch - 2 Back-Prop : 282, Loss : 0.2005898505449295\n",
            "Mini-Batch - 3 Back-Prop : 282, Loss : 0.18322524428367615\n",
            "Mini-Batch - 4 Back-Prop : 282, Loss : 0.16479556262493134\n",
            "Mini-Batch - 5 Back-Prop : 282, Loss : 0.16826383769512177\n",
            "Mini-Batch - 6 Back-Prop : 282, Loss : 0.19488473236560822\n",
            "Mini-Batch - 7 Back-Prop : 282, Loss : 0.17491526901721954\n",
            "Mini-Batch - 8 Back-Prop : 282, Loss : 0.18028977513313293\n",
            "Episode 9995 finished with score 1348.0, result : lose board : [[16.0, 32.0, 4.0, 16.0], [4.0, 16.0, 128.0, 2.0], [2.0, 4.0, 8.0, 64.0], [4, 2, 4, 8.0]], epsilon  : 4.94e-322, learning rate : 0.00040499999886378646 \n",
            "\n",
            "Maximum Score : 6356.0 ,Episode : 5768\n",
            "Loss : 0.1733394099606408\n",
            "\n",
            "Maximum Score : 6356.0 ,Episode : 5768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMeJmUVkGPrX"
      },
      "source": [
        "## Store the Trained Weights in a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QObZLa0aGPrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0a3db7-aebc-4380-8c14-3e557486da43"
      },
      "source": [
        "path = r'/content/gdrive/Shareddrives/CMPE_260/Tamanna_DQN/Final_Weights'\n",
        "weights = ['conv1_layer1_weights','conv1_layer2_weights','conv2_layer1_weights','conv2_layer2_weights','fc_layer1_weights','fc_layer1_biases','fc_layer2_weights','fc_layer2_biases']\n",
        "for w in weights:\n",
        "    flatten = final_weights[w].reshape(-1,1)\n",
        "    file = open(path + '\\\\' + w +'.csv','w')\n",
        "    file.write('Sno,Weight\\n')\n",
        "    for i in range(flatten.shape[0]):\n",
        "        file.write(str(i) +',' +str(flatten[i][0])+'\\n') \n",
        "    file.close()\n",
        "    print(w + \" written!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1_layer1_weights written!\n",
            "conv1_layer2_weights written!\n",
            "conv2_layer1_weights written!\n",
            "conv2_layer2_weights written!\n",
            "fc_layer1_weights written!\n",
            "fc_layer1_biases written!\n",
            "fc_layer2_weights written!\n",
            "fc_layer2_biases written!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPepWux9jtr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}